<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Planet Sage</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="Planet/2.0 +http://www.planetplanet.org">
<link rel="shortcut icon" href="images/sageicon.png" type="image/x-icon" />
<link rel="stylesheet" href="planet.css" type="text/css">
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type='text/x-mathjax-config'>
  MathJax.Hub.Config({tex2jax: {inlineMath:  [['$', '$'], ['\\(', 
'\\)']]}});
</script>
<link rel="alternate" href="http://planet.sagemath.org/atom.xml" title="" type="application/atom+xml">
</head>

<body>

<div class="body-corner">
<div id="body-corner-tl"></div> 
<div id="body-corner-tr"></div> 
</div>

<div id="header" class="small">

<div id="header-logo">
<a href="http://www.sagemath.org"><img src="images/sage_logo_new.png" title="Sage Computer Algebra System" alt="Sage logo"/></a> 
<a href="./index.html">Planet Sage Blog</a>
</div>

<div id="header-text">
</div>

</div>

<div id="header-navbar">
</div>
<div id="subnav">
</div>

<div class="bodypadding">

<div class="daygroup">
<h2>June 04, 2015</h2>

<div class="channelgroup">







<h3><a href="http://borassisagemath.blogspot.com/" title="Performance Improvements for the Graph Module of Sagemath">Michele Borassi</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-8558001006126216932.post-5727768572864220659">
<h4><a href="http://borassisagemath.blogspot.com/2015/06/comparison-of-graph-libraries.html">Comparison of Graph Libraries</a></h4>
<div class="entry">
<div class="content">
Many times, people asked me "Which is the best available graph library?", or "Which graph library should I use to compute this, or that?".<br />Well, personally I love to use Sage, but there are also several good alternatives. Then, the question becomes "How could we improve Sage, so that people will choose it?".<br /><br />In my opinion, graph libraries are compared according to the following parameters:<br /><ol><li>simplicity and documentation: people have little time, and the faster they learn how to use the library, the better;</li><li>number of routines available;</li><li>speed: sometimes, the input is very big, and the algorithms take much time to finish, so that a fast implementation is fundamental.</li></ol>While it is very difficult to measure the first point, the others can be compared and improved. For this reason, in order to outperform other libraries, we should implement new features, and improve existing ones. You don't say!<br /><br />However, this answer is not satisfactory: in principle, we could add all features available in other libraries, but this is a huge translational work, and while we are doing this work the other libraries will change, making this effort a never-ending story.<br /><br />My project proposes an alternative: cooperating instead of competing. I will try to interface Sage with other libraries, and to use their algorithms when the Sage counterpart is not available, or less efficient. This way, with an affordable amount of work, we will be able to run all algorithms available in the best graph libraries!<br /><br />As a first step, I have compared all the most famous C, C++, and Python graph libraries according to points 2 and 3, in order to choose which libraries should be included. The next posts will analyze the results of this comparison.</div>







<p class="date">
<a href="http://borassisagemath.blogspot.com/2015/06/comparison-of-graph-libraries.html">by Michele Borassi (noreply@blogger.com) at June 04, 2015 02:11 AM</a>
</p>
</div>
</div>




<div class="entrygroup" id="tag:blogger.com,1999:blog-8558001006126216932.post-6371615580569256662">
<h4><a href="http://borassisagemath.blogspot.com/2015/06/google-summer-of-code-lets-start.html">Google Summer of Code: let's start!</a></h4>
<div class="entry">
<div class="content">
This blog will follow my Google Summer of Code project, entitled <i>Performance Improvements for the Graph Module of Sagemath</i>. The complete project is available <a href="https://sites.google.com/a/imtlucca.it/borassi/unpublished-works/google-summer-of-code">here</a>, and related documents with partial results will be available on the same website.<br />In this first post, I would like to thank my mentor David Coudert and Nathann Cohen, who helped me a lot in writing this project and understanding how the graph module of Sagemath works.<br />With their help, and with the help of the Sage community, I hope it will be a useful and funny work! Let's start!</div>







<p class="date">
<a href="http://borassisagemath.blogspot.com/2015/06/google-summer-of-code-lets-start.html">by Michele Borassi (noreply@blogger.com) at June 04, 2015 01:10 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>May 29, 2015</h2>

<div class="channelgroup">







<h3><a href="http://benjamin-hackl.at/tag/gsoc15/" title="Benjamin Hackl » GSoC15">Benjamin Hackl</a></h3>


<div class="entrygroup" id="http://benjamin-hackl.at/?p=244" lang="en-US">
<h4><a href="http://benjamin-hackl.at/2015/05/29/asymptotic-expressions-motivation/">Asymptotic Expressions: Motivation</a></h4>
<div class="entry">
<div class="content">
<p>So, as Google Summer of Code started on Monday, May 25th it is time to give a proper motivation for the project I have proposed. The working title of my project is <b><i>(Multivariate) Asymptotic Expressions</i></b><i></i>, and its overall goal is to bring <em>asymptotic expressions</em> to SageMath.</p>
<h3>What are A<em>symptotic Expressions?</em></h3>
<p>A motivating answer for this question comes from the theory of <a href="http://en.wikipedia.org/wiki/Taylor_series">Taylor series</a>. Assume that we have a sufficiently nice (in this case meaning smooth) function <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-c87b82ed51d7a54a7534229a094c1ad1_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="f : \R \to \R" title="Rendered by QuickLaTeX.com" height="16" width="79" /> that we want to approximate in a neighborhood of some point <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-840fb05bb6710960e5bc919fdaff157a_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x_0 \in \R" title="Rendered by QuickLaTeX.com" height="15" width="52" />. Taylor&#8217;s theorem allows us to write <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-b4d1b0df3c2410f4861f806999e45296_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="f(x) = T_n(x) + R_n(x)" title="Rendered by QuickLaTeX.com" height="18" width="169" /> where</p>
<p class="ql-center-displayed-equation"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-9c322e654df5f0f826ba652d1b743d2d_l3.png" height="54" width="602" class="ql-img-displayed-equation quicklatex-auto-format" alt="\[ T_n(x) = \sum_{j=0}^n \frac{f^{(j)}(x_0)}{j!}\cdot (x-x_0)^j = f(x_0) + f'(x_0)\cdot (x-x_0) + \cdots + \frac{f^{(n)}(x_0)}{n!}\cdot (x-x_0)^n,  \]" title="Rendered by QuickLaTeX.com" /></p>
<p>and <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-a25561ccfcbcc5a1becd46f410004893_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \cdot (x-x_0)^{n+1}" title="Rendered by QuickLaTeX.com" height="29" width="233" />, where <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-df66f067b957c88b4cceb31908ffe0b8_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\xi" title="Rendered by QuickLaTeX.com" height="17" width="8" /> lies in a neighborhood of <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-94c80ec33ac5b2e6202e2482b43fff32_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x_0" title="Rendered by QuickLaTeX.com" height="11" width="17" />. Note that for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f54f6341692eb73e2cc8919871424c76_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to x_0" title="Rendered by QuickLaTeX.com" height="13" width="55" />, <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f89339de737848834d3fd33c3f8efc9c_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="R_n(x)" title="Rendered by QuickLaTeX.com" height="18" width="46" /> &#8220;behaves like&#8221; <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-4f169c562efa6f7772cbc3c2f7c7c775_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="(x-x_0)^{n+1}" title="Rendered by QuickLaTeX.com" height="19" width="88" />. In particular, we can certainly find a constant <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-6241993782e36c4cf93d595fe1f94592_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="C > 0" /> 0" /> 0" title="Rendered by QuickLaTeX.com" height="12" width="47" style="vertical-align: 0px;" /> such that <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-0f763c216e25a2102c1eba211d7c6f03_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="|R_n(x)| \leq C\cdot |x-x_0|^{n+1}" title="Rendered by QuickLaTeX.com" height="19" width="189" />, or, in other words: for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f54f6341692eb73e2cc8919871424c76_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to x_0" title="Rendered by QuickLaTeX.com" height="13" width="55" /> the growth of the function <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f89339de737848834d3fd33c3f8efc9c_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="R_n(x)" title="Rendered by QuickLaTeX.com" height="18" width="46" /> is bounded from above by the growth of <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-4f169c562efa6f7772cbc3c2f7c7c775_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="(x-x_0)^{n+1}" title="Rendered by QuickLaTeX.com" height="19" width="88" />.</p>
<p>The idea of bounding the growth of a function by the growth of another function when the argument approaches some number (or <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-dab23ad70ec4a26260829f7f75f2ac61_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\infty" title="Rendered by QuickLaTeX.com" height="8" width="16" />) is the central idea behind the <em><a href="http://en.wikipedia.org/wiki/Big_O_notation">big O notation</a>. </em>For function <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-edf708ccb5ccad7718fed2822e0bcaaf_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="f, g : \R \to \R" title="Rendered by QuickLaTeX.com" height="16" width="95" /> we write <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-62f42bb36a79a3e1917930d0e0d36534_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="f(x) = O(g(x))" title="Rendered by QuickLaTeX.com" height="18" width="118" /> for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f54f6341692eb73e2cc8919871424c76_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to x_0" title="Rendered by QuickLaTeX.com" height="13" width="55" /> if there is a constant <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-6241993782e36c4cf93d595fe1f94592_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="C > 0" /> 0" /> 0" title="Rendered by QuickLaTeX.com" height="12" width="47" style="vertical-align: 0px;" /> such that <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-6c30ce4921c60b9d16ea7f61fb761927_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="|f(x)| \leq C\cdot |g(x)|" title="Rendered by QuickLaTeX.com" height="18" width="134" /> for all <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-17a344e93aa6abe0fb47ef5c279e6883_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10" /> in some neighborhood of <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-94c80ec33ac5b2e6202e2482b43fff32_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x_0" title="Rendered by QuickLaTeX.com" height="11" width="17" />.</p>
<p>A case that is particularly important is the case of <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-458f808450d27107407e04750f78cca2_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x_0 = \infty" title="Rendered by QuickLaTeX.com" height="11" width="58" />, that is if we want to compare and/or characterize the behavior of some function for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-a26b2bc9c401bc80e9f89a67984f695f_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to\infty" title="Rendered by QuickLaTeX.com" height="11" width="55" />, which is also called the functions <em>asymptotic behavior</em>. For example, consider the functions <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-370568c7cd1969cb318d2d416d6901bb_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\log x" title="Rendered by QuickLaTeX.com" height="16" width="36" />, <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-c3210e65424c2b4e03a22f5754bff2c9_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x^3" title="Rendered by QuickLaTeX.com" height="15" width="17" /> and <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-d5f313dcaf65848d869f1b2e420033aa_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="e^x" title="Rendered by QuickLaTeX.com" height="12" width="16" />. All of them are growing unbounded for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-a26b2bc9c401bc80e9f89a67984f695f_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to\infty" title="Rendered by QuickLaTeX.com" height="11" width="55" /> &#8212; however, their asymptotic behavior differs. This can be seen by considering pairwise quotients of these functions: <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-c0c460203a2b221428db0fe2e2cadc62_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\frac{x^3}{e^x} \to 0" title="Rendered by QuickLaTeX.com" height="24" width="53" /> for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-a26b2bc9c401bc80e9f89a67984f695f_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to\infty" title="Rendered by QuickLaTeX.com" height="11" width="55" />, and therefore the asymptotic growth of <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-c3210e65424c2b4e03a22f5754bff2c9_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x^3" title="Rendered by QuickLaTeX.com" height="15" width="17" /> can be bounded above by the growth of <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-d5f313dcaf65848d869f1b2e420033aa_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="e^x" title="Rendered by QuickLaTeX.com" height="12" width="16" />, meaning <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f275960cfb2a2a659ee575c444f4064b_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x^3 = O(e^x)" title="Rendered by QuickLaTeX.com" height="19" width="85" /> for <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-a26b2bc9c401bc80e9f89a67984f695f_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x\to\infty" title="Rendered by QuickLaTeX.com" height="11" width="55" />.</p>
<p>The analysis of a functions asymptotic behavior is important for many applications, for example when determining time and space complexity of algorithms in computer science, or for describing the growth of classes of combinatorial objects: take, for example, binary strings of length <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-4c85c346e199ac1d20024087a0d3d320_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="2n" title="Rendered by QuickLaTeX.com" height="12" width="20" /> that contain equally many zeros and ones. If <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-cea2171f7755461938be5273bee96776_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="s_n" title="Rendered by QuickLaTeX.com" height="11" width="16" /> denotes the number of such strings, then we have</p>
<p class="ql-center-displayed-equation"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-f09413e7c95c203bfaaa0f54fd7fa83c_l3.png" height="43" width="381" class="ql-img-displayed-equation quicklatex-auto-format" alt="\[ s_n = \binom{2n}{n} = \frac{4^n}{\sqrt{n\pi}} \left(1 + O\left(\frac{1}{n}\right)\right) \quad\text{ for } n\to\infty. \]" title="Rendered by QuickLaTeX.com" /></p>
<p>Expressions like these are <em>asymptotic expressions.</em> When we consider asymptotic expressions in only one variable, everything works out nicely as a total order is induced. But as soon as multiple variables are involved, we don&#8217;t have a total order any more. Consider, for example, <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-03985c71f4b9bddbca21ef2a4f4a13f3_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x^2 y" title="Rendered by QuickLaTeX.com" height="19" width="27" /> and <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-ac7e5aa341e378463cb095b30897dcf3_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="xy^2" title="Rendered by QuickLaTeX.com" height="19" width="26" /> when <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-17a344e93aa6abe0fb47ef5c279e6883_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x" title="Rendered by QuickLaTeX.com" height="8" width="10" /> and <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-b74f69d2abdaf2998f9dce6d562d9db8_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="y" title="Rendered by QuickLaTeX.com" height="12" width="9" /> approach <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-dab23ad70ec4a26260829f7f75f2ac61_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\infty" title="Rendered by QuickLaTeX.com" height="8" width="16" />. These two elements cannot be compared to each other, which complicates computing with these expressions as they may contain multiple &#8220;irreducible&#8221; O-terms.</p>
<p>The following univariate and multivariate examples shall demonstrate how computing with such expressions looks like (all variables are assumed to go to <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-dab23ad70ec4a26260829f7f75f2ac61_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\infty" title="Rendered by QuickLaTeX.com" height="8" width="16" />):</p>
<p class="ql-center-displayed-equation"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-690ed4ebd933b86fb99f542d1bd83f3d_l3.png" height="21" width="581" class="ql-img-displayed-equation quicklatex-auto-format" alt="\[ x + O(x) = O(x),\quad x^2 \cdot (x + O(1)) = x^3 + O(x^2),\quad O(x^2) \cdot O(x^3) = O(x^5),  \]" title="Rendered by QuickLaTeX.com" /></p>
<p class="ql-center-displayed-equation"><span class="ql-right-eqno"> &nbsp; </span><span class="ql-left-eqno"> &nbsp; </span><img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-7d62b4942340f22047d7717cb66e4c85_l3.png" height="21" width="738" class="ql-img-displayed-equation quicklatex-auto-format" alt="\[ x y + O(x^2 y) = O(x^2y),\quad (y \log y + O(y)) (x^2 y + O(4^x \sqrt{x})) =  x^2 y^2 \log y + O(x^2 y^2) + O(4^x \sqrt{x} y \log y).   \]" title="Rendered by QuickLaTeX.com" /></p>
<p>Our plan is to provide an implementation based on which computations with these and more complicated expressions are possible.</p>
<h3>Planned Structure</h3>
<p>There are four core concepts of our implementation.</p>
<ul>
<li><strong><a href="http://trac.sagemath.org/ticket/17601">Asymptotic Growth Groups</a></strong>:<em> </em>These are multiplicative groups that contain <em>growth elements</em> like <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-5b355071c898b3aa2cf24ed7ae6de2fc_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="x^2" title="Rendered by QuickLaTeX.com" height="15" width="17" />, <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-370568c7cd1969cb318d2d416d6901bb_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\log x" title="Rendered by QuickLaTeX.com" height="16" width="36" />, <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-191411aa176821cc6949d8c94a4847cc_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="2^x \cdot x \cdot \log x" title="Rendered by QuickLaTeX.com" height="16" width="89" />. For starters, only univariate power growth groups will be implemented.</li>
</ul>
<ul>
<li><strong><a href="http://trac.sagemath.org/ticket/17715">Asymptotic Term Monoids</a></strong>: These monoids contain <em>asymptotic terms </em>&#8212; in essence, these are summands of asymptotic terms. Apart from exact term monoids (growth elements with a coefficient), we will also implement O-term monoids as well as a term monoid for a deviation of O-terms. Asymptotic terms have (in addition to their group operation, multiplication) <em>absorption </em>as an additional operation: for example, O-terms are able to absorb all asymptotically &#8220;smaller&#8221; elements.</li>
</ul>
<ul>
<li><strong><a href="http://trac.sagemath.org/ticket/17693">Mutable Poset</a></strong>: As we have mentioned above, due to the fact that multivariate asymptotic expressions do not have a total order with respect to their growth, we need a partially ordered set (&#8220;Poset&#8221;) that deals with this structure such that operations like absorbing terms can be performed efficiently. The mutable poset is the central data structure that asymptotic expressions are built upon.</li>
</ul>
<ul>
<li><strong><a href="http://trac.sagemath.org/ticket/17716">Asymptotic</a><a href="http://trac.sagemath.org/ticket/17716"> Ring</a></strong>: This is our top-level structure which is also supposed to be the main interaction object for users. The asymptotic ring contains the asymptotic expressions, i.e. intelligently managed sums of asymptotic terms. All common operations shall be possible here. Furthermore, the interface should be intelligent enough such that admissible expressions from the symbolic ring can be directly converted into elements of the asymptotic ring.</li>
</ul>
<p>Obviously, this &#8220;planned structure&#8221; is rather superficial. However, this is only to supplement the motivation for my project with some ideas on the implementation. I&#8217;ll go a lot more into the details of what I am currently implementing in the next few blog posts!</p>
<p>&nbsp;</p></div>







<p class="date">
<a href="http://benjamin-hackl.at/2015/05/29/asymptotic-expressions-motivation/">by behackl at May 29, 2015 01:34 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>May 27, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-9002226548496308542">
<h4><a href="http://sagemath.blogspot.com/2015/05/guiding-principles-for-sagemath-inc.html">Guiding principles for SageMath, Inc.</a></h4>
<div class="entry">
<div class="content">
<div class="salvus-editor-html-md-preview-content">In February of this year (2015), I founded a Delaware C Corporation called "SageMath, Inc.". &nbsp;This is a first stab at the guiding principles for the company. &nbsp; &nbsp;It should help clarify the relationship between the company, the Sage project, and other projects like OpenDreamKit and Jupyter/IPython.<br /><h3 id="company-mission-statement-">Company mission statement:</h3><blockquote>Make open source mathematical software ubiquitous.</blockquote>This involves both creating the SageMathCloud website and supporting the development and distribution of the SageMath and other software, including Jupyter, Octave, Scilab, etc.  Anything open source.<br /><h3 id="company-principles-">Company principles:</h3><ul><li>Absolutely all company funded software must be open source, under a <strong>GPLv3 <i>compatible</i></strong> license.    We are a 100% open source company.<br /> </li><li>Company independence and self-determination is far more important than money.  A core principle is that SMI is not for sale at any price, and will not participate in any partnership (for cost) that would restrict our freedom. This means:<br /> <ul><li>reject any offers from corp development from big companies to purchase or partner,</li><li>do not take any investment money unless absolutely necessary, and then only from the highest quality investors</li><li>do not take venture capital ever</li></ul></li><li>Be as open as possible about everything involving the company.  What should not be open (since it is dangerous):<br /> <ul><li>security issues, passwords</li><li>finances (which could attract trolls)</li><li>private user data</li></ul></li></ul>What should be open:<br /><ul><li>aggregate usage data, e.g., number of users.</li><li>aggregate data that could help other open source projects improve their development, e.g., common problems we observe with Jupyter notebooks should be provided to their team.</li><li>guiding principles</li></ul><h3 id="business-model">Business model</h3><ul><li>SageMathCloud is freemium with the expectation that 2-5% of users pay.<br /> </li><li>Target audience: all potential users of cloud-based math-related software.<br /> </li></ul><h3 id="sagemathcloud-mission">SageMathCloud mission</h3><blockquote>Make it as easy as possible to use open source mathematical software in the cloud.</blockquote>This means:<br /><ul><li>Minimize onboard friction, so in less than 1 minute, you can create an account and be using Sage or Jupyter or LaTeX.  Morever, the UI should be simple and streamlined specifically for the tasks, while still having deep functionality to support expert users.  Also, everything persists and can be sorted, searched, used later, etc.<br /> </li><li>Minimize support friction, so one click from within SMC leads to a support forum, an easy way for admins to directly help, etc.  This is not at all implemented yet.  Also, a support marketplace where experts get paid to help non-experts (tutoring, etc.).<br /> </li><li>Minimize teaching friction, so <em>everything</em> involving software related to teaching a course is as easy as possible, including managing a list of students, distributing and collecting homework, and automated grading and feedback.<br /> </li><li>Minimize pay friction, sign up for a $7 monthly membership, then simple clear pay-as-you-go functionality if you need more power.          <br /> </li></ul></div></div>







<p class="date">
<a href="http://sagemath.blogspot.com/2015/05/guiding-principles-for-sagemath-inc.html">by William Stein (noreply@blogger.com) at May 27, 2015 01:03 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>May 23, 2015</h2>

<div class="channelgroup">







<h3><a href="http://benjamin-hackl.at/tag/gsoc15/" title="Benjamin Hackl » GSoC15">Benjamin Hackl</a></h3>


<div class="entrygroup" id="http://benjamin-hackl.at/?p=109" lang="en-US">
<h4><a href="http://benjamin-hackl.at/2015/05/23/google-summer-of-code-countdown/">Google Summer of Code — Countdown</a></h4>
<div class="entry">
<div class="content">
<p>Today I received the welcome package for attending this year&#8217;s &#8220;Google Summer of Code&#8221;! Actually, it&#8217;s pretty cool; the following things were included:</p>
<ul>
<li>a blue notebook with a monochromatic GSoC 15 logo (in dark blue) printed on it</li>
<li>a sticker with a colored GSoC 15 logo</li>
<li>a pen that is both a blue ballpoint pen as well as a mechanical pencil (0.5)</li>
</ul>
<p>Here is a photo of all this stuff:</p>
<p><a href="http://benjamin-hackl.at/asdf-wp/wp-content/uploads/2015/05/gsoc_welcome.jpg"><img class=" size-medium wp-image-118 aligncenter" src="http://benjamin-hackl.at/asdf-wp/wp-content/uploads/2015/05/gsoc_welcome-225x300.jpg" alt="gsoc_welcome" width="225" height="300" /></a></p>
<p>&nbsp;</p>
<p>The work on our project (multivariate) Asymptotic Expressions (in cooperation with <a href="http://danielkrenn.at">Daniel Krenn</a> and <a href="http://wwwu.aau.at/cheuberg">Clemens Heuberger</a>) begins (or rather continues) on Monday, the 25th of May. Over the course of next week (probably in a <img src="http://benjamin-hackl.at/asdf-wp/wp-content/ql-cache/quicklatex.com-da09357369045f1edc78767bdc4bff93_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="\varepsilon" title="Rendered by QuickLaTeX.com" height="8" width="8" />-neighborhood of Monday) I will blog about the status quo, as well as about the motivation for the project. <img src="http://benjamin-hackl.at/asdf-wp/wp-includes/images/smilies/simple-smile.png" alt=":-)" class="wp-smiley" /></p></div>







<p class="date">
<a href="http://benjamin-hackl.at/2015/05/23/google-summer-of-code-countdown/">by behackl at May 23, 2015 01:58 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>May 04, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/05/04/code-on-cake-poker-and-a-number-theory-classification-webapp/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/05/04/code-on-cake-poker-and-a-number-theory-classification-webapp/">Code on cake, poker and a number theory classification web app</a></h4>
<div class="entry">
<div class="content">
<p>I have just finished writing feedback and obtaining marks for my first year
students’ presentations. These presentations follow 11 weeks during which
students formed companies and worked together to come up with a ‘product’ which
had to involve mathematics and code (this semester comes just after 11 weeks of
learning Python and Sage). In this post I’ll briefly describe some of the great
things that the students came up with.</p>

<p>I must say that I was blown away by the standard this year. Last year the
students did exceptionally well but this year the standard was even higher, I am
so grateful for the effort put in by more or less everyone.</p>

<p>Some of the great projects included:</p>

<ul>
  <li>
    <p>A website that used a fitted utility function (obtained from questioning
family, friends, flatmates) to rank parking lots in terms of price and
distance from a given venue (the website was written in Django and the
function fitted using Sage).</p>
  </li>
  <li>
    <p>A commando training app, with an actual reservist marine who is a student
of ours:</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/venture.jpg" alt="" /></p>
  </li>
  <li>
    <p>A story based game with an original storyline stemming from the zodiac. The
presentation culminated in Geraint, Jason and I (who were the audience)
retaliating to their Nerf gun attack with our (hidden under the desk) Nerf guns (we had a hunch
that this group would ambush us…). The game mechanics itself was coded in
pure Python and the UI was almost written in Django (that
was the goal but they didn’t have the time to fully implement it).</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/cardiff_elite_four.jpg" alt="" /></p>
  </li>
  <li>
    <p>A Django site that had a graphical timeline of mathematics (on click you had
access to a quizz and info etc…). This was one I was
particularly excited about as it’s a tool I would love to use.</p>
  </li>
  <li>
    <p>An outreach/educational package based around cryptography. They coded a
variety of cyphers in Python and also put together an excellent set of
teaching resources with really well drawn characters etc… They even threw in
my dog Auraya (the likeness of the drawing is pretty awesome :)):</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/cryptogram.jpg" alt="" />
  <img src="http://vknight.org/unpeudemath/assets/images/auraya.jpg" alt="" /></p>
  </li>
  <li>
    <p>I ask my students to find an original way of showcasing their code. I don’t
actually know the right answer to that ‘challenge’. Most students showcase the
website and/or app, some will talk me through some code but this year one
group did something quite frankly awesome: <strong>code on cake</strong>. Here’s some of
the code they wrote for their phone app (written with kivy):</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/-1_cake.jpg" alt="" /></p>
  </li>
  <li>
    <p>One group built a fully functioning and hosted web app (after taking a look at
Django they decided that Flask was the way to go for this particular tool).
Their app takes in a natural number and classifies it against a number of
categories, go ahead and try it right now: <a href="http://jayrobertvos.pythonanywhere.com/">Categorising Numbers</a></p>
  </li>
  <li>
    <p>One of the more fun presentations was for a poker simulation app that uses a
prime number representation of a hand of poker to simulate all possible
outcomes of a given state. This work remarkably fast and immediately spits out
(with neat graphics of the cards) the probability of winning given the current
cards. As well as an impressive app the students presented it very well and
invited me to play a game of poker (I lost, their mark was not affected…):</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/team_super_awesome_funsies_selfie.jpg" alt="" /></p>

    <p>Here are a couple of screen shots of the app itself:</p>

    <p>Home screen:</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/oddson_1.png" alt="" /></p>

    <p>The input card screen:</p>

    <p><img src="http://vknight.org/unpeudemath/assets/images/oddson_0.png" alt="" /></p>
  </li>
</ul>

<p>I am missing out a bunch of great projects (including an impressive <em>actual</em>
business that I will be delighted to talk about more when appropriate). I am
very grateful to the efforts put in by all the students and wish them well
during their exams.</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/05/04/code-on-cake-poker-and-a-number-theory-classification-webapp/">May 04, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>April 06, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/04/06/my-5-reasons-why-jekyll-with-github-is-a-terrible-teaching-tool/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/04/06/my-5-reasons-why-jekyll-with-github-is-a-terrible-teaching-tool/">My 5 reasons why jekyll + github is a terrible teaching tool.</a></h4>
<div class="entry">
<div class="content">
<p>For the past year or so I have been using <a href="http://jekyllrb.com/">jekyll</a> for all
my courses.
If you do not know, in a nutshell, jekyll is a ruby framework that lets you
write templates for pages and build nice websites using static markdown files
for your content.
Here I will describe what I think of jekyll from a pedagogic point of view, in 5 main points.</p>

<h2 id="jekyll-is-terrible-because-the-tutorial-is-too-well-written-and-easy-to-follow">1. Jekyll is terrible because the tutorial is too well written and easy to follow.</h2>

<p>First of all, as an academic I enjoy when things are difficult to read and
follow.
The Jekyll tutorial can get you up and running with a jekyll site in less than 5
minutes.
It is far too clear and easy to follow.
This sort of clear and to the point
explanation is very dangerous from a pedagogic point of view as students might
stumble upon it and raise their expectations of the educational process they are
going through.</p>

<p>In all seriousness, the tutorial is well written and clear, with a basic
knowledge of the command line you can modify the base site and have a website
deployed in less than 10 minutes.</p>

<h2 id="jekyll-is-terrible-because-it-works-too-seamlessly-with-github">2. Jekyll is terrible because it works too seamlessly with github.</h2>

<p>First of all gh-pages takes care of the hosting.
Not having to use a complicated server saves far too much time.
As academics we have too much free time already, I do not like getting bored.</p>

<p>Github promotes the sharing and openness of code, resources and processes.
Using a jekyll site in conjunction with github means that others can
easily see and comment on all the materials as well as potentially
improve them.
This openness is dangerous as it ensures that courses are living and breathing
things as opposed to a set of notes/problem sheets that sit safely in a drawer
somewhere.</p>

<p>The fact that jekyll uses markdown is also a problem.
On github anyone can easily read and send a pull request (which improves things)
without really knowing markdown (let alone git).
This is very terrible indeed, <a href="https://github.com/drvinceknight/Computing_for_mathematics/commit/c9370a3e2880e0d6d2d3a0f4e3bb90a306783787">here for example is a pull request sent to me by a
student</a>.
The student in question found a mistake in a question sheet and asked me about it,
right there in the lab I just said ‘go ahead and fix it :)’ (and they did).
Involving students in the process of fixing/improving their course materials
has the potential for utter chaos.
Furthermore normalising mistakes is another big problem: all students should be
terrified of making a mistake and/or trying things.</p>

<p>Finally, having a personal site as a github project gives you a site at the
following url:</p>

<pre><code>username.github.io
</code></pre>

<p>By simply having a <code>gh-pages</code> branch for each class site, this will
automatically be served at:</p>

<pre><code>username.github.io/class-site
</code></pre>

<p>This is far too sensible and flexible.
Furthermore the promotion of decentralisation of content is dangerous.
If one of my class sites breaks: none of my others will be affected!!!
How can I expect any free time with such a robust system?
This is dangerously efficient.</p>

<h2 id="jekyll-is-terrible-because-it-is-too-flexible">3. Jekyll is terrible because it is too flexible.</h2>

<p>You can (if you want to) include:</p>

<ul>
  <li>
    <p><a href="https://disqus.com/">A disqus.com</a> board to a template for a page which means
that students can easily comment and talk to you about materials.
Furthermore you can also use this to add things to your materials in a
discussion based way, for example I have been able to far too easily to add a
picture of a whiteboard explaining something students have asked.</p>
  </li>
  <li>
    <p><a href="https://www.mathjax.org/">Mathjax</a>. With some escaping this works out of the
box. Being able to include nicely rendered mathematics misaligns students’
expectations as to what is on the web.</p>
  </li>
  <li>
    <p><a href="https://sagecell.sagemath.org/">Sage cells</a> can be easily popped in to
worksheets allowing students to immediately use code to illustrate/explain a
concept.</p>
  </li>
</ul>

<p>and various others: you can just include any html/javascript etc…</p>

<p>This promotion of interactive and modern resources by Jekyll is truly terrible
as it gets students away from what teaching materials should really be about:
dusty notes in the bottom of a drawer (worked fine for me).</p>

<p>The flexibility of Jekyll is also really terrible as it makes me forget the
restrictions imposed on me by whatever VLE we are supposed to use.
This is making me weak and soft, when someone takes the choice away from me and
I am forced to use the VLE, I most probably won’t be ready.</p>

<p>(A jekyll + github setup also implis that a wiki immediately exists for a page
and I am also experimenting with a <a href="https://gitter.im">gitter.im</a> room for each class).</p>

<h2 id="jekyll-is-terrible-because-it-gives-a-responsive-site-out-of-the-box">4. Jekyll is terrible because it gives a responsive site out of the box.</h2>

<p>Students should consume their materials exactly when and how we want them to.
The base jekyll site cames with a basic responsive framework, here is a photo of
one of my class sheets (which also again shows the disgustingly beautifully
rendered mathematics):</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/jekyll_site.png" alt="" /></p>

<p>This responsive framework works right out of the box (you can also obviously use
further frameworks if you want to, see my point about flexibility) from the tutorial and this
encourages students to have access to the materials on whatever platform they
want whenever they want.
This cannot be a good thing.</p>

<h2 id="jekyll-is-terrible-because-it-saves-me-too-much-time">5. Jekyll is terrible because it saves me too much time.</h2>

<p>The main point that is truly worrying about jekyll is how much time it saves me.
I have mentioned this before, as academics we need to constantly make sure we do
not get bored.
Jekyll does not help with this.</p>

<p>I can edit my files using whatever system I want (I can even do this on github
directly if I wanted to), I push and the website is up to date.</p>

<p>In the past I would have a lot of time taken up by compiling a LaTeX document
and uploading to our VLE.
I would sit back and worry about being bored before realising (thankfully) that
I had a typo and so needed to write, delete and upload again.</p>

<p>Furthermore, I can easily use the github issue tracker to keep on top of to do
lists etc… (which I am actually beginning to do for more or less every aspect
of my life).
TAs can also easily fix/improve minor things without asking me to upload
whatever it is they wrote.</p>

<p>Github + Jekyll works seamlessly and ensures that I have more time to respond to
student queries and think.
This time for reflection on teaching practice is dangerous: I might choose to do
things differently than how they have been done for the past 100 years.</p>

<p>(<em>In case my tone is unclear: I am such a huge jekyll fan and think it is a
brilliant pedagogic tool.
There might well be various other static site generators and other options so please do
comment about them below :)</em>)</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/04/06/my-5-reasons-why-jekyll-with-github-is-a-terrible-teaching-tool/">April 06, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 25, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/25/a_one_week_flipped_teaching_environment_to_introduce_object_oriented_programming/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/25/a_one_week_flipped_teaching_environment_to_introduce_object_oriented_programming/">A one week flipped learning environment to introduce Object Oriented Programming</a></h4>
<div class="entry">
<div class="content">
<p>This post describes a teaching activity that is run for the Cardiff MSc. programmes.
The activity is revolves around a two day hackathon that gets students to use Python and object oriented programming to solve a challenge.
The activity is placed within a flipped learning environment and makes use of what I feel is a very nice form of assessment (we just get to know the students).</p>

<p>This year is the third installment of this exercise which came as a result of the MSc advisory board requesting that object oriented programming be introduced to our MSc.</p>

<p>Before describing the activity itself let me just put this simple diagram that describes the flipped learning environment here (if you would like more info about it be sure to talk to <a href="https://plus.google.com/+RobertTalbert/posts">Robert Talbert</a> who has always been very helpful to me):</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/flipped_environment.svg" alt="" /></p>

<h2 id="description-of-what-happens">Description of what happens</h2>

<p>After 3 iterations and a number of discussions about the format with <a href="https://plus.google.com/u/0/+PaulHarper/posts">Paul Harper</a> (the director of the MSc) I think the last iteration is pretty spot on and it goes something like this:</p>

<h3 id="monday-transfer-of-content">Monday: Transfer of content</h3>

<p>We give a brief overview of Python (you can see the <a href="http://vincent-knight.com/Introduction_to_OOP/">slides here</a>) up until and including basic syntax for classes.</p>

<h3 id="tuesday--wednesday-nothing">Tuesday + Wednesday: Nothing</h3>

<p>Students can, if they want to, read up about Python, look through videos at the website and elsewhere, look through past challenges etc…
<strong>This is in effect when the knowledge transfer happens</strong></p>

<h3 id="thursday-flying-solo-followed-by-feedback">Thursday: Flying solo followed by feedback</h3>

<p>Students are handed a challenge of some sort (you can see the past two <a href="http://vincent-knight.com/Introduction_to_OOP/Challenges/">here</a>).
Students work in groups of 4 at attempting to solve the problem.
On this day, the two postgrads (<a href="https://plus.google.com/u/0/+JasonYoung/posts">Jason</a> and <a href="https://plus.google.com/u/0/118222786508884333473/posts">Geraint</a>) and myself observe the groups.
When we are asked questions we in general ask questions back.
This sometimes leads to a fair bit of frustration but is the difficult process that makes the rest of the process worthwhile.</p>

<p>Here is a photo of some of the groups getting to work:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/oop_thursday_gp_1.jpg" alt="" />
<img src="http://vknight.org/unpeudemath/assets/images/oop_thursday_gp_2.jpg" alt="" /></p>

<p>At the very end of the day (starting at 1600 for about 30 minutes with each group).
During this feedback session go through the code written by each group in detail, highlighting things they are having difficulty with and agreeing on a course of action for the next day.
<strong>This is the point at which the class ‘flips’ so to speak: transfer of content is done and difficulties are identified and conceptualised</strong>.</p>

<p>Here is a photo of Jason, Geraint and I at the end of a very long day after the feedback sessions:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/oop_post_feedback.jpg" alt="" /></p>

<p>The other point of this day is that we start our continuous assessment: taking notes and discussing how each group is doing:</p>

<ul>
  <li>Where are they progress wise?</li>
  <li>What difficulties do we need to look out for?</li>
  <li>How are the groups approaching the problem and working together.</li>
</ul>

<p>Here you can see a photo of Jason in front of the board that we fill up over the 2 days with notes and comments:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/oop_board.jpg" alt="" /></p>

<h3 id="friday-sprint-finish-with-more-assistance">Friday: Sprint finish with more assistance</h3>

<p>On the second/last day students are given slightly more assistance from Jason, Geraint and I but are still very much left to continue with their hard work.
The main difference being that when students ask questions we sometimes answer them.</p>

<p>Here is one group who managed to crack something quite difficult on the second day:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/oop_friday_gp.jpg" alt="" /></p>

<p>The final part of this day is to round all the students together and announce the marks, which brings us nicely to the assessment part of this activity.</p>

<h2 id="assessment">Assessment</h2>

<p>I really enjoy assessing this activity.
This is not something I say about assessment very often, but we are continuously assessing the students and are able to gain a true idea of how they do.
The final piece of code is not what everything is marked on as it is in essence not terribly important.</p>

<p>Here is a photo of the team who did the best this year:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/oop_winners.jpg" alt="" /></p>

<p>If I could sit with students over the 11 week period of the other courses I teach and get to know them and assess them that way, that is indeed how I would do it.</p>

<h2 id="summary"> Summary</h2>

<p>Here is a summary of how I feel this activity fits in the original diagram I had:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/oop_day_as_a_flipped_environment.svg" alt="" /></p>

<p>As you can see despite ‘being in contact’ with students for most of Thursday I would not consider this contact time in the usual sense as most of that contact is part of the assessment.</p>

<p>This is always a very fun (and exhausting) two days and I look forward to next year.</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/25/a_one_week_flipped_teaching_environment_to_introduce_object_oriented_programming/">March 25, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 24, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/24/marrying_toys_and_students/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/24/marrying_toys_and_students/">Marrying toys and students</a></h4>
<div class="entry">
<div class="content">
<p>In class yesterday we took a look at matching games.
These are sometimes referred to as stable marriage problems.
To have some data for us to play with I asked for some volunteers to marry.
Sadly I apparently am not allowed to ask students to rank each other in class and I also do not have the authority to marry.
So, <a href="http://drvinceknight.blogspot.co.uk/2014/03/matching-games-in-class.html">like last year</a> I used some of my office toys and asked students to rank them.</p>

<p>I brought three toys to class:</p>

<ul>
  <li>The best ninja turtle: Donatello</li>
  <li>A tech deck</li>
  <li>A foam football</li>
</ul>

<p>I asked 3 students to come down and rank them and in turn I let the toys rank the students.</p>

<p>We discussed possible matchings with some great questions such as:</p>

<blockquote>
  <p>“Are we trying to make everyone as happy as possible?”</p>
</blockquote>

<p>The answer to that is: no.
We are simply trying to ensure that no one has an incentive to deviate from their current matching by breaking their match for someone they prefer and who also prefers them.</p>

<p>Here is the stable matching we found together:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/matching_game.jpg" alt="" /></p>

<p>Note that we can run the Gale-Shapley value using Sage:</p>

<div class="compute"></div>

<p>The 3 students got to hold on to the toys for the hour and I was half expecting the football to be thrown around but sadly that did not happen.
Perhaps next year.</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/24/marrying_toys_and_students/">March 24, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 23, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/23/cooperative_basketball_in_class/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/23/cooperative_basketball_in_class/">Cooperative basketball in class</a></h4>
<div class="entry">
<div class="content">
<p>Today in class we repeated the game we played <a href="http://drvinceknight.blogspot.co.uk/2014/03/basketball-and-cooperative-games-in.html">last year</a>.
3 teams of 3 students took part this year and here is a photo of the aftermath:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/basketball.jpg" alt="" /></p>

<p>As a class we watched the three teams attempt to free-throw as many crumpled up pieces of paper in to the bin as possible.</p>

<p>Based on the total number we then tried to come up with how many each subset/coalition of players would have gotten in.
So for example, 2 out of 3 of the teams had one student crumple paper while the other 2 took shots.
So whilst that individual did not get any in, they contributed an important part to the team effort.</p>

<p>Here are the characteristic functions that show what each team did:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/basketball-characteristic-functions.jpg" alt="" /></p>

<p>Here is some <a href="http://sagemath.org/">Sage</a> code that gives the Shapley value for each game (<a href="http://vincent-knight.com/Year_3_game_theory_course/Content/Chapter_16_Cooperative_games/">take a look at my class notes</a> or at <a href="http://drvinceknight.blogspot.co.uk/2014/03/basketball-and-cooperative-games-in.html">last years post</a> to see how to calculate this):</p>

<p>Let us define the first game:</p>

<div class="compute"></div>

<p>If you click <code>Evaluate</code> above you see that the Shapley value is given by:</p>



<p>(This one we calculated in class)</p>

<p>By changing the numbers above we get the following for the other two games.</p>

<ul>
  <li>
    <p>Game 2:</p>

    
  </li>
  <li>
    <p>Game 3:</p>

    
  </li>
</ul>

<p>This was a bit of fun and most importantly from a class point of view gave us some nice numbers to work from and calculate the Shapley value together.</p>

<p>If anyone would like to read about the Shapley value a bit more take a look at the <a href="http://www.sagemath.org/doc/reference/game_theory/sage/game_theory/cooperative_game.html">Sage documentation</a> which not only shows how to calculate it using Sage but also goes over some of the mathematics (including another formulation).</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/23/cooperative_basketball_in_class/">March 23, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 20, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Character-Theory/">
<h4><a href="http://sheaves.github.io/Character-Theory/">Character Theory Basics</a></h4>
<div class="entry">
<div class="content">
<p>This post illustrates some of SageMath’s character theory functionality, as well as some basic results about characters of finite groups. </p>

<!--more-->

<h2 id="basic-definitions-and-properties">Basic Definitions and Properties</h2>

<p>Given a representation $(V,\rho)$ of a group $G$, its <a href="http://en.wikipedia.org/wiki/Character_theory" target="_blank"><strong>character</strong></a> is a map $ \chi: G \to \mathbb{C}$ that returns the <a href="http://en.wikipedia.org/wiki/Trace_(linear_algebra)" target="_blank">trace</a> of the matrices given by $\rho$:</p>



<p>A character $\chi$ is <strong>irreducible</strong> if the corresponding $(V,\rho)$ is <a href="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/" target="_blank">irreducible</a>.</p>

<p>Despite the simplicity of the definition, the (irreducible) characters of a group contain a surprising amount of information about the group. Some <a href="http://en.wikipedia.org/wiki/Character_theory#Applications" target="_blank">big theorems</a> in group theory depend heavily on character theory.</p>

<p>Let’s calculate the character of the permutation representation of $D_4$. For each $g \in G$, we’ll display the pairs:</p>



<p><em>(The Sage cells in this post are linked, so things may not work if you don’t execute them in order.)</em></p>

<div class="linked">
  
</div>

<p>Many of the following properties of characters can be deduced from properties of the trace:</p>

<ol>
  <li>The <strong>dimension</strong> of a character is the dimension of $V$ in $(V,\rho)$. Since $\rho(\text{Id})$ is always the identity matrix, the dimension of $\chi$ is $\chi(\text{Id})$.</li>
  <li>Because the trace is <a href="http://en.wikipedia.org/wiki/Similarity_invariance" target="_blank">invariant under similarity transformations</a>, $\chi(hgh^{-1}) = \chi(g)$ for all $g,h \in G$. So characters are constant on conjugacy classes, and are thus <a href="http://en.wikipedia.org/wiki/Class_function" target="_blank"><strong>class functions</strong></a>.</li>
  <li>Let $\chi_V$ denote the character of $(V,\rho)$. Recalling the definitions of <a href="http://sheaves.github.io/Representation-Theory-Sums-Products/" target="_blank">direct sums and tensor products</a>, we see that</li>
</ol>



<h2 id="the-character-table">The Character Table</h2>

<p>Let’s ignore the representation $\rho$ for now, and just look at the character $\chi$:</p>

<div class="linked">
  
</div>

<p>This is succinct, but we can make it even shorter. From point 2 above, $\chi$ is constant on conjugacy classes of $G$, so we don’t lose any information by just looking at the values of $\chi$ on each conjugacy class:</p>

<div class="linked">
  
</div>

<p>Even shorter, let’s just display the values of $\chi$:</p>

<div class="linked">
  
</div>

<p>This single row of numbers represents the character of <em>one</em> representation of $G$. If we knew all the irreducible representations of $G$ and their corresponding characters, we could form a table with one row for each character. This is called the <a href="http://en.wikipedia.org/wiki/Character_table" target="_blank"><strong>character table</strong></a> of $G$.</p>

<p>Remember how we had to define our representations by hand, one by one? We don’t have to do that for characters, because  SageMath has the <a href="http://www.sagemath.org/doc/constructions/rep_theory.html" target="_blank">character tables of small groups built-in</a>:</p>

<div class="linked">
  
</div>

<p>This just goes to show how important the character of a group is. We can also access individual characters as a functions. Let’s say we want the last one:</p>

<div class="linked">
  
</div>

<p>Notice that the character we were playing with, $[4,2,0,0,0]$, is not in the table. This is because its representation $\rho$  is not irreducible. At the end of the post on <a href="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/" target="_blank">decomposing representations</a>, we saw that $\rho$ splits into two $1$-dimensional irreducible representations and one $2$-dimensional one. It’s not hard to see that the character of $\rho$ is the sum of rows 1,4 and 5 in our character table:</p>

<div class="linked">
  
</div>

<p>Just as we could decompose every representation of $G$ into a sum of irreducible representations, we can express any character as a sum of irreducible characters. </p>

<p>The next post discusses how to do this easily, by making use of the <a href="http://en.wikipedia.org/wiki/Schur_orthogonality_relations">Schur orthogonality relations</a>. These are really cool relations among the rows and columns of the character table. Apart from decomposing representations into irreducibles, we’ll also be able to prove that the character table is always square!</p></div>







<p class="date">
<a href="http://sheaves.github.io/Character-Theory/">March 20, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 19, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/19/playing_stochastic_games_in_class/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/19/playing_stochastic_games_in_class/">Playing stochastic games in class</a></h4>
<div class="entry">
<div class="content">
<p>The final blog post I am late in writing is about the Stochastic game we played in class last week.
The particular type of game I am referring to is also called a Markov game where players play a series of Normal Form games, with the <em>next</em> game being picked from a random distribution the nature of which depends on the strategy profiles.
In other words the choice of the players does not only impact on the utility gained by the players but also on the probability of what the net game will be…
I blogged about <a href="http://drvinceknight.blogspot.co.uk/2014/03/playing-stochasticmarkov-games-in-class.html">this last year</a> so feel free to read about some of the details there.</p>

<p>The main idea is that one stage game corresponds to this normal form game (a prisoner’s dilemma):</p>



<p>at the other we play:</p>



<p>The probability distributions, of the form \((x,1-x)\) where \(x\) is the probability with which we play the first game again are given by:</p>



<p>and the probability distribution for the second game was \((0,1)\).
In essence the second game was an <em>absorption</em> game and so players would try and avoid it.</p>

<p>To deal with the potential for the game to last for ever we played this with a discounting factor \(\delta=1/2\).
Whilst that discounting factor will be interpreted as such in theory, for the purposes of playing the game in class we used that as a probability at which the game continues.</p>

<p>You can see a photo of this all represented on the board:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/markov_game-game.jpg" alt="" /></p>

<p>We played this as a team game and you can see the results here:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/markov_game-results.jpg" alt="" /></p>

<p>As opposed to last year no actual duel lasted more than one round: I had a coded dice to sample at each step.
The first random roll of the dice was to see if the game continued based on the \(\delta\) property (this in effect ‘deals with infinity’).
The second random sample was to find out which game we payed next and if we ever went to the absorption games things finished there.</p>

<p>The winner was team B who in fact defected after the initial cooperation in the first game (perhaps that was enough to convince other teams they would be cooperative).</p>

<p>After playing this, we calculated (using some basic algebra examining each potential pure equilibria) the Nash equilibria for this game and found that there were two pure equilibria: both players Cooperating and both players defecting.</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/19/playing_stochastic_games_in_class/">March 19, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 17, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/gametheory/2015/03/17/incomplete_information_games_in_class/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/gametheory/2015/03/17/incomplete_information_games_in_class/">Incomplete information games in class</a></h4>
<div class="entry">
<div class="content">
<p>Last week my class and I looked at the basics of games with incomplete information.
The main idea is that players do not necessarily know where there are in an extensive form game.
We repeated a game I played last year that you can read about <a href="http://drvinceknight.blogspot.co.uk/2014/03/playing-game-with-incomplete.html">here</a>.</p>

<p>Here is a picture of the game we played (for details take a look at the post from last year):</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/matchingpenniesunderuncertainty.png" alt="" /></p>

<p>We played a round robing where everyone played against everyone else and you can see the results in these two notebook pages that Jason kept track off:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/2015-incomplete-info-game-1.jpg" alt="" />
<img src="http://vknight.org/unpeudemath/assets/images/2015-incomplete-info-game-2.jpg" alt="" /></p>

<p>We see that the winner was Reg, who on both occasions of being the second player: went with the coin.</p>

<p>To find the Nash equilibria for this game we can translate it in to normal form game by doing the following two things:</p>

<ol>
  <li>Identify the strategy sets for the players</li>
  <li>Averaging of the outcome probabilities</li>
</ol>

<p>This gives the following strategies:</p>



<p>and</p>



<p>The strategies for the second player correspond to a 2-vector indexed by the information sets of the second player.
In other words the first letter says what to do if the coin comes up as heads and the second letter says what to do if the coin comes up as tails:</p>

<ol>
  <li>\(HH\): No matter what: play heads;</li>
  <li>\(HT\): If the coin comes up as heads: play heads. If the coin comes up as tails: play tails.</li>
  <li>\(TH\): If the coin comes up as heads: play tails. If the coin comes up as tails: play heads.</li>
  <li>\(TT\): No matter what: play tails;</li>
</ol>

<p>Once we have done that and using the above ordering we can obtain the normal form game representation:</p>



<p>In class we obtained the Nash equilibria for this game by realising that the third column strategy (\(TH\): always disagree with the coin) was dominated and then carrying out some indifference analysis.</p>

<p>Here let us just throw it at Sage (<a href="https://www.youtube.com/watch?v=QjXAvRiU4Og">here is a video showing and explaining some of the code</a>):</p>

<div class="compute"></div>

<p>The equilibria returned confirms what we did in class: the first player can more or less randomly (with bounds on the distribution) pick heads or tails but the second player should always agree with the coin.</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/gametheory/2015/03/17/incomplete_information_games_in_class/">March 17, 2015 12:00 AM</a>
</p>
</div>
</div>




<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/gametheory/2015/03/17/discussing_the_game_theory_of_walking_in_class/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/gametheory/2015/03/17/discussing_the_game_theory_of_walking_in_class/">Discussing the game theory of walking/driving in class</a></h4>
<div class="entry">
<div class="content">
<p>Last week, in game theory class we looked at pairwise contest games.
To introduce this we began by looking at the particular game that one could use to model the situation of two individuals walking or driving towards each other:</p>



<p>The above models people walking/driving towards each other and choosing a side of the road.
If they choose the same side they will not walk/drive in to each other.</p>

<p>I got a coupe of volunteers to simulate this and ‘walk’ towards each other having picked a side.
We very quickly arrived at one of the stage Nash equilibria: both players choosing left and/or choosing right.</p>

<p>I wrote a blog post about this a while ago when the BBC wrote an article about social convention.
You can read that <a href="http://vknight.org/unpeudemath/mathematics/2014/07/27/game-theory-and-pavement-etiquette/">here</a>.</p>

<p>We went on to compute the evolutionary stability of 3 potential stable equilibria:</p>

<ol>
  <li>Everyone driving on the left;</li>
  <li>Everyone driving on the right;</li>
  <li>Everyone randomly picking a side each time.</li>
</ol>

<p>Note that the above corresponds to the three Nash equilibria of the game itself.
You can see this using some Sage code immediately (<a href="https://www.youtube.com/watch?v=QjXAvRiU4Og">here is a video I just put together showing how one can use Sage to obtain Nash equilibria</a>) - just click on ‘Evaluate’:</p>

<div class="compute"></div>

<p>We did this calculations in two ways:</p>

<ol>
  <li>From first principles using the definitions of evolutionary stability (this took a while).
2 Using a clever theoretic result that in effect does the analysis for us once and for all.</li>
</ol>

<p>Both gave us the same result: driving on a given side of the road is evolutionarily stable whereas everyone randomly picking a side is not (a nudge in any given direction would ensure people picked a side).</p>

<p>This kind of corresponds to the two (poorly drawn) pictures below:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/stability.svg" alt="" /></p>

<p>To further demonstrate the instability of the ‘choose a random side’ situation here is a plot of the actual evolutionary process (<a href="https://www.youtube.com/watch?v=Tz-lZy0AKRI">here is a video that shows what is happening</a>):</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/evolution_from_random_walking.png" alt="" /></p>

<p>We see that if we start by walking randomly the tiniest of mutation send everyone to picking a side.</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/gametheory/2015/03/17/discussing_the_game_theory_of_walking_in_class/">March 17, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 12, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Animations/">
<h4><a href="http://sheaves.github.io/Animations/">Animated GIFs</a></h4>
<div class="entry">
<div class="content">
<p>I really should be posting about character theory, but I got distracted making some aesthetic changes to this blog (new icon and favicon!) and creating animations like this:</p>

<p><img src="http://sheaves.github.io/images/harmonograph_loop.gif" alt="harmonograph" /></p>

<!--more-->

<div class="no_out">
  
</div>

<p>I’m not putting this in a SageCell because this could take quite a while, especially if you increase the number of frames (by changing the parameters in <code>srange</code>), but feel free to try it out on your own copy of Sage. It saves an animated GIF that loops forever (<code>iterations = 0</code>) at the location specified by <code>savefile</code>.</p>

<p>For more information, checkout the <a href="http://www.sagemath.org/doc/reference/plotting/sage/plot/animate.html">Sage reference for animated plots</a>.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Animations/">March 12, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 08, 2015</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/08/playing-an-infinitely-repeated-game-in-class/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/08/playing-an-infinitely-repeated-game-in-class/">Playing an infinitely repeated game in class</a></h4>
<div class="entry">
<div class="content">
<p>Following <a href="http://vknight.org/unpeudemath/pedagogy/2015/02/26/this-class-teaches-me-to-not-trust-my-classmates/">the iterated Prisoner’s dilemma tournament my class I and I played last week</a> we went on to play a version of the game where we repeated things infinitely many times.
This post will briefly describe what we got up to.</p>

<p>As you can read in the post about this activity from <a href="http://drvinceknight.blogspot.co.uk/2014/02/iterated-prisoners-dilemma-with-twist.html">last year</a>, the way we play for an infinite amount of time (that would take a while) is to apply a discounting factor \(\delta\) to the payoffs <strong>and</strong> to interpret this factor as the probability with which the game continues.</p>

<p><strong>Before I go any further (and put up pictures with the team names) I need to explain something (for the readers who are not my students).</strong></p>

<p>For every class I teach I insist in spending a fair while going over a mid module feedback form that is used at Cardiff University (asking students to detail 3 things they like and don’t like about the class).
One student wrote (what is probably my favourite piece of feedback ever):</p>

<blockquote>
  <p>“Vince is a dick… but in a good way.”</p>
</blockquote>

<p>Anyway, I mentioned that to the class during my feedback-feedback session and that explains one of the team names (which I found pretty amusing):</p>

<ul>
  <li>Orange</li>
  <li>Where’s the gun</li>
  <li>We don’t know</li>
  <li>Vince is a good dick</li>
</ul>

<p>Once we had the team names set up (and I stopped trying to stop laughing) I wrote some quick Python code that we could run after each iteration:</p>

<div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">random</span>
<span class="n">continue_prob</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span>

<span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">continue_prob</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">'Game continues'</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">'Game Over'</span></code></pre></div>

<p>We started off by playing with (\delta=.5) and here are the results:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/infinite_pd_2015_results.jpg" alt="" /></p>

<p>You can see the various duels here:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/infinite_pd_2015_duels.jpg" alt="" /></p>

<p>As you can see, very little cooperation happened this way and in fact because everyone could see what everyone else was doing Orange took advantage of the last round to create a coalition and win.
We also see one particular duel that cost two teams very highly (because the ‘dice rolls’ did not really help).</p>

<p>After this I suggest to the class that we play again but that no one got to see what was happening to the other teams (this was actually suggested to me by students the year before).
We went ahead with this and used \(delta=.25\): so the game had a less chance of carrying on.</p>

<p>You can see the result and duels here (this had to be squeezed on to a board that could be hidden):</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/infinite_pd_2015_second_game.jpg" alt="" /></p>

<p>Based on the theory we would expect more cooperation to be likely but as you can see this did not happen.</p>

<p>The tie at the end was settled with a game of Rock Paper Scissors Lizard Spock which actually gave place to a rematch of the <a href="http://vknight.org/unpeudemath/pedagogy/2015/02/13/rock-paper-scissors-lizard-spock/">Rock Paper Scissors Lizard Spock tournament</a> we played earlier.
Except this time Laura, lost her crown :)</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/03/08/playing-an-infinitely-repeated-game-in-class/">March 08, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>February 26, 2015</h2>

<div class="channelgroup">







<h3><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/" title="Sébastien Labbé">Sébastien Labbé</a></h3>


<div class="entrygroup" id="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences" lang="en">
<h4><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences">Arnoux-Rauzy-Poincaré sequences</a></h4>
<div class="entry">
<div class="content">
<div class="document">
<p>In a recent article with Valérie Berthé <a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#bl15" id="id1">[BL15]</a>, we provided a multidimensional
continued fraction algorithm called Arnoux-Rauzy-Poincaré (ARP) to construct,
given any vector \(v\in\mathbb{R}_+^3\), an infinite word
\(w\in\{1,2,3\}^\mathbb{N}\) over a three-letter alphabet such that the
frequencies of letters in \(w\) exists and are equal to \(v\) and such that
the number of factors (i.e.  finite block of consecutive letters) of length
\(n\) appearing in \(w\) is linear and less than \(\frac{5}{2}n+1\). We
also conjecture that for almost all \(v\) the contructed word describes a
discrete path in the positive octant staying at a bounded distance from the
euclidean line of direction \(v\).</p>
<p>In Sage, you can construct this word using the next version of my package
slabbe-0.2 (not released yet, email me to press me to finish it). The one with
frequencies of letters proportionnal to \((1, e, \pi)\) is:</p>


<div class="pygments_manni"><pre>sage: from slabbe.mcf import algo
sage: D = algo.arp.substitutions()
sage: it = algo.arp.coding_iterator((1,e,pi))
sage: w = words.s_adic(it, repeat(1), D)
word: 1232323123233231232332312323123232312323...
</pre></div>



<p>The factor complexity is close to 2n+1 and the balance is often less or equal
to three:</p>


<div class="pygments_manni"><pre>sage: w[:10000].number_of_factors(100)
202
sage: w[:100000].number_of_factors(1000)
2002
sage: w[:1000].balance()
3
sage: w[:2000].balance()
3
</pre></div>



<p>Note that bounded distance from the euclidean line almost surely was proven in
<a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#dhs2013" id="id2">[DHS2013]</a> for Brun algorithm, another MCF algorithm.</p>
<p><strong>Other approaches: Standard model and billiard sequences</strong></p>
<p>Other approaches have been proposed to construct such discrete lines.</p>
<p>One of them is the standard model of Eric Andres <a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#a03" id="id3">[A03]</a>. It is also equivalent
to billiard sequences in the cube. It is well known that the factor complexity
of billiard sequences is quadratic \(p(n)=n^2+n+1\) <a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#amst94" id="id4">[AMST94]</a>.
Experimentally, we can verify this. We first create a billiard word of some
given direction:</p>


<div class="pygments_manni"><pre>sage: from slabbe import BilliardCube
sage: v = vector(RR, (1, e, pi))
sage: b = BilliardCube(v)
sage: b
Cubic billiard of direction (1.00000000000000, 2.71828182845905, 3.14159265358979)
sage: w = b.to_word()
sage: w
word: 3231232323123233213232321323231233232132...
</pre></div>



<p>We create some prefixes of \(w\) that we represent internally as <tt class="docutils literal">char*</tt>.
The creation is slow because the implementation of billiard words in my
optional package is in Python and is not that efficient:</p>


<div class="pygments_manni"><pre>sage: p3 = Word(w[:10^3], alphabet=[1,2,3], datatype='char')
sage: p4 = Word(w[:10^4], alphabet=[1,2,3], datatype='char') # takes 3s
sage: p5 = Word(w[:10^5], alphabet=[1,2,3], datatype='char') # takes 32s
sage: p6 = Word(w[:10^6], alphabet=[1,2,3], datatype='char') # takes 5min 20s
</pre></div>



<p>We see below that exactly \(n^2+n+1\) factors of length \(n&lt;20\) appears in
the prefix of length 1000000 of \(w\):</p>


<div class="pygments_manni"><pre>sage: A = ['n'] + range(30)
sage: c3 = ['p_(w[:10^3])(n)'] + map(p3.number_of_factors, range(30))
sage: c4 = ['p_(w[:10^4])(n)'] + map(p4.number_of_factors, range(30))
sage: c5 = ['p_(w[:10^5])(n)'] + map(p5.number_of_factors, range(30)) # takes 4s
sage: c6 = ['p_(w[:10^6])(n)'] + map(p6.number_of_factors, range(30)) # takes 49s
sage: ref = ['n^2+n+1'] + [n^2+n+1 for n in range(30)]
sage: T = table(columns=[A,c3,c4,c5,c6,ref])
sage: T
  n    p_(w[:10^3])(n)   p_(w[:10^4])(n)   p_(w[:10^5])(n)   p_(w[:10^6])(n)   n^2+n+1
+----+-----------------+-----------------+-----------------+-----------------+---------+
  0    1                 1                 1                 1                 1
  1    3                 3                 3                 3                 3
  2    7                 7                 7                 7                 7
  3    13                13                13                13                13
  4    21                21                21                21                21
  5    31                31                31                31                31
  6    43                43                43                43                43
  7    52                55                56                57                57
  8    63                69                71                73                73
  9    74                85                88                91                91
  10   87                103               107               111               111
  11   100               123               128               133               133
  12   115               145               151               157               157
  13   130               169               176               183               183
  14   144               195               203               211               211
  15   160               223               232               241               241
  16   176               253               263               273               273
  17   192               285               296               307               307
  18   208               319               331               343               343
  19   224               355               368               381               381
  20   239               392               407               421               421
  21   254               430               448               463               463
  22   268               470               491               507               507
  23   282               510               536               553               553
  24   296               552               583               601               601
  25   310               596               632               651               651
  26   324               642               683               703               703
  27   335               687               734               757               757
  28   345               734               787               813               813
  29   355               783               842               871               871
</pre></div>



<p>Billiard sequences generate paths that are at a bounded distance from an
euclidean line. This is equivalent to say that the balance is finite. The
balance is defined as the supremum value of difference of the number of
apparition of a letter in two factors of the same length. For billiard
sequences, the balance is 2:</p>


<div class="pygments_manni"><pre>sage: p3.balance()
2
sage: p4.balance() # takes 2min 37s
2
</pre></div>



<p><strong>Other approaches: Melançon and Reutenauer</strong></p>
<p>Melançon and Reutenauer <a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#mr13" id="id5">[MR13]</a> also suggested a method that generalizes
Christoffel words in higher dimension. The construction is based on the
application of two substitutions generalizing the construction of sturmian
sequences. Below we compute the factor complexity and the balance of some of
their words over a three-letter alphabet.</p>
<p>On a three-letter alphabet, the two morphisms are:</p>


<div class="pygments_manni"><pre>sage: L = WordMorphism('1-&gt;1,2-&gt;13,3-&gt;2')
sage: R = WordMorphism('1-&gt;13,2-&gt;2,3-&gt;3')
sage: L
WordMorphism: 1-&gt;1, 2-&gt;13, 3-&gt;2
sage: R
WordMorphism: 1-&gt;13, 2-&gt;2, 3-&gt;3
</pre></div>



<p>Example 1: periodic case \(LRLRLRLRLR\dots\). In this example, the factor
complexity seems to be around \(p(n)=2.76n\) and the balance is at least 28:</p>


<div class="pygments_manni"><pre>sage: from itertools import repeat, cycle
sage: W = words.s_adic(cycle((L,R)),repeat('1'))
sage: W
word: 1213122121313121312212212131221213131213...
sage: map(W[:10000].number_of_factors, [10,20,40,80])
[27, 54, 110, 221]
sage: [27/10., 54/20., 110/40., 221/80.]
[2.70000000000000, 2.70000000000000, 2.75000000000000, 2.76250000000000]
sage: W[:1000].balance()  # takes 1.6s
21
sage: W[:2000].balance()  # takes 6.4s
28
</pre></div>



<p>Example 2: \(RLR^2LR^4LR^8LR^{16}LR^{32}LR^{64}LR^{128}\dots\) taken from
the conclusion of their article. In this example, the factor complexity seems
to be \(p(n)=3n\) and balance at least as high (=bad) as \(122\):</p>


<div class="pygments_manni"><pre>sage: W = words.s_adic([R,L,R,R,L,R,R,R,R,L]+[R]*8+[L]+[R]*16+[L]+[R]*32+[L]+[R]*64+[L]+[R]*128,'1')
sage: W.length()
330312
sage: map(W.number_of_factors, [10, 20, 100, 200, 300, 1000])
[29, 57, 295, 595, 895, 2981]
sage: [29/10., 57/20., 295/100., 595/200., 895/300., 2981/1000.]
[2.90000000000000,
 2.85000000000000,
 2.95000000000000,
 2.97500000000000,
 2.98333333333333,
 2.98100000000000]
sage: W[:1000].balance()  # takes 1.6s
122
sage: W[:2000].balance()  # takes 6s
122
</pre></div>



<p>Example 3: some random ones. The complexity \(p(n)/n\) occillates between 2
and 3 for factors of length \(n=1000\) in prefixes of length 100000:</p>


<div class="pygments_manni"><pre>sage: for _ in range(10):
....:     W = words.s_adic([choice((L,R)) for _ in range(50)],'1')
....:     print W[:100000].number_of_factors(1000)/1000.
2.02700000000000
2.23600000000000
2.74000000000000
2.21500000000000
2.78700000000000
2.52700000000000
2.85700000000000
2.33300000000000
2.65500000000000
2.51800000000000
</pre></div>



<p>For ten randomly generated words, the balance goes from 6 to 27 which is much
more than what is obtained for billiard words or by our approach:</p>


<div class="pygments_manni"><pre>sage: for _ in range(10):
....:     W = words.s_adic([choice((L,R)) for _ in range(50)],'1')
....:     print W[:1000].balance(), W[:2000].balance()
12 15
8 24
14 14
5 11
17 17
14 14
6 6
19 27
9 16
12 12
</pre></div>



<div class="section" id="references">
<h1>References</h1>
<table class="docutils citation" frame="void" id="bl15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#id1">[BL15]</a></td><td>V. Berthé, S. Labbé,
Factor Complexity of S-adic words generated by the Arnoux-Rauzy-Poincaré Algorithm,
<em>Advances in Applied Mathematics</em> 63 (2015) 90-130.
<a class="reference external" href="http://dx.doi.org/10.1016/j.aam.2014.11.001">http://dx.doi.org/10.1016/j.aam.2014.11.001</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dhs2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#id2">[DHS2013]</a></td><td>Delecroix, Vincent, Tomás Hejda, and Wolfgang Steiner. “Balancedness of
Arnoux-Rauzy and Brun Words.” In Combinatorics on Words, 119–31. Springer,
2013. <a class="reference external" href="http://link.springer.com/chapter/10.1007/978-3-642-40579-2_14">http://link.springer.com/chapter/10.1007/978-3-642-40579-2_14</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="a03" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#id3">[A03]</a></td><td>E. Andres,
Discrete linear objects in dimension n: the standard model,
Graphical Models 65 (2003) 92-111.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="amst94" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#id4">[AMST94]</a></td><td>P. Arnoux, C. Mauduit, I. Shiokawa, J. I. Tamura,
Complexity of sequences defined by billiards in the cube,
Bull. Soc. Math. France 122 (1994) 1-12.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="mr13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences#id5">[MR13]</a></td><td>G. Melançon, C. Reutenauer,
On a class of Lyndon words extending Christoffel words and related to a
multidimensional continued fraction algorithm.
J. Integer Seq. 16, No. 9, Article 13.9.7, 30 p., electronic only (2013).
<a class="reference external" href="https://cs.uwaterloo.ca/journals/JIS/VOL16/Reutenauer/reut3.html">https://cs.uwaterloo.ca/journals/JIS/VOL16/Reutenauer/reut3.html</a></td></tr>
</tbody>
</table>
</div>
</div></div>







<p class="date">
<a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2015/02/arnoux-rauzy-poincare-sequences">by Sébastien Labbé at February 26, 2015 04:22 PM</a>
</p>
</div>
</div>



</div>
<div class="channelgroup">







<h3><a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a></h3>


<div class="entrygroup" id="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/02/26/this-class-teaches-me-to-not-trust-my-classmates/">
<h4><a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/02/26/this-class-teaches-me-to-not-trust-my-classmates/">This class teaches me to not trust my classmates: An iterated prisoners dilemma in class</a></h4>
<div class="entry">
<div class="content">
<p>On Monday, in class we played an iterated prisoner’s dilemma tournament.
I have done this many times (both in outreach events with <a href="http://www.profpaulharper.com/">Paul Harper</a> and in this class).
This is always a lot of fun but none more so than last year when Paul’s son Thomas joined us.
You can read about that one <a href="http://drvinceknight.blogspot.co.uk/2014/02/iterated-prisoners-dilemma-tournament.html">here</a>.</p>

<p>The format of the game is as close to that of Axelrod’s original tournament as I think it can be.
I split the class in to 4 teams and we create a round robin where each team plays every other team at 8 consecutive rounds of the prisoner’s dilemma:</p>



<p>The utilities represent ‘years in prison’ and over the 3 matches that each team will play (against every other team) the goal is to reduce the total amount of time spent in prison.</p>

<p>Here are some photos from the game:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/pd_2015_01.jpg" alt="" /></p>

<p><img src="http://vknight.org/unpeudemath/assets/images/pd_2015_02.jpg" alt="" /></p>

<p><img src="http://vknight.org/unpeudemath/assets/images/pd_2015_03.jpg" alt="" /></p>

<p>Here are the scores:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/pd_2015_results.jpg" alt="" /></p>

<p>We see that ‘We will take the gun’ acquired the least total score and so they won the collection of cookies etc…</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/pd_2015_cookies.jpg" alt="" /></p>

<p>(The names followed a promise from me to let the team with the coolest name have a nerf gun… Can’t say this had the wanted effect…)</p>

<p>At one point during the tournament, one team actually almost declared a strategy which was cool:</p>

<blockquote>
  <p>We will cooperate until you defect at which point we will reevaluate</p>
</blockquote>

<p>This was pretty cool as I hadn’t discussed at all what a strategy means in a repeated game (ie I had not discussed the fact that a strategy in a repeated game takes count of both play histories).</p>

<p>Here are all the actual duels:</p>

<p><img src="http://vknight.org/unpeudemath/assets/images/pd_2015_duels.jpg" alt="" /></p>

<p>You’ll also notice at the end that a coalition formed and one team agreed to defect so that they could share the prize.
This happens about 50% of the time when we play this game but I never cease to be amused by it.
Hopefully everyone found this fun and perhaps some even already agree with a bit of feedback I received on this course last year:</p>

<blockquote>
  <p>‘This class teaches me to not trust my classmates’</p>
</blockquote>

<p>One of the other really cool things that happened after this class was H asking for a hand to submit a strategy to my Axelrod repository.
She built a strategy called ‘Once Bitten’ that performs pretty well!
You can see it <a href="https://github.com/drvinceknight/Axelrod/blob/master/axelrod/strategies/oncebitten.py">here</a> (click on ‘Blame’ and you can see the code that she wrote).</p>

<p>(Big thanks to Jason for keeping track of the scores and to Geraint for helping and grabbing some nice pictures)</p></div>







<p class="date">
<a href="http://drvinceknight.github.io/unpeudemath/pedagogy/2015/02/26/this-class-teaches-me-to-not-trust-my-classmates/">February 26, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>February 15, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Group-Ring-Regular-Representation/">
<h4><a href="http://sheaves.github.io/Group-Ring-Regular-Representation/">The Group Ring and the Regular Representation</a></h4>
<div class="entry">
<div class="content">
<p>In the <a href="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/" target="_blank">previous post</a>, we saw how to decompose a given group representation into irreducibles. But we still don’t know much about the irreducible representations of a (finite) group. What do they look like? How many are there? Infinitely many?</p>

<p>In this post, we’ll construct the <a href="http://en.wikipedia.org/wiki/Group_ring" target="_blank">group ring</a> of a group. Treating this as a vector space, we get the <a href="http://en.wikipedia.org/wiki/Regular_representation" target="_blank">regular representation</a>, which turns out to contain <em>all</em> the irreducible representations of $G$!</p>

<!--more-->

<h2 id="the-group-ring-fg">The group ring $FG$</h2>

<p>Given a (finite) group $G$ and a field $F$, we can treat each element of $G$ as a basis element of a vector space over $F$. The resulting vector space generated by $g \in G$ is</p>



<p>Let’s do this is Sage with the group $G = D_4$ and the field $F = \mathbb{Q}$:</p>

<p><em>(The Sage cells in this post are linked, so things may not work if you don’t execute them in order.)</em></p>

<div class="linked">
  
</div>

<p>We can view $v \in FG$ as vector in $F^n$, where $n$ is the size of $G$ : </p>

<div class="linked">
  
</div>

<p>Here, we’re treating each $g \in G$ as a basis element of $FG$</p>

<div class="linked">
  
</div>

<p>Vectors in $FG$ are added component-wise:</p>



<div class="linked">
  
</div>

<h2 id="multiplication-as-a-linear-transformation">Multiplication as a linear transformation</h2>

<p>In fact $FG$ is also a  <em>ring</em> (called the <a href="http://en.wikipedia.org/wiki/Group_ring" target="_blank"><strong>group ring</strong></a>), because we can multiply vectors using the multiplication rule of the group $G$:</p>



<div class="linked">
  
</div>

<p>That wasn’t very illuminating. However, treating multiplication by $v \in FG$ as a function</p>



<p>one can check that each $T_v$ is a linear transformation! We can thus represent $T_v$ as a matrix whose columns are $T_v(g), g \in G$:</p>

<div class="linked">
  
</div>

<h2 id="the-regular-representation">The regular representation</h2>

<p>We’re especially interested in $T_g, g \in G$. These are invertible, with inverse $T_{g^{-1}}$, and their matrices are all permutation matrices, because multiplying by $g \in G$ simply permutes elements of $G$:</p>

<div class="linked">
  
</div>

<p>Define a function $\rho_{FG}$ which assigns to each $g\in G$ the corresponding $T_g$:</p>



<p>Then $(FG,\rho_{FG})$ is the <a href="http://en.wikipedia.org/wiki/Regular_representation" target="_blank"><strong>regular representation</strong></a> of $G$ over $F$. </p>

<p>The regular representation of any non-trivial group is not irreducible. In fact, it is a direct sum of <em>all</em> the irreducible representations of $G$! What’s more, if $(V,\rho)$ is an irreducible representation of $G$ and $\dim V = k$, then $V$ occurs $k$ times in the direct-sum decomposition of $FG$!</p>

<p>Let’s apply the decomposition algorithm in the <a href="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/" target="_blank">previous post</a> to $(FG,\rho_{FG})$ (this might take a while to run):</p>

<div class="sage">
  
</div>

<p>So the regular representation of $D_4$ decomposes into four (distinct) $1$-dim representations and two (isomorphic) $2$-dim ones.</p>

<h2 id="building-character">Building character</h2>

<p>We’ve spent a lot of time working directly with representations of a group. While more concrete, the actual matrix representations themselves tend to be a little clumsy, especially when the groups in question get large. </p>

<p>In the next few posts, I’ll switch gears to <a href="http://en.wikipedia.org/wiki/Character_theory" target="_blank">character theory</a>, which is a simpler but more powerful way of working with group representations.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Group-Ring-Regular-Representation/">February 15, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>February 02, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/">
<h4><a href="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/">Decomposing Representations</a></h4>
<div class="entry">
<div class="content">
<p>In this post, we’ll implement an algorithm for decomposing representations that <a href="http://www.ams.org/journals/mcom/1970-24-111/S0025-5718-1970-0280611-6/S0025-5718-1970-0280611-6.pdf" target="_blank">Dixon published in 1970</a>.</p>

<!--more-->

<p>As a motivating example, I’ll use the permutation matrix representation of $D_4$ that we saw in an <a href="http://sheaves.github.io/Representation-Theory-Intro/" target="_blank">earlier post</a>. To make the code more generally applicable, let’s call the group $G$ and the representation $\rho$:</p>

<p><em>(The Sage cells in this post are linked, so things may not work if you don’t execute them in order.)</em></p>

<div class="linked">
  
</div>

<p>We’ll see that this is decomposable, and find out what its irreducible components are.</p>

<h3 id="unitary-representations">Unitary representations</h3>

<p>A short remark before we begin: The algorithm assumes that $\rho$ is a <a href="http://en.wikipedia.org/wiki/Unitary_representation" target="_blank">unitary representation</a></p>

<p>i.e. for all $g \in G$,</p>



<p>where $A*$ is the <a href="http://en.wikipedia.org/wiki/Conjugate_transpose" target="_blank">conjugate transpose</a> of a matrix $A$. 
For $G$ a finite group, all representations can be made unitary under an appropriate change of basis, so we need not be too concerned about this. In any case, permutation representations are always unitary, so we can proceed with our example.</p>

<h2 id="finding-non-scalar-commuting-matrices">Finding non-scalar, commuting matrices</h2>

<p>At the end of the <a href="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/" target="_blank">previous post</a> we saw that in order to decompose a representation $(V,\rho)$, it is enough to find a non-scalar matrix $T$ that commutes with $\rho(g)$ for every $g \in G$.  This first step finds a <a href="http://en.wikipedia.org/wiki/Hermitian_matrix" target="_blank">Hermitian</a> non-scalar $H$ that commutes with $\rho(G)$ (if there is one to be found).</p>

<p>Let $E_{rs}$ denote the $n \times n$ matrix with a $1$ in the $(r,s)$th entry and zeros everywhere else. Here $n$ is the dimension of $V$ in the representation $(V,\rho)$. Define</p>



<p>then the set of matrices $H_{rs}$ forms a Hermitian basis for the $n \times n$ matrices over $\mathbb{C}$.</p>

<p>Now for each $r,s$, compute the sum</p>



<p>Observe that $H$ has the following properties:</p>

<ul>
  <li>it is hermitian</li>
  <li>it commutes with $\rho(g)$ for all $g \in G$</li>
</ul>

<p>If $\rho$ is irreducible, then $H$ is a scalar matrix for all $r,s$. Otherwise, it turns out that there <strong>will</strong> be some $r,s$ such that $H$ is non-scalar (this is due to the fact that the $H_{rs}$ matrices form a basis of the $n \times n$ matrices$).</p>

<p>Let’s test this algorithm on our permutation representation of $D_4$:</p>

<div class="linked">
  
</div>

<p>We get a non-scalar $H$! So the permutation representation of $D_4$ is reducible!</p>

<h2 id="using-h-to-decompose-rho">Using $H$ to decompose $\rho$</h2>

<p>Our next step is to use the eigenspaces of $H$ to decompose $\rho$. At the end of the <a href="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/" target="_blank">previous post</a>, we saw that $\rho(g)$ preserves the eigenspaces of $H$, so we need only find the eigenspaces of $H$ to decompose $\rho$. </p>

<p>Since $H$ is hermitian, it is <a href="http://en.wikipedia.org/wiki/Diagonalizable_matrix" target="_blank">diagonalizable</a>, so its eigenvectors form a basis of $V$. We can find this basis by computing the <a href="http://en.wikipedia.org/wiki/Jordan_normal_form" target="_blank">Jordan decomposition</a> of $H$:</p>

<div class="linked">
  
</div>

<p>Finally, we observe that $P^{-1} \rho(g) P$ has the same block-diagonal form for each $g \in G$:</p>

<div class="linked">
  
</div>

<p>We have thus decomposed $\rho$ into two 1-dimensional representations and one 2-dimensional one! </p>

<h2 id="decomposing-into-irreducibles">Decomposing into irreducibles</h2>

<p>Finally, to get a decomposition into irreducibles,  we can apply the algorithm recursively on each of the subrepresentations to see if they further decompose. </p>

<p>Here’s a stand-alone script that decomposes a representation into its irreducible components:</p>

<div class="sage">
  
</div>

<h2 id="getting-all-irreducible-representations">Getting all irreducible representations</h2>

<p>Now we know how to test for irreducibility and decompose reducible representations. But we still don’t know how many irreducible representations a group has. </p>

<p>It turns out that finite groups have finitely many irreducible representations! In the <a href="http://sheaves.github.io/Group-Ring-Regular-Representation/">next post</a>, we’ll construct a representation for any finite group $G$ that contains <em>all</em> the irreducible representations of $G$.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/">February 02, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>January 26, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/">
<h4><a href="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/">Irreducible and Indecomposable Representations</a></h4>
<div class="entry">
<div class="content">
<p>Following up from the questions I asked at the end of the <a href="http://sheaves.github.io/Representation-Theory-Sums-Products/" target="_blank">previous post</a>, I’ll define (ir)reducible and (in)decomposable representations, and discuss how we might detect them. Unlike previous posts, this post will have just text, and no code. This discussion will form the basis of the algorithm in the next post.</p>

<!--more-->

<h2 id="decomposability">Decomposability</h2>

<p>In the previous post, I showed how to form the direct sum $(V_1 \oplus V2,\rho)$ of two representations $(V_1,\rho_1)$ and $(V_2,\rho_2)$. The matrices given by $\rho$ looked like this:</p>



<p>A representation $(V,\rho)$ is <strong>decomposable</strong> if there is a basis of $V$ such that each $\rho(g)$ takes this block diagonal form. If $(V,\rho)$ does not admit such a decomposition, it is <strong>indecomposable</strong>.</p>

<p>Equivalently, $(V,\rho)$ is decomposable if there is an invertible matrix $P$ such that for all $g\in G$,</p>



<p>and indecomposable otherwise. Here, $P$ is a change of basis matrix and conjugating by $P$ changes from the standard basis to the basis given by the columns of $P$. </p>

<h2 id="reducibility">Reducibility</h2>

<p>Notice that if $\rho(g)$ were block diagonal, then writing $v \in V$ as ${v_1 \choose v_2}$, where $v_1$ and $v_2$ are vectors whose dimensions agree with the blocks of $\rho(g)$, we see that</p>



<p>Let $V_1$ be the subspace of $V$ corresponding to vectors of the form ${v_1 \choose 0}$, and $V_2$ be the subspace of vectors of the form ${0 \choose v_2}$. Then for all $g \in G, v \in V_i$,</p>



<p>Now suppose instead that for all $g \in G, \rho(g)$ has the block upper-triangular form</p>



<p>where $ * $ represents an arbitrary matrix (possibly different for each $g \in G$). If $*$ is not the zero matrix for some $g$, then we will still have $\rho(g) v \in V_1 \,\, \forall v \in V_1$, but we no longer have $\rho(g) v \in V_2 \,\, \forall v \in V_2$. In this case, we say that $V_1$ is a subrepresentation of $V$ whereas $V_2$ is not.</p>

<p>Formally, if we have a subspace $W \subset V$ such that for all $g \in G, w \in W$,</p>



<p>then $W$ is a $G$-<strong>invariant</strong> subspace of $V$, and $(W,\rho)$ is a  <strong>subrepresentation</strong> of $(V,\rho)$.</p>

<p>Any representation $(V,\rho)$ has at least two subrepresentations: $(0,\rho)$ and $(V,\rho)$. If there are no other subrepresentations, then $(V,\rho)$ is <a href="http://en.wikipedia.org/wiki/Irreducible_representation" target="_blank"><strong>irreducible</strong></a>. Otherwise, it is <strong>reducible</strong>.</p>

<p>Equivalently, $(V,\rho)$ is reducible if there is an invertible matrix $P$ such that for all $g \in G$,</p>



<p>and irreducible otherwise.</p>

<h2 id="maschkes-theorem">Maschke’s Theorem</h2>

<p>Note that a decomposable representation is also reducible, but the converse is not generally true.
(Equivalently: an irreducible representation is also indecomposable, but the converse is not generally true.)
<a href="http://en.wikipedia.org/wiki/Maschke%27s_theorem" target="_blank">Maschke’s Theorem</a> tells us that the converse is true over fields of characteristic zero! In other words:</p>

<blockquote>
  <p>Suppose $V$ is a vector space over a field of characteristic zero, say $\mathbb{C}$, and $(V,\rho)$ has a subrepresentation $(W_1,\rho)$. Then there is a subspace $W_2$ (called the direct complement of $W_1$) such that $V = W_1 \oplus W_2$.</p>
</blockquote>

<p>Since we will be working over $\mathbb{C}$, we can thus treat (in)decomposability as equivalent to (ir)reducibility. To understand representations of $G$, we need only understand its irreducible representations, because any other representation can be decomposed into a direct sum of irreducibles.</p>

<h2 id="schurs-lemma">Schur’s Lemma</h2>

<p>How may we detect (ir)reducible representations? We’ll make use of the following linear algebraic properties:</p>

<p>Given an eigenvalue $\lambda$ of a matrix $A \in \mathbb{C}^{n \times n}$, its $\lambda$-eigenspace is</p>



<p>Clearly, each eigenspace is an invariant subspace of $A$. If we have another matrix $B \in \mathbb{C}^{n \times n}$ such that $AB = BA$, then $B$ preserves the eigenspaces of $A$ as well. To see this, take $v \in E_\lambda$, then</p>



<p>so $E_\lambda$ is also an invariant subspace of $B$!</p>

<p>Now suppose we have a representation $(V,\rho)$ and a linear map $T:V \to V$ such that for all $g \in G, v \in V$,</p>



<p>Treating $T$ as a matrix, this is equivalent to saying that $\rho(g)T = T\rho(g)$ for all $g \in G$. In that case, the eigenspaces of $T$ are $G$-invariant subspaces, and will yield decompositions of $(V,\rho)$  if they are not the whole of $V$. But if $E_\lambda = V$, then $Tv = \lambda v$ for all $v \in V$, so in fact $T = \lambda I$, where $I$ is the identity matrix. We have thus shown a variant of <a href="http://en.wikipedia.org/wiki/Schur%27s_lemma" target="_blank">Schur’s lemma</a>:</p>

<blockquote>
  <p>If $(V,\rho)$ is irreducible, and $\rho(g) T = T \rho(g)$ for all $g \in G$, then $T =\lambda I$ for some $\lambda$.</p>
</blockquote>

<p>We already know that scalar matrices (i.e. matrices of the form $\lambda I$) commute with all matrices. If $(V,\rho)$ is irreducible, this result says that there are no other matrices that commute with all $\rho(g)$. The converse is also true:</p>

<blockquote>
  <p>If $(V,\rho)$ is a reducible, then there is some $T \neq \lambda I$ such that $\rho(g) T = T\rho(g)$ for all $g \in G$.</p>
</blockquote>

<p>I won’t prove this, but note that if $V$ has a decomposition $W_1 \oplus W_2$, then the projection onto either $W_i$ will have the desired properties.  If we have such a $T$, then its eigenspaces will give a decomposition of $(V,\rho)$. This will be the subject of the <a href="http://sheaves.github.io/Representation-Theory-Decomposing-Representations/">next post</a>.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/">January 26, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>January 24, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Representation-Theory-Sums-Products/">
<h4><a href="http://sheaves.github.io/Representation-Theory-Sums-Products/">Direct Sums and Tensor Products</a></h4>
<div class="entry">
<div class="content">
<p>In this short post, we will show two ways of combining existing representations to obtain new representations.</p>

<!--more-->

<h2 id="recall">Recall</h2>
<p>In the <a href="http://sheaves.github.io/Representation-Theory-Intro/" target="_blank">previous post</a>, we saw two representations of $D_4$: the permutation representation, and the representation given in this <a href="http://en.wikipedia.org/wiki/Dihedral_group#Matrix_representation" target="_blank">Wikipedia example</a>. Let’s first define these in Sage:</p>

<p><em>(The Sage cells in this post are linked, so things may not work if you don’t execute them in order.)</em></p>

<div class="linked">
  
</div>

<h2 id="direct-sums">Direct Sums</h2>

<p>If $(V_1,\rho_1), (V_2,\rho_2)$ are representations of $G$, the <a href="http://groupprops.subwiki.org/wiki/Direct_sum_of_linear_representations" target="_blank">direct sum</a> of these representations is $(V_1 \oplus V_2, \rho)$, where $\rho$ sends $g \in G$ to the <a href="http://en.wikipedia.org/wiki/Block_matrix#Block_diagonal_matrices" target="_blank">block diagonal matrix</a> </p>



<p>Here $\rho_1(g), \rho_2(g)$ and the “zeros” are all <em>matrices</em>.</p>

<p>It’s best to illustrate with an example. We can define a function <code>direct_sum</code> in Sage that takes two representations and returns their direct sum.</p>

<div class="linked">
  
</div>

<h2 id="tensor-products">Tensor products</h2>
<p>We can also form the <a href="http://groupprops.subwiki.org/wiki/Tensor_product_of_linear_representations" target="_blank">tensor product</a> $(V_1 \otimes V_2,\rho)$, where $\rho$ sends $g \in G$ to the <a href="http://en.wikipedia.org/wiki/Kronecker_product" target="_blank">Kronecker product</a> of the matrices $\rho_1(g)$ and $\rho_2(g)$.</p>

<p>We define a function <code>tensor_prod</code> that takes two representations and returns their tensor product.</p>

<div class="linked">
  
</div>

<p>Observe that</p>

<ul>
  <li>$\dim V_1 \oplus V_2 = \dim V_1 + \dim V_2$,</li>
  <li>$\dim V_1 \otimes V_2 = \dim V_1 \times \dim V_2$,</li>
</ul>

<p>which motivates the terms direct <em>sum</em> and tensor <em>product</em>.</p>

<p>We can keep taking direct sums and tensor products of existing representations to obtain new ones:</p>

<div class="linked">
  
</div>

<h2 id="decomposing-representations">Decomposing representations</h2>
<p>Now we know how to build new representations out of old ones. One might be interested in the inverse questions: </p>

<ol>
  <li>Is a given representation a direct sum of smaller representations?</li>
  <li>Is a given representation a tensor product of smaller representations?</li>
</ol>

<p>It turns out that Q1 is a much more interesting question to ask than Q2.</p>

<p>A (very poor) analogy of this situation is the problem of “building up” natural numbers. We have two ways of building up new integers from old: we can either add numbers, or multiply them. Given a number $n$, it’s easy (and not very interesting) to find smaller numbers that add up to $n$. However, <a href="http://en.wikipedia.org/wiki/Integer_factorization" target="_blank">finding numbers whose product is $n$</a> is <em>much much</em> harder (especially for large $n$) and much more <a href="http://en.wikipedia.org/wiki/Algebraic_number_theory" target="_blank">rewarding</a>. Prime numbers also play a special role in the latter case: every positive integer has a unique factorization into primes.</p>

<p>The analogy is a poor one (not least because the roles of “sum” and “product” are switched!). However, it motivates the question </p>

<ul>
  <li>What are the analogues of “primes” for representations?</li>
</ul>

<p>We’ll try to answer this last question and Q1 in the <a href="http://sheaves.github.io/Representation-Theory-Irreducibility-Indecomposability/">next few posts</a>, and see what it means for us when working with representations in Sage.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Representation-Theory-Sums-Products/">January 24, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>January 20, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Representation-Theory-Intro/">
<h4><a href="http://sheaves.github.io/Representation-Theory-Intro/">Representation Theory in Sage - Basics</a></h4>
<div class="entry">
<div class="content">
<p>This is the first of a series of posts about working with group representations in Sage.</p>

<!--more-->

<h2 id="basic-definitions">Basic Definitions</h2>

<p>Given a group $G$, a linear representation of $G$ is a group homomorphism $\rho: G \to \mathrm{GL}(V)$ 
such that </p>



<p>For our purposes, we will assume that $G$ is a finite group and $V$ is an $n$-dimensional vector space over $\mathbb{C}$. Then $\mathrm{GL}(V)$ is isomorphic to the invertible $n \times n$ matrices over $\mathbb{C}$, which we will denote $\mathrm{GL}_n \mathbb{C}$. </p>

<p>So a representation is just a function that takes group elements and returns invertible matrices, in such a way that the above equation holds.</p>

<p>Various authors refer to the map $\rho$, the vector space $V$, or the tuple $(V,\rho)$ as a representation; this shouldn’t cause any confusion, as it’s usually clear from context whether we are referring to a map or a vector space. When I need to be extra precise, I’ll use $(V,\rho)$.</p>

<h2 id="some-simple-examples">Some simple examples</h2>

<h3 id="trivial-representation">Trivial representation</h3>
<p>The simplest representation is just the trivial representation that sends every element of $G$ to the identity matrix (of some fixed dimension $n$). Let’s do this for the symmetric group $S_3$:</p>

<p><em>(The Sage cells in this post are linked, so things may not work if you don’t execute them in order.)</em></p>

<div class="linked">
  
</div>

<p>We can verify that this is indeed a group homomorphism (warning: There are 6 elements in $S_3$, which means we have to check $6^2 = 36$ pairs!):</p>

<div class="linked">
  
</div>

<h3 id="permutation-representation">Permutation representation</h3>
<p>This isn’t very interesting. However, we also know that $S_3$ is the group of permutations of the 3-element set {$1,2,3$}. We can associate to each permutation a <a href="http://mathworld.wolfram.com/PermutationMatrix.html" target="_blank">permutation matrix</a>. Sage already has this implemented for us, via the method <code>matrix()</code> for a group element <code>g</code>:</p>

<div class="linked">
  
</div>

<p><em>Qn: From the permutation matrix, can you tell which permutation $g$ corresponds to?</em></p>

<p>We can again verify that this is indeed a representation. Let’s not print out all the output; instead, we’ll only print something if it is <em>not</em> a representation. If nothing pops up, then we’re fine:</p>

<div class="linked">
  
</div>

<h3 id="defining-a-representation-from-generators">Defining a representation from generators</h3>
<p>We could define permutation representations so easily only because Sage has them built in. But what if we had some other representation that we’d like to work with in Sage? Take the <a href="http://en.wikipedia.org/wiki/Dihedral_group" target="_blank">dihedral group</a> $D_4$. Wikipedia tells us that this group has <a href="http://en.wikipedia.org/wiki/Dihedral_group#Matrix_representation" target="_blank">a certain matrix representation</a>. How can we recreate this in Sage?</p>

<p>We could hard-code the relevant matrices in our function definition. However, typing all these matrices can be time-consuming, especially if the group is large.</p>

<p>But remember that representations are group homomorphisms. If we’ve defined $\rho(g)$ and $\rho(h)$, then we can get $\rho(gh)$ simply by multiplying the matrices $\rho(g)$ and $\rho(h)$! If we have a <a href="http://en.wikipedia.org/wiki/Generating_set_of_a_group" target="_blank">set of generators</a> of a group, then we only need to define $\rho$ on these generators. Let’s do that for the generators of $D_4$:</p>

<div class="linked">
  
</div>

<p>We see that $D_4$ has a generating set of 2 elements (note: the method <code>gens()</code> need not return a <em>minimal</em> generating set, but in this case, we do get a minimal generating set). Let’s call these $r$ and $s$. We know that elements of $D_4$ can be written $r^is^j$, where $i = 0,1,2,3$ and $j = 0,1$. We first run through all such pairs $(i,j)$ to create a <a href="https://docs.python.org/2/tutorial/datastructures.html#dictionaries" target="_blank">dictionary</a> that tells us which group elements are given by which $(i,j)$:</p>

<div class="linked">
  
</div>

<p>Now for $g = r^i s^j \in D_4$, we can define $\rho(g) = \rho(r)^i \rho(s)^j$ and we will get a representation of $D_4$. We need only choose the matrices we want for $\rho(r)$ and $\rho(s)$.</p>

<p>$r$ and $s$ correspond to $R_1$ and $S_0$, resp., in the <a href="http://en.wikipedia.org/wiki/Dihedral_group#Matrix_representation" target="_blank">Wikipedia example</a>, so let’s use their matrix representations to generate our representation:</p>

<div class="linked">
  
</div>

<p>One can verify that this does indeed give the same matrices as the Wikipedia example, albeit in a different order.</p>

<h2 id="we-can-do-better">We can do better!</h2>
<p>All the representations we’ve defined so far aren’t very satisfying! For the last example, we required the special property that all elements in $D_4$ have the form $r^i s^j$. In general, it isn’t always easy to express a given group element in terms of the group’s generators (this is known as the <a href="http://en.wikipedia.org/wiki/Word_problem_for_groups" target="_blank">word problem</a>).</p>

<p>We’ve also been constructing representations in a rather ad-hoc manner. Is there a more general way to construct representations? And how many are representations are there?</p>

<p>In the <a href="http://sheaves.github.io/Representation-Theory-Sums-Products/">next post</a>, I’ll run through two simple ways of combining existing representations to get new ones: the direct sum and the tensor product. I’ll also define <em>irreducible</em> representations, and state some results that will shed some light on the above questions.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Representation-Theory-Intro/">January 20, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>January 17, 2015</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Subgroup-Explorer/">
<h4><a href="http://sheaves.github.io/Subgroup-Explorer/">Subgroup Explorer</a></h4>
<div class="entry">
<div class="content">
<p><img src="http://sheaves.github.io/images/SubgroupExplorer.png" alt="Subgroup Explorer" title="Subgroup Lattice Generator" /></p>

<p>I’ve written a subgroup lattice generator for all groups of size up to 32. It’s powered by Sage and GAP, and allows you to view the lattice of subgroups or subgroup conjugacy classes of a group from your browser.</p>

<!--more-->
<p>Click <strong>Go!</strong> below to refresh the viewer, or if it doesn’t load.</p>

<div class="go">
  
</div>

<p><a href="http://en.wikipedia.org/wiki/Normal_subgroup" target="_blank">Normal subgroups</a> are colored green. Additionally, the <a href="http://en.wikipedia.org/wiki/Center_%28group_theory%29" target="_blank">center</a> is blue while the <a href="http://en.wikipedia.org/wiki/Commutator_subgroup" target="_blank">commutator subgroup</a> is pink.</p>

<p>Showing the full subgroup lattice can get messy for large groups. If the option <code>Conjugacy classes of subgroups</code> is selected, the viewer only shows the <a href="http://en.wikipedia.org/wiki/Conjugacy_class#Conjugacy_of_subgroups_and_general_subsets" target="_blank">conjugacy classes of subgroups</a> (i.e. all subgroups that are conjugate are combined into a single vertex).</p>

<p>The edge labels indicate how many subgroups of one conjugacy class a given representative subgroup of another conjugacy class <strong>contains</strong>, or how many subgroups of one conjugacy class a given representative subgroup of another conjugacy class is <strong>contained by</strong>. The labels are omitted if these numbers are 1. The edge colors indicate whether the subgroups in the “smaller” conjugacy class are normal subgroups of those in “larger” conjugacy class.</p>

<p>In the image at the top of the post, the group <code>C15 : C4</code> (the colon stands for <a href="http://en.wikipedia.org/wiki/Semidirect_product" target="_blank">semi-direct product</a> and is usually written $\rtimes$) contains 5 subgroups isomorphic to <code>C3 : C4</code>, which in turn contains 3 subgroups isomorphic to <code>C4</code> and 1 subgroup isomorphic to <code>C6</code> (the 5 belows to another edge). The edge colors indicate that <code>C6</code> is a normal subgroup of <code>C3 : C3</code> whereas <code>C4</code> is not. For further information on group descriptors, click <a href="http://groupprops.subwiki.org/wiki/GAP:StructureDescription#Aspects_of_structure_description" target="_blank">here</a>.</p>

<p>And here’s the code for a version that you can run on <a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a>. It allows you to input much larger groups. This was used to produce the image at the top of the post. Don’t try running it here, however, since the SageCellServer doesn’t have the <code>database_gap</code> package installed.</p>

<div class="no_eval">
  
</div>

<p>Finally, while verifying the results of this program, I found an error in <a href="http://www.cambridge.org/us/academic/subjects/mathematics/algebra/representations-groups-computational-approach" target="_blank">this book</a>!
The correction has been pencilled in. The original number printed was 1.
<img src="http://sheaves.github.io/images/A5Lattice_CompareSmall.jpg" alt="A5 Lattice" title="A5 Subgroup Lattice" /></p></div>







<p class="date">
<a href="http://sheaves.github.io/Subgroup-Explorer/">January 17, 2015 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>December 27, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Subgroup-Lattice-Edges/">
<h4><a href="http://sheaves.github.io/Subgroup-Lattice-Edges/">Lattice of Subgroups III - Coloring Edges</a></h4>
<div class="entry">
<div class="content">
<p>This post will cover the coloring of edges in the lattice of subgroups of a group. </p>

<p><img src="http://sheaves.github.io/images/C3semiC8.png" alt="Lattice of subgroups of $C3:C8$" /></p>

<!--more-->

<p>Coloring edges is almost as simple as <a href="http://sheaves.github.io/Subgroup-Lattice-Color-Vertices/">coloring vertices</a>, so we’ll start with that. </p>

<h2 id="generating-small-groups">Generating small groups</h2>
<p>As we’ve done in previous posts, let’s start by choosing a group and generate its lattice of subgroups. This can be done by referring to this list of <a href="http://www.sagemath.org/doc/constructions/groups.html#construction-instructions-for-every-group-of-order-less-than-32">constructions for every group of order less than 32 </a>. These instructions allow us to construct every group on Wikipedia’s <a href="http://en.wikipedia.org/wiki/List_of_small_groups">list of small groups</a>! </p>

<p>For this post, we’ll use $G = C_3 \rtimes C_8$ (or $\mathbb{Z}_3 \rtimes \mathbb{Z}_8$). First, we’ll generate $G$ and display it’s poset of subgroups. For simplicity, we’ll label by cardinality, and we won’t color the vertices.</p>

<p><em>(The Sage cells in this post are linked, so things may not work if you don’t execute them in order.)</em></p>

<div class="linked">
  
</div>

<h2 id="coloring-edges">Coloring edges</h2>
<p>In the <a href="http://sheaves.github.io/Subgroup-Lattice-Color-Vertices/">previous post</a>, we colored vertices according to whether the corresponding subgroup was normal (or abelian, or a Sylow subgroup, etc.) These are properties that depend only on each individual subgroup.</p>

<p>However, suppose we want to see the subnormal series of the group. A <a href="http://en.wikipedia.org/wiki/Subgroup_series#Normal_series.2C_subnormal_series">subnormal series</a> is a series of subgroups where each subgroup is a normal subgroup of the next group in the series. Checking whether a particular series of subgroups is a subnormal series requires checking <em>pairs</em> of subgroups to see whether one is a normal subgroup of the other. This suggests that we color <em>edges</em> according to whether one of its endpoints is a normal subgroup of the other endpoint.</p>

<p>The edges of the <a href="http://en.wikipedia.org/wiki/Hasse_diagram">Hasse diagram</a> of a poset are the pairs $(h,k)$ where $h$ is <a href="http://en.wikipedia.org/wiki/Covering_relation">covered by</a> $k$ in the poset. This means that $h &lt; k$, with nothing else in between. We thus obtain all the edges of a Hasse diagram by calling <code>P.cover_relations()</code> on the poset $P$.</p>

<p>To color edges of a graph, we create a dictionary <code>edge_colors</code>:</p>

<div class="linked">
  
</div>

<h3 id="up-next">Up next…</h3>
<p>This is the last post describing relatively simple things one can do to visualize subgroup lattices (or more generally, posets) in Sage. In the next post, I’ll write code to label edges. Doing this requires extracting the Hasse diagram of a poset as a graph and modifying the edge labels. Also, subgroup lattices tend to get unwieldy for large groups. In the next post, we’ll restrict our attention to conjugacy classes of subgroups, rather than all subgroups.</p>

<p>After that, I hope to write a bit about doing some simple representation theory things in Sage.</p></div>







<p class="date">
<a href="http://sheaves.github.io/Subgroup-Lattice-Edges/">December 27, 2014 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>December 25, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a></h3>


<div class="entrygroup" id="http://sheaves.github.io/Holiday-Harmonograph/">
<h4><a href="http://sheaves.github.io/Holiday-Harmonograph/">Holiday Harmonograph</a></h4>
<div class="entry">
<div class="content">
<p><em>(Guest post from the Annals of Harmonography)</em>
<img src="http://sheaves.github.io/images/harmonograph_loop.gif" alt="harmonograph" /></p>

<!--more-->

<p>When it’s snowing outside (or maybe not),</p>

<p>And your feet are cold (or maybe hot),</p>

<p>When it’s dark as day (or bright as night),</p>

<p>And your heart is heavy (and head is light),</p>

<p>What should you do (what should you say)</p>

<p>To make it all right (to make it okay)?</p>

<p>.</p>

<p>Just pick up a pen (a pencil will do),</p>

<p>Set up a swing (or <a href="http://www.karlsims.com/harmonograph/">three</a>, or two),</p>

<p>And while the world spins (or comes to a still),</p>

<p>In your own little room (or on top of a hill),</p>

<p>Let your pendulum sway (in its time, in its way),</p>

<p>And watch as the pen draws your worries away!</p>

<p>.</p>

<p>.</p>

<p><em>(Click inside the colored box to choose a color. Then click outside and watch it update.)</em></p>

<div class="auto_out">
  
</div>

<h3 id="related-articles">Related Articles:</h3>

<ul>
  <li>7 celebrities and their harmonographs</li>
  <li>What your harmonograph says about you</li>
  <li>10 tips for a happier harmonograph</li>
  <li>Harmonograph secrets… revealed!</li>
</ul></div>







<p class="date">
<a href="http://sheaves.github.io/Holiday-Harmonograph/">December 25, 2014 12:00 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>November 14, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-8239368345310276770">
<h4><a href="http://sagemath.blogspot.com/2014/11/sagemathcloud-notifications-are-now.html">SageMathCloud Notifications are Now Better</a></h4>
<div class="entry">
<div class="content">
<span>I just made live a new notifications systems for&nbsp;</span><span>&nbsp;</span><a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a><span>, which I spent all week writing. &nbsp;</span><br /><span><br /></span><span><br /></span><div class="separator"><a href="http://3.bp.blogspot.com/-WUoD0M9H66Q/VGaAvhl9LMI/AAAAAAABRRg/M4oyqykFK1w/s1600/Screen%2BShot%2B2014-11-14%2Bat%2B2.15.09%2BPM.png"><img border="0" src="http://3.bp.blogspot.com/-WUoD0M9H66Q/VGaAvhl9LMI/AAAAAAABRRg/M4oyqykFK1w/s1600/Screen%2BShot%2B2014-11-14%2Bat%2B2.15.09%2BPM.png" height="248" width="400" /></a></div><span><br /></span><span><br /></span><span>These notifications are what you see when you click the bell in the upper right. &nbsp; This new system replaces the one I made live two weeks ago. &nbsp; &nbsp; Whenever somebody actively *edits* (using the web interface) any file in any project you collaborate on, a notification will get created or updated. &nbsp; &nbsp;If a person *comments* on any file in any project you collaborate on (using the chat interface to the right), then not only does the notification get updated, there is also a little red counter on top of the bell and also in the title of the&nbsp;</span><span>&nbsp;</span><a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a><span>&nbsp;tab. &nbsp; In particular, people will now be&nbsp;much more likely to see the chats you make on files.</span><br /><div><div><br /></div><div class="separator"><a href="http://4.bp.blogspot.com/-MuNCyjAT7ec/VGaBGsXLWgI/AAAAAAABRRo/YTENwRbG7Fw/s1600/Screen%2BShot%2B2014-11-14%2Bat%2B2.23.58%2BPM.png"><img border="0" src="http://4.bp.blogspot.com/-MuNCyjAT7ec/VGaBGsXLWgI/AAAAAAABRRo/YTENwRbG7Fw/s1600/Screen%2BShot%2B2014-11-14%2Bat%2B2.23.58%2BPM.png" height="231" width="400" /></a></div><div><br /></div><div><br /></div><div><br /></div><div><b>NOTE: </b>I have not yet enabled any sort of daily email notification summary, but that is planned.&nbsp;</div><div><br /></div><div>Some technical details: &nbsp;Why did this take all week? &nbsp;It's because the technology that makes it work behind the scenes is something that was fairly difficult for me to figure out how to implement. &nbsp;I implemented a way to create an object that can be used simultaneously by many clients and supports realtime synchronization.... but is stored by the distributed <a href="http://www.datastax.com/" target="_blank">Cassandra </a>database instead of a file in a project. &nbsp; Any changes to that object get synchronized around very quickly. &nbsp; It's similar to how synchronized text editing (with several people at once) works, but I rethought <a href="https://neil.fraser.name/writing/sync/" target="_blank">differential synchronization</a> carefully, and also figured out how to synchronize using an eventually consistent database. &nbsp; &nbsp;This will be useful for implementing a lot other things in <a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a> that operate at a different level than "one single project". &nbsp;For example, I plan to add functions so you can access these same "synchronized databases" from Python processes -- then you'll be able to have sage worksheets (say) running on several different projects, but all saving their data to some common synchronized place (backed by the database). &nbsp; Another application will be a listing of the last 100 (say) files you've opened, with easy ways to store extra info about them. &nbsp; &nbsp;It will also be easy to make account and project settings more realtime, so when you change something, it automatically takes effect and is also synchronized across other browser tabs you may have open. &nbsp; If you're into modern Single Page App web development, this might remind you of Angular or React or Hoodie or Firebase -- what I did this week is probably kind of like some of the sync functionality of those frameworks, but I use Cassandra (instead of MongoDB, say) and differential synchronization. &nbsp;</div><div><br /></div><div>I <a href="https://gist.github.com/williamstein/badf771e50658010d56d" target="_blank">BSD-licensed the differential synchronization code </a>&nbsp;that&nbsp;I wrote as part of the above.&nbsp;</div><div><br /></div></div><div><br /></div></div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/11/sagemathcloud-notifications-are-now.html">by William Stein (noreply@blogger.com) at November 14, 2014 02:31 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>October 17, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-3221518328989833144">
<h4><a href="http://sagemath.blogspot.com/2014/10/a-non-technical-overview-of.html">A Non-technical Overview of the SageMathCloud Project</a></h4>
<div class="entry">
<div class="content">
<a href="http://1.bp.blogspot.com/-zd2T2HBgpag/VEFoFOU5GaI/AAAAAAABQ4U/ODq-0-ua7y0/s1600/Screen%2BShot%2B2014-10-17%2Bat%2B12.03.25%2BPM.png"><img border="0" src="http://1.bp.blogspot.com/-zd2T2HBgpag/VEFoFOU5GaI/AAAAAAABQ4U/ODq-0-ua7y0/s1600/Screen%2BShot%2B2014-10-17%2Bat%2B12.03.25%2BPM.png" height="194" width="320" /></a>What problems is the <a href="https://cloud.sagemath.com/">SageMathCloud project</a> trying to solve?  What pain points does it address?  Who are the competitors and what is the state of the technology right now?     <br /><br /><br /><h2 id="what-problems-youre-trying-to-solve-and-why-are-these-a-problem">What problems you’re trying to solve and why are these a problem?</h2><ul><li><strong>Computational Education</strong>: How can I <em>teach a course</em> that involves mathematical computation and programming?</li><li><strong>Computational Research:</strong> How can I carry out <em>collaborative computational research</em> projects?</li><li><strong>Cloud computing:</strong> How can I get easy user-friendly collaborative access to a <em>remote Linux server</em>?</li></ul><h2 id="what-are-the-pain-points-of-the-status-quo-and-who-feels-the-pain">What are the pain points of the status quo and who feels the pain?</h2><ul><li><strong>Student/Teacher pain:</strong><ul><li>Getting <em>students to install software</em> needed for a course on their computers is a major pain; sometimes it is just impossible, due to no major math software (not even Sage) supporting all recent versions of Windows/Linux/OS X/iOS/Android.</li><li>Getting university <em>computer labs to install the software</em> you need for a course is frustrating and expensive (time and money).</li><li>Even if computer labs worked, they are often being used by another course, stuffy, and students can't possibly do all their homework there, so computation gets short shrift. Lab keyboards, hardware, etc., all hard to get used to. Crappy monitors.</li><li>Painful confusing problems <em>copying files around</em> between teachers and students.</li><li>Helping a student or collaborator with their specific problem is very hard <em>without physical access</em> to their computer.</li></ul></li><li><strong>Researcher pain:</strong><ul><li>Making <em>backups every few minutes</em> of the complete state of everything when doing research often hard and distracting, but important for reproducibility.</li><li><em>Copying around documents</em>, emailing or pushing/pulling them to revision control is frustrating and confusing.</li><li><em>Installing obscuring software</em> is frustarting and distracting from the research they really want to do.</li></ul></li><li><strong>Everybody:</strong><ul><li>It is frustrating not having <em>LIVE working access</em> to your files wherever you are. (Dropbox/Github doesn't solve this, since files are static.)</li><li>It is difficult to <em>leave computations running remotely</em>.</li></ul></li></ul><h2 id="why-is-your-technology-poised-to-succeed">Why is your technology poised to succeed?</h2><ul><li>When it works, <strong>SageMathCloud solves every pain point listed above.</strong></li><li>The timing is right, due to <em>massive improvements in web browsers</em> during the last 3 years.</li><li>I am on full <em>sabbatical</em> this year, so at least success isn't totally impossible due to not working on the project.</li><li>I have been solving the above problems in less scalable ways for myself, colleagues and students <em>since the 1990s</em>.</li><li><em>SageMathCloud has many users</em> that provide valuable feedback.</li><li>We have already <em>solved difficult problems</em> since I started this project in Summer 2012 (and launched first version in April 2013).</li></ul><h2 id="who-are-your-competitors">Who are your competitors?</h2><em>There are no competitors</em> with a similar range of functionality. However, there are many webapps that have some overlap in capabilities:<br /><ul><li><strong>Mathematical overlap:</strong> Online Mathematica: "Bring Mathematica to life in the cloud"</li><li><strong>Python overlap:</strong> Wakari: "Web-based Python Data Analysis"; also PythonAnywhere</li><li><strong>Latex overlap:</strong> ShareLaTeX, WriteLaTeX</li><li><strong>Web-based IDE's/terminals:</strong> target writing webapps (not research or math education): c9.io, nitrous.io, codio.com, terminal.com</li><li><strong>Homework:</strong> WebAssign and WebWork</li></ul>Right now, <strong>SageMathCloud gives away for free far more</strong> than any other similar site, due to very substantial temporary financial support from Google, the NSF and others.<br /><h2 id="whats-the-total-addressable-market">What’s the total addressable market?</h2>Though our primary focus is the <em>college mathematics classroom</em>, there is a larger market:<br /><ul><li><strong>Students:</strong> all undergrad/high school students in the world taking a course involving programming or mathematics</li><li><strong>Teachers:</strong> all teachers of such courses</li><li><strong>Researchers:</strong> anybody working in areas that involve programming or data analysis</li></ul>Moreover, the web-based platform for computing that we're building lends itself to many other collaborative applications.<br /><h2 id="what-stage-is-your-technology-at">What stage is your technology at?</h2><ul><li>The site is up and running and has <strong>28,413 monthly active users</strong></li><li>There are still many bugs</li><li>I have a <em>precise todo list</em> that would take me at least <em>2 months</em> fulltime to finish.</li></ul><h2 id="is-your-solution-technically-feasible-at-this-point">Is your solution technically feasible at this point?</h2><ul><li>Yes. It is only a matter of time until the software is very polished.</li><li>Morever, we have compute resources to support significantly more users.</li><li>But without money (from paying customers or investment), if growth continues at the current rate then we will have to clamp down on free quotas for users.</li></ul><h2 id="what-technical-milestones-remain">What technical milestones remain?</h2><ul><li>Infrastructure for creating automatically-graded homework problems.</li><li>Fill in lots of details and polish.</li></ul><h2 id="do-you-have-external-credibility-with-technicalbusiness-experts-and-customers">Do you have external credibility with technical/business experts and customers?</h2><ul><li><strong>Business experts:</strong> I don't even know any business experts.</li><li><strong>Technical experts:</strong> I founded the Sage math software, which is 10 years old and relatively well known by mathematicians.</li><li><strong>Customers:</strong> We have no customers; we haven't offered anything for sale.</li></ul><h2 id="market-research">Market research?</h2><ul><li>I know about math software and its users as a result of founding the Sage open source math software project, NSF-funded projects I've been involved in, etc.</li></ul><h2 id="is-the-intellectual-property-around-your-technology-protected">Is the intellectual property around your technology protected?</h2><ul><li>The IP is software.</li><li>The website software is mostly new Javascript code we wrote that is copyright Univ. of Washington and mostly not open source; it depends on various open source libraries and components.</li><li>The Sage math software is entirely open source.</li></ul><h2 id="who-are-the-team-members-to-move-this-technology-forward">Who are the team members to move this technology forward?</h2>I am the only person working on this project fulltime right now.<br /><ul><li><strong>Everything:</strong> William Stein -- UW professor</li><li><strong>Browser client code:</strong> Jon Lee, Andy Huchala, Nicholas Ruhland -- UW undergrads</li><li><strong>Web design, analytics:</strong> Harald Schilly -- Austrian grad student</li><li><strong>Hardware:</strong> Keith Clawson</li></ul><h2 id="why-are-you-the-ideal-team">Why are you the ideal team?</h2><ul><li>We are not the ideal team.</li><li>If I had money maybe I could build the ideal team, leveraging my experience and connections from the Sage project...</li></ul></div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/10/a-non-technical-overview-of.html">by William Stein (noreply@blogger.com) at October 17, 2014 12:04 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>October 16, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-5655260630534776590">
<h4><a href="http://sagemath.blogspot.com/2014/10/public-sharing-in-sagemathcloud-finally.html">Public Sharing in SageMathCloud, Finally</a></h4>
<div class="entry">
<div class="content">
<a href="https://cloud.sagemath.com/">SageMathCloud (SMC)</a> is a free (<a href="http://www.nsf.gov/">NSF</a>, <a href="http://google.com/">Google</a> and <a href="http://www.washington.edu/">UW</a> supported) website that lets you collaboratively work with Sage worksheets, IPython notebooks, LaTeX documents and much, much more. All work is snapshotted every few minutes, and copied out to several data centers, so if something goes wrong with a project running on one machine (right before your lecture begins or homework assignment is due), it will pop up on another machine. We designed the backend architecture from the ground up to be very horizontally scalable and have no single points of failure.<br /><br />This post is about an important new feature: <em><b>You can now mark a folder or file so that all other users can view it, and very easily copy it to their own project.</b></em><br /><br /><div class="separator"><a href="http://3.bp.blogspot.com/-oV_0xhD4af0/VEAnl6SRVQI/AAAAAAABQ2U/NkKVdh0NbNE/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.15.58%2BPM.png"><img border="0" src="http://3.bp.blogspot.com/-oV_0xhD4af0/VEAnl6SRVQI/AAAAAAABQ2U/NkKVdh0NbNE/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.15.58%2BPM.png" height="308" width="400" /></a></div><br /><br /><br />This solves problems:<br /><ul><li><strong>Problem:</strong> You create a "template" project, e.g., with pre-installed software, worksheets, IPython notebooks, etc., and want other users to easily be able to clone it as a new project. <strong>Solution:</strong> Mark the home directory of the project public, and share the link widely.<br /></li></ul><div class="separator"><a href="http://2.bp.blogspot.com/-FDT_Z1UD9H0/VEAn9tH3OhI/AAAAAAABQ2c/RQGklZMBiJA/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.17.35%2BPM.png"><img border="0" src="http://2.bp.blogspot.com/-FDT_Z1UD9H0/VEAn9tH3OhI/AAAAAAABQ2c/RQGklZMBiJA/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.17.35%2BPM.png" height="201" width="320" /></a></div><br /><ul><li><strong>Problem:</strong> You create a syllabus for a course, an assignment, a worksheet full of 3d images, etc., that you want to share with a group of students. <strong>Solution:</strong> Make the syllabus or worksheet public, and share the link with your students via an email and on the course website. (Note: You can also use a course document to share files with all students privately.) <a href="https://cloud.sagemath.com/projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/files/some%203d%20plots.sagews" target="_blank">For example...</a><br /></li></ul><div class="separator"><a href="http://1.bp.blogspot.com/-dMZS2DgsnzY/VEAouDdZu6I/AAAAAAABQ2k/6iPT0OWIomk/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.20.38%2BPM.png"><img border="0" src="http://1.bp.blogspot.com/-dMZS2DgsnzY/VEAouDdZu6I/AAAAAAABQ2k/6iPT0OWIomk/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.20.38%2BPM.png" height="320" width="286" /></a></div><div class="separator"><br /></div><div class="separator"><a href="http://3.bp.blogspot.com/-hQIq6QKlzLo/VEApB-yQV8I/AAAAAAABQ2s/o-jx4vjIlj0/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.22.15%2BPM.png"><img border="0" src="http://3.bp.blogspot.com/-hQIq6QKlzLo/VEApB-yQV8I/AAAAAAABQ2s/o-jx4vjIlj0/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.22.15%2BPM.png" height="74" width="320" /></a></div><div class="separator"><br /></div><ul><li><strong>Problem:</strong> You run into a problem using <a href="https://cloud.sagemath.com/">SMC</a> and want help. <strong>Solution:</strong> Make the worksheet or code that isn't working public, and post <a href="https://cloud.sagemath.com/projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/files/confused.sagews" target="_blank">a link</a> in a forum asking for help.</li></ul><div class="separator"><a href="http://4.bp.blogspot.com/-CdngoQAPCi8/VEApPsnc_8I/AAAAAAABQ20/r6wHP-IMqQ8/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.23.13%2BPM.png"><img border="0" src="http://4.bp.blogspot.com/-CdngoQAPCi8/VEApPsnc_8I/AAAAAAABQ20/r6wHP-IMqQ8/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.23.13%2BPM.png" height="216" width="320" /></a></div><ul><li><strong>Problem:</strong> You write a blog post explaining how to solve a problem and write related code in an <a href="https://cloud.sagemath.com/">SMC</a> worksheet, which you want your readers to see. <strong>Solution:</strong> Make that code public and post a link in your blog post.</li></ul>Here's <a href="http://youtu.be/B4GiyjIXL4Q">a screencast</a>.<br /><br />Each <a href="https://cloud.sagemath.com/">SMC</a> project has its own local "project server", which takes some time to start up, and serves files, coordinates Sage, terminal, and IPython sessions, etc. Public sharing completely avoids having anything to do with the project server -- <strong>it works fine even if the project server is not running</strong> -- it's always fast and there is no startup time if the project server isn't running. Moreover, public sharing reads the live files from your project, so you can update the files in a public shared directory, add new files, etc., and users will see these changes (when they refresh, since it's not automatic).<br />As an example, here is the <a href="https://cloud.sagemath.com/projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/files/cloud-examples/">cloud-examples github repo as a share</a>. If you click on it (and have a SageMathCloud account), you'll see this:<br /><pre><br /></pre><div class="separator"><a href="http://1.bp.blogspot.com/-nFbB6EldXxw/VEAph5pthGI/AAAAAAABQ28/cEBiDtyHSf8/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.24.21%2BPM.png"><img border="0" src="http://1.bp.blogspot.com/-nFbB6EldXxw/VEAph5pthGI/AAAAAAABQ28/cEBiDtyHSf8/s1600/Screen%2BShot%2B2014-10-16%2Bat%2B1.24.21%2BPM.png" height="280" width="400" /></a></div><pre><br /></pre><h2 id="what-next">What Next?</h2>There is an enormous amount of natural additional functionality to build on top of public sharing.<br /><br />For example, not all document types can be previewed in read-only mode right now; in particular, IPython notebooks, task lists, LaTeX documents, images, and PDF files must be copied from the public share to another project before people can view them. It is better to release a first usable version of public sharing before systematically going through and implementing the additional features needed to support all of the above. You <em>can</em> make complicated Sage worksheets with embedded images and 3d graphics, and those can be previewed before copying them to a project.<br />Right now, the only way to visit a public share is to paste the URL into a browser tab and load it. Soon the projects page will be re-organized so you can search for publicly shared paths, see all public shares that you have previously visited, who shared them, how many +1's they've received, comments, etc.<br /><br />Also, I plan to eventually make it so public shares will be visible to people who have not logged in, and when viewing a publicly shared file or directory, there will be an option to start it running in a limited <em>project</em>, which will vanish from existence after a period of inactivity (say).<br /><br />There are also dozens of details that are not yet implemented. For example, it would be nice to be able to directly download files (and directories!) to your computer from a public share. And it's also natural to share a folder or file with a specific list of people, rather than sharing it publicly. If somebody is viewing a public file and you change it, they should likely see the update automatically. Right now when viewing a share, you don't even know who shared it, and if you open a worksheet it can automatically execute Javascript, which is potentially unsafe. &nbsp;Once public content is easily found, if somebody posts "evil" content publicly, there needs to be an easy way for users to report it.<br /><h2 id="sharing-will-permeate-everything">Sharing will permeate everything</h2>Sharing has been thought about a great deal during the last few years in the context of sites such as Github, Facebook, Google+ and Twitter. With <a href="https://cloud.sagemath.com/">SMC</a>, we've developed a foundation for interactive collaborative computing in a browser, and will introduce sharing on top of that in a way that is motivated by your problems. For example, as with Github or Google+, when somebody makes a copy of your publicly shared folder, this copy should be listed (under "copies") and it could start out public by default. There is much to do.<br /><br />One reason it took so long to release the first version of public sharing is that I kept imagining that sharing would happen at the level of complete projects, just like sharing in Github. However, when thinking through your problems, it makes way more sense in <a href="https://cloud.sagemath.com/">SMC</a> to share individual directories and files. Technically, sharing at this level works works well for <em>read-only</em> access, not for read-write access, since projects are mapped to Linux accounts. Another reason I have been very hesitant to support sharing is that I've had enormous trouble over the years with spammers posting content that gets me in trouble (with my University -- it is illegal for UW to host advertisements). However, by not letting search engines index content, the motivation for spammers to post nasty content is greatly reduced.<br /><br />Imagine publicly sharing recipes for automatically gradable homework problems, which use the full power of everything installed in <a href="https://cloud.sagemath.com/">SMC</a>, get forked, improved, used, etc.</div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/10/public-sharing-in-sagemathcloud-finally.html">by William Stein (noreply@blogger.com) at October 16, 2014 01:29 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>October 01, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-4658363764746166473">
<h4><a href="http://sagemath.blogspot.com/2014/10/sagemathcloud-course-management.html">SageMathCloud Course Management</a></h4>
<div class="entry">
<div class="content">
<div class="modal-body"><a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a> now has some very rudimentary course management functionality. &nbsp;Though still very basic, it makes it much, much easier to make files available to students, collect homework, etc., entirely using <a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a> (without having to use email or any other submissions systems or github to share files). &nbsp; To get started, create a new course by clicking on +New, then typing the name of your course and click "Course":<br /><br /><div class="separator"><a href="http://2.bp.blogspot.com/-zJYWHLYWRP8/VCxOUQCrbrI/AAAAAAABQQ4/KT4IWWwUQKg/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.55.15%2BAM.png"><img border="0" src="http://2.bp.blogspot.com/-zJYWHLYWRP8/VCxOUQCrbrI/AAAAAAABQQ4/KT4IWWwUQKg/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.55.15%2BAM.png" height="198" width="320" /></a></div><br /><br />Course documents allow you to manage a <i>list of students</i>, <i>create projects</i> for each                     of them, <i>share homework</i> and folders with them, <i>collect                     homework</i>, and <i>grade and return</i> it to students.                       <br /><h4>Add Students</h4>To add a student to your course, click on the <a class="btn btn-primary btn-default" href="https://www.blogger.com/null"><i class="fa fa-users"> </i>  Students</a> tab,                         then type a student's name or email address in the "Add student" box to the right and press                         enter or click the button.   Searching for an email address is best, since you can be certain that the person you're adding is                         really a student in your course (instead of an unknown SageMathCloud user with the same name); moreover, if your student                         doesn't already have an account, they will receive an invitation via email.                         <span class="lighten">(NOTE: There is currently no way to add dozens of students at once.)</span>                    <br /><span class="lighten"><br /></span><div class="separator"><a href="http://1.bp.blogspot.com/-5jlvxCeEwAk/VCxO5T9_U1I/AAAAAAABQRA/YjyF5gcEogs/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.57.53%2BAM.png"><img border="0" src="http://1.bp.blogspot.com/-5jlvxCeEwAk/VCxO5T9_U1I/AAAAAAABQRA/YjyF5gcEogs/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.57.53%2BAM.png" height="171" width="320" /></a></div><span class="lighten"><br /></span><span class="lighten"><br /></span>Once you add a student, click on <a class="btn btn-warning" href="https://www.blogger.com/null"><i class="fa fa-plus-circle"> </i>  Create Project</a> next to your                         student's name to create their project.  You own the project, and they will be added as a collaborator, and invited by email if they                         do not yet have an account.<br /><br /><div class="separator"><a href="http://3.bp.blogspot.com/-pi4VnSnlrCA/VCxPS2-Tc4I/AAAAAAABQRQ/03FygAXUnRM/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.59.50%2BAM.png"><img border="0" src="http://3.bp.blogspot.com/-pi4VnSnlrCA/VCxPS2-Tc4I/AAAAAAABQRQ/03FygAXUnRM/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.59.50%2BAM.png" height="123" width="320" /></a></div><br /><br /><br /><br /><div class="separator"><a href="http://3.bp.blogspot.com/-C5hvg7AuAow/VCxPSzz8TuI/AAAAAAABQRU/LyBP3j2xA7s/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.00.10%2BPM.png"><img border="0" src="http://3.bp.blogspot.com/-C5hvg7AuAow/VCxPSzz8TuI/AAAAAAABQRU/LyBP3j2xA7s/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.00.10%2BPM.png" height="129" width="320" /></a></div><br />&nbsp;Don't worry, student projects are hidden by default from your main project listing.<br /><br /><div class="separator"><a href="http://4.bp.blogspot.com/-ZzDNFNJIvAQ/VCxPk6o1hnI/AAAAAAABQRg/fF3r40SK6_c/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.01.23%2BPM.png"><img border="0" src="http://4.bp.blogspot.com/-ZzDNFNJIvAQ/VCxPk6o1hnI/AAAAAAABQRg/fF3r40SK6_c/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.01.23%2BPM.png" height="115" width="320" /></a></div><br />(To delete a student, click <i class="fa fa-times"> </i> to the right of the student.                         You can toggle whether deleted students are shown in settings.)<br /><br /><h4>Add Assignments</h4>To create an assignment, first click                         <a href="https://www.blogger.com/null">                            <i class="project-control-icon fa fa-plus-circle"></i>                            <span class="project-pages-button-label hidden-xs">New</span>                        </a>                        in the upper left of your project to create a new folder, and create or add files to it, as usual.                         Click on the <a class="btn btn-default btn-primary" href="https://www.blogger.com/null"><i class="fa fa-share-square-o"> </i> Assignments</a>                        tab of the course, then search for the folder by typing some part of its name in the box on the far right.                         Click to select the folder and it will be added to your                         list of assignments.                         To make <b>copies</b> of this folder available to all of your students whose projects you have created,                         click the <a class="btn btn-warning" href="https://www.blogger.com/null"><i class="fa fa-share-square-o"> </i>  Assign</a> button.                         <span class="lighten">NOTE: You can share arbitrary folders with any contents with your                             students -- folders don't have                             to contain "assignments", and may contain anything, Sage worksheets, IPython notebooks,                             LaTeX documents, etc.</span>                    <br /><span class="lighten"><br /></span><div class="separator"><a href="http://1.bp.blogspot.com/-zv3oNd_QHhI/VCxQD8AEiSI/AAAAAAABQRo/aIPlWFZ83cw/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.03.06%2BPM.png"><img border="0" src="http://1.bp.blogspot.com/-zv3oNd_QHhI/VCxQD8AEiSI/AAAAAAABQRo/aIPlWFZ83cw/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.03.06%2BPM.png" height="98" width="320" /></a></div><div class="separator"><br /></div><div class="separator"><br /></div><div class="separator"><a href="http://1.bp.blogspot.com/-LT4ZJFwHv3k/VCxQEwwjM7I/AAAAAAABQRw/N9d6TlSgoak/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.03.20%2BPM.png"><img border="0" src="http://1.bp.blogspot.com/-LT4ZJFwHv3k/VCxQEwwjM7I/AAAAAAABQRw/N9d6TlSgoak/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.03.20%2BPM.png" height="140" width="320" /></a></div><br /><span class="lighten"><br /></span><span class="lighten"><br /></span><h4>Collecting and Grading Assignments</h4>To collect an assignment from your students,                         click <a class="btn btn-warning" href="https://www.blogger.com/null"><i class="fa fa-share-square-o fa-rotate-180"> </i>  Collect</a> to the right of an assignment                         to collect it from all students.                         <span class="lighten">                        (NOTE: There is currently no way to schedule collection to happen at a specific time -- it happens                         when you click the button.  Click it again to update the collected files.)</span>                    <br />Once the assignments are collected, click                         <button class="btn btn-default dropdown-toggle" type="button">                            <i class="fa fa-eye"> </i> Grade <span class="caret"></span>                        </button>                        and select a student to jump to the folder that contains the collected version of a                         student's assignment. Edit the                         files there, indicating grades on each problem, etc.                         <span class="lighten">                            NOTE: There is no special support yet for recording grades, knowing which homework you have graded already, etc.                         </span>                    <br />When you are done grading, click <a class="btn btn-warning" href="https://www.blogger.com/null"><i class="fa fa-share-square-o"> </i>  Return Graded</a>                        to return the graded homework to the students.  If the homework folder is called <tt>homework1</tt>, then the graded version                         will appear in the student's project as <tt>homework1-graded</tt>.                     <br /><br /><br /><div class="separator"><a href="http://1.bp.blogspot.com/-QlF6BMvK4wM/VCxQXrL-QxI/AAAAAAABQR4/0PsVB19gPE0/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.04.35%2BPM.png"><img border="0" src="http://1.bp.blogspot.com/-QlF6BMvK4wM/VCxQXrL-QxI/AAAAAAABQR4/0PsVB19gPE0/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B12.04.35%2BPM.png" height="108" width="320" /></a></div><br /><h4>Course Settings</h4>Set the title and description of the course in the                         <a class="btn btn-default btn-primary" href="https://www.blogger.com/null"><i class="fa fa-wrench"> </i> Settings</a> tab.  When you                         change these, the new title and description                         propagates automatically to all student projects for this course.                     <br /><br /><div class="separator"><a href="http://3.bp.blogspot.com/-h0Zt3E4dEGs/VCxO9o_lDsI/AAAAAAABQRI/FTyzihxwku0/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.58.21%2BAM.png"><img border="0" src="http://3.bp.blogspot.com/-h0Zt3E4dEGs/VCxO9o_lDsI/AAAAAAABQRI/FTyzihxwku0/s1600/Screen%2BShot%2B2014-10-01%2Bat%2B11.58.21%2BAM.png" height="151" width="320" /></a></div><br /><h4>Other</h4><ul><li>A&nbsp;<a href="http://youtu.be/C8ZALCcCCkM" target="_blank">Video Tutorial</a>                        </li></ul><h4>Technical Remarks</h4>The underlying file format of a .course file is a plain text file with one line in JSON format for each student,                     shared assignment, and for settings.                  </div></div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/10/sagemathcloud-course-management.html">by William Stein (noreply@blogger.com) at October 01, 2014 12:05 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>September 27, 2014</h2>

<div class="channelgroup">







<h3><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/" title="Sébastien Labbé">Sébastien Labbé</a></h3>


<div class="entrygroup" id="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/09/abelian-complexity-of-the-oldenburger-sequence" lang="en">
<h4><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/09/abelian-complexity-of-the-oldenburger-sequence">Abelian complexity of the Oldenburger sequence</a></h4>
<div class="entry">
<div class="content">
<div class="document">
<p>The Oldenburger infinite sequence <a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/09/abelian-complexity-of-the-oldenburger-sequence#o39" id="id1">[O39]</a>
\[
K = 1221121221221121122121121221121121221221\ldots
\]
also known under the name of <a class="reference external" href="http://en.wikipedia.org/wiki/Kolakoski_sequence">Kolakoski</a>, is equal to its <em>exponent
trajectory</em>.  The exponent trajectory \(\Delta\) can be obtained by counting
the lengths of blocks of consecutive and equal letters:
\[
K =
1^12^21^22^11^12^21^12^21^22^11^22^21^12^11^22^11^12^21^22^11^22^11^12^21^12^21^22^11^12^21^12^11^22^11^22^21^12^21^2\ldots
\]
The sequence of exponents above gives the exponent trajectory of the
Oldenburger sequence:
\[
\Delta = 12211212212211211221211212\ldots
\]
which is equal to the original sequence \(K\).
You can define this sequence in Sage:</p>


<div class="pygments_manni"><pre>sage: K = words.KolakoskiWord()
sage: K
word: 1221121221221121122121121221121121221221...
sage: K.delta()          # delta returns the exponent trajectory
word: 1221121221221121122121121221121121221221...
</pre></div>



<p>There are a lot of open problem related to basic properties of that sequence.
For example, we do not know if that sequence is recurrent, that is, all finite
subword or factor (finite block of consecutive letters) always reappear. Also,
it is still open to prove whether the density of <tt class="docutils literal">1</tt> in that sequence is
equal to \(1/2\).</p>
<p>In this blog post, I do some computations on its abelian complexity
\(p_{ab}(n)\) defined as the number of distinct abelian vectors of subwords of
length \(n\) in the sequence. The abelian vector \(\vec{w}\) of a word
\(w\) counts the number of occurences of each letter:
\[
w = 12211212212
\quad
\mapsto
\quad
1^5 2^7 \text{, abelianized}
\quad
\mapsto
\quad
\vec{w} = (5, 7) \text{, the abelian vector of }
w
\]</p>
<p>Here are the abelian vectors of subwords of length 10 and 20 in the prefix of
length 100 of the Oldenburger sequence.  The functions <tt class="docutils literal">abelian_vectors</tt> and
<tt class="docutils literal">abelian_complexity</tt>  are not in Sage as of now. Code is available at <a class="reference external" href="http://trac.sagemath.org/ticket/17058">trac
#17058</a> to be merged in Sage soon:</p>


<div class="pygments_manni"><pre>sage: prefix = words.KolakoskiWord()[:100]
sage: prefix.abelian_vectors(10)
{(4, 6), (5, 5), (6, 4)}
sage: prefix.abelian_vectors(20)
{(8, 12), (9, 11), (10, 10), (11, 9), (12, 8)}
</pre></div>



<p>Therefore, the prefix of length 100 has 3 vectors of subwords of length 10 and 5
vectors of subwords of length 20:</p>


<div class="pygments_manni"><pre>sage: p100.abelian_complexity(10)
3
sage: p100.abelian_complexity(20)
5
</pre></div>



<p>I import the <tt class="docutils literal">OldenburgerSequence</tt> from my optional spkg because it is faster
than the implementation in Sage:</p>


<div class="pygments_manni"><pre>sage: from slabbe import KolakoskiWord as OldenburgerSequence
sage: Olden = OldenburgerSequence()
</pre></div>



<p>I count the number of abelian vectors of subwords of length 100 in the prefix of
length \(2^{20}\) of the Oldenburger sequence:</p>


<div class="pygments_manni"><pre>sage: prefix = Olden[:2^20]
sage: %time prefix.abelian_vectors(100)
CPU times: user 3.48 s, sys: 66.9 ms, total: 3.54 s
Wall time: 3.56 s
{(47, 53), (48, 52), (49, 51), (50, 50), (51, 49), (52, 48), (53, 47)}
</pre></div>



<p>Number of abelian vectors of subwords of length less than 100 in the prefix of
length \(2^{20}\) of the Oldenburger sequence:</p>


<div class="pygments_manni"><pre>sage: %time L100 = map(prefix.abelian_complexity, range(100))
CPU times: user 3min 20s, sys: 1.08 s, total: 3min 21s
Wall time: 3min 23s
sage: from collections import Counter
sage: Counter(L100)
Counter({5: 26, 6: 26, 4: 17, 7: 15, 3: 8, 8: 4, 2: 3, 1: 1})
</pre></div>



<p>Let's draw that:</p>


<div class="pygments_manni"><pre>sage: labels = ('Length of factors', 'Number of abelian vectors')
sage: title = 'Abelian Complexity of the prefix of length $2^{20}$ of Oldenburger sequence'
sage: list_plot(L100, color='green', plotjoined=True, axes_labels=labels, title=title)
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/oldenburger_abelian_100.png"><img alt="/~labbe/Files/2014/oldenburger_abelian_100.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/oldenburger_abelian_100.png" /></a>
<p>It seems to grow something like \(\log(n)\). Let's now consider subwords of
length \(2^n\) for \(0\leq n\leq 12\) in the same prefix of length
\(2^{20}\):</p>


<div class="pygments_manni"><pre>sage: %time L20 = [(2^n, prefix.abelian_complexity(2^n)) for n in range(20)]
CPU times: user 41 s, sys: 239 ms, total: 41.2 s
Wall time: 41.5 s
sage: L20
[(1, 2), (2, 3), (4, 3), (8, 3), (16, 3), (32, 5), (64, 5), (128, 9),
(256, 9), (512, 13), (1024, 17), (2048, 22), (4096, 27), (8192, 40),
(16384, 46), (32768, 67), (65536, 81), (131072, 85), (262144, 90), (524288, 104)]
</pre></div>



<p>I now look at subwords of length \(2^n\) for \(0\leq n\leq 23\) in the
longer prefix of length \(2^{24}\):</p>


<div class="pygments_manni"><pre>sage: prefix = Olden[:2^24]
sage: %time L24 = [(2^n, prefix.abelian_complexity(2^n)) for n in range(24)]
CPU times: user 20min 47s, sys: 13.5 s, total: 21min
Wall time: 20min 13s
sage: L24
[(1, 2), (2, 3), (4, 3), (8, 3), (16, 3), (32, 5), (64, 5), (128, 9), (256,
9), (512, 13), (1024, 17), (2048, 23), (4096, 33), (8192, 46), (16384, 58),
(32768, 74), (65536, 98), (131072, 134), (262144, 165), (524288, 229),
(1048576, 302), (2097152, 371), (4194304, 304), (8388608, 329)]
</pre></div>



<p>The next graph gather all of the above computations:</p>


<div class="pygments_manni"><pre>sage: G = Graphics()
sage: legend = 'in the prefix of length 2^{}'
sage: G += list_plot(L24, plotjoined=True, thickness=4, color='blue', legend_label=legend.format(24))
sage: G += list_plot(L20, plotjoined=True, thickness=4, color='red', legend_label=legend.format(20))
sage: G += list_plot(L100, plotjoined=True, thickness=4, color='green', legend_label=legend.format(20))
sage: labels = ('Length of factors', 'Number of abelian vectors')
sage: title = 'Abelian complexity of Oldenburger sequence'
sage: G.show(scale=('semilogx', 2), axes_labels=labels, title=title)
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/oldenburger_abelian_2e24.png"><img alt="/~labbe/Files/2014/oldenburger_abelian_2e24.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/oldenburger_abelian_2e24.png" /></a>
<p>A linear growth in the above graphics with logarithmic \(x\) abcisse would
mean a growth in \(\log(n)\).  After those experimentations, my hypothesis
is that the abelian complexity of the Oldenburger sequence grows like
\(\log(n)^2\).</p>
<div class="section" id="references">
<h1>References</h1>
<table class="docutils citation" frame="void" id="o39" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/09/abelian-complexity-of-the-oldenburger-sequence#id1">[O39]</a></td><td>Oldenburger, Rufus (1939). &quot;Exponent trajectories in symbolic dynamics&quot;.
Transactions of the American Mathematical Society 46: 453–466.
<a class="reference external" href="http://dx.doi.org/10.2307%2F1989933">doi:10.2307/1989933</a></td></tr>
</tbody>
</table>
</div>
</div></div>







<p class="date">
<a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/09/abelian-complexity-of-the-oldenburger-sequence">by Sébastien Labbé at September 27, 2014 10:00 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>August 27, 2014</h2>

<div class="channelgroup">







<h3><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/" title="Sébastien Labbé">Sébastien Labbé</a></h3>


<div class="entrygroup" id="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released" lang="en">
<h4><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released">slabbe-0.1.spkg released</a></h4>
<div class="entry">
<div class="content">
<div class="document">
<p>These is a summary of the functionalities present in <a class="reference external" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Sage">slabbe-0.1</a> optional Sage
package. It depends on version 6.3 of Sage because it uses
<a class="reference external" href="http://www.sagemath.org/doc/reference/structure/sage/sets/recursively_enumerated_set.html">RecursivelyEnumeratedSet</a> code that was merged in 6.3.  It contains modules
on digital geometry, combinatorics on words and more.</p>
<p>Install the optional spkg (depends on sage-6.3):</p>


<div class="pygments_manni"><pre>sage -i http://www.liafa.univ-paris-diderot.fr/~labbe/Sage/slabbe-0.1.spkg
</pre></div>



<p>In each of the example below, you first have to import the module once and for
all:</p>


<div class="pygments_manni"><pre>sage: from slabbe import *
</pre></div>



<p>To construct the image below, make sure to use tikz package so that <tt class="docutils literal">view</tt> is
able to compile tikz code when called:</p>


<div class="pygments_manni"><pre>sage: latex.add_to_preamble(&quot;\\usepackage{tikz}&quot;)
sage: latex.extra_preamble()
'\\usepackage{tikz}'
</pre></div>



<div class="section" id="draw-the-part-of-a-discrete-plane">
<h1>Draw the part of a discrete plane</h1>


<div class="pygments_manni"><pre>sage: p = DiscretePlane([1,pi,7], 1+pi+7, mu=0)
sage: d = DiscreteTube([-5,5],[-5,5])
sage: I = p &amp; d
sage: I
Intersection of the following objects:
Set of points x in ZZ^3 satisfying: 0 &lt;= (1, pi, 7) . x + 0 &lt; pi + 8
DiscreteTube: Preimage of [-5, 5] x [-5, 5] by a 2 by 3 matrix
sage: clip = d.clip()
sage: tikz = I.tikz(clip=clip)
sage: view(tikz, tightpage=True)
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/discreteplane1pi7.png"><img alt="/~labbe/Files/2014/discreteplane1pi7.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/discreteplane1pi7.png" /></a>
</div>
<div class="section" id="draw-the-part-of-a-discrete-line">
<h1>Draw the part of a discrete line</h1>


<div class="pygments_manni"><pre>sage: L = DiscreteLine([-2,3], 5)
sage: b = DiscreteBox([0,10], [0,10])
sage: I = L &amp; b
sage: I
Intersection of the following objects:
Set of points x in ZZ^2 satisfying: 0 &lt;= (-2, 3) . x + 0 &lt; 5
[0, 10] x [0, 10]
sage: I.plot()
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/discreteline23.png"><img alt="/~labbe/Files/2014/discreteline23.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/discreteline23.png" /></a>
</div>
<div class="section" id="double-square-tiles">
<h1>Double square tiles</h1>
<p>This module was developped for the article on the combinatorial properties of
double square tiles written with Ariane Garon and Alexandre Blondin Massé
<a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released#bgl2012" id="id3">[BGL2012]</a>. The original version of the code was written with Alexandre.</p>


<div class="pygments_manni"><pre>sage: D = DoubleSquare((34,21,34,21))
sage: D
Double Square Tile
  w0 = 3032321232303010303230301012101030   w4 = 1210103010121232121012123230323212
  w1 = 323030103032321232303                w5 = 101212321210103010121
  w2 = 2321210121232303232123230301030323   w6 = 0103032303010121010301012123212101
  w3 = 212323032321210121232                w7 = 030101210103032303010
(|w0|, |w1|, |w2|, |w3|) = (34, 21, 34, 21)
(d0, d1, d2, d3)         = (42, 68, 42, 68)
(n0, n1, n2, n3)         = (0, 0, 0, 0)
sage: D.plot()
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/fibo2.png"><img alt="/~labbe/Files/2014/fibo2.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/fibo2.png" /></a>


<div class="pygments_manni"><pre>sage: D.extend(0).extend(1).plot()
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/fibo2extend0extend1.png"><img alt="/~labbe/Files/2014/fibo2extend0extend1.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/fibo2extend0extend1.png" /></a>
<p>We have shown that using two invertible operations (called SWAP and TRIM),
every double square tiles can be reduced to the unit square:</p>


<div class="pygments_manni"><pre>sage: D.plot_reduction()
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/fibo2reduction.png"><img alt="/~labbe/Files/2014/fibo2reduction.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/fibo2reduction.png" /></a>
<p>The reduction operations are:</p>


<div class="pygments_manni"><pre>sage: D.reduction()
['SWAP_1', 'TRIM_1', 'TRIM_3', 'SWAP_1', 'TRIM_1', 'TRIM_3', 'TRIM_0', 'TRIM_2']
</pre></div>



<p>The result of the reduction is the unit square:</p>


<div class="pygments_manni"><pre>sage: unit_square = D.apply(D.reduction())
sage: unit_square
Double Square Tile
  w0 =     w4 =
  w1 = 3   w5 = 1
  w2 =     w6 =
  w3 = 2   w7 = 0
(|w0|, |w1|, |w2|, |w3|) = (0, 1, 0, 1)
(d0, d1, d2, d3)         = (2, 0, 2, 0)
(n0, n1, n2, n3)         = (0, NaN, 0, NaN)
sage: unit_square.plot()
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/unit_square.png"><img alt="/~labbe/Files/2014/unit_square.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/unit_square.png" /></a>
<p>Since SWAP and TRIM are invertible operations, we can recover every double
square from the unit square:</p>


<div class="pygments_manni"><pre>sage: E = unit_square.extend(2).extend(0).extend(3).extend(1).swap(1).extend(3).extend(1).swap(1)
sage: D == E
True
</pre></div>



</div>
<div class="section" id="christoffel-graphs">
<h1>Christoffel graphs</h1>
<p>This module was developped for the article on a d-dimensional extension of
Christoffel Words written with Christophe Reutenauer <a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released#lr2014" id="id5">[LR2014]</a>.</p>


<div class="pygments_manni"><pre>sage: G = ChristoffelGraph((6,10,15))
sage: G
Christoffel set of edges for normal vector v=(6, 10, 15)
sage: tikz = G.tikz_kernel()
sage: view(tikz, tightpage=True)
</pre></div>



<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/christoffelgraph6_10_15.png"><img alt="/~labbe/Files/2014/christoffelgraph6_10_15.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/christoffelgraph6_10_15.png" /></a>
</div>
<div class="section" id="bispecial-extension-types">
<h1>Bispecial extension types</h1>
<p>This module was developped for the article on the factor complexity of
infinite sequences genereated by substitutions written with Valérie Berthé
<a class="citation-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released#bl2014" id="id7">[BL2014]</a>.</p>
<p>The extension type of an ordinary bispecial factor:</p>


<div class="pygments_manni"><pre>sage: L = [(1,3), (2,3), (3,1), (3,2), (3,3)]
sage: E = ExtensionType1to1(L, alphabet=(1,2,3))
sage: E
  E(w)   1   2   3
   1             X
   2             X
   3     X   X   X
 m(w)=0, ordinary
sage: E.is_ordinaire()
True
</pre></div>



<p>Creation of a strong-weak pair of bispecial words from a neutral
<strong>not ordinaire</strong> word:</p>


<div class="pygments_manni"><pre>sage: p23 = WordMorphism({1:[1,2,3],2:[2,3],3:[3]})
sage: e = ExtensionType1to1([(1,2),(2,3),(3,1),(3,2),(3,3)], [1,2,3])
sage: e
  E(w)   1   2   3
   1         X
   2             X
   3     X   X   X
 m(w)=0, not ord.
sage: A,B = e.apply(p23)
sage: A
  E(3w)   1   2   3
    1
    2         X   X
    3     X   X   X
 m(w)=1, not ord.
sage: B
  E(23w)   1   2   3
    1          X
    2
    3              X
 m(w)=-1, not ord.
</pre></div>



</div>
<div class="section" id="fast-kolakoski-word">
<h1>Fast Kolakoski word</h1>
<p>This module was written for fun. It uses cython implementation inspired from
the 10 lines of C code written by Dominique Bernardi and shared during Sage
Days 28 in Orsay, France, in January 2011.</p>


<div class="pygments_manni"><pre>sage: K = KolakoskiWord()
sage: K
word: 1221121221221121122121121221121121221221...
sage: %time K[10^5]
CPU times: user 1.56 ms, sys: 7 µs, total: 1.57 ms
Wall time: 1.57 ms
1
sage: %time K[10^6]
CPU times: user 15.8 ms, sys: 30 µs, total: 15.8 ms
Wall time: 15.9 ms
2
sage: %time K[10^8]
CPU times: user 1.58 s, sys: 2.28 ms, total: 1.58 s
Wall time: 1.59 s
1
sage: %time K[10^9]
CPU times: user 15.8 s, sys: 12.4 ms, total: 15.9 s
Wall time: 15.9 s
1
</pre></div>



<p>This is much faster than the Python implementation available in Sage:</p>


<div class="pygments_manni"><pre>sage: K = words.KolakoskiWord()
sage: %time K[10^5]
CPU times: user 779 ms, sys: 25.9 ms, total: 805 ms
Wall time: 802 ms
1
</pre></div>



</div>
<div class="section" id="references">
<h1>References</h1>
<table class="docutils citation" frame="void" id="bgl2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released#id3">[BGL2012]</a></td><td>A. Blondin Massé, A. Garon, S. Labbé, Combinatorial properties
of double square tiles, <em>Theoretical Computer Science</em> 502 (2013) 98-117.
<a class="reference external" href="http://dx.doi.org/10.1016/j.tcs.2012.10.040">doi:10.1016/j.tcs.2012.10.040</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lr2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released#id5">[LR2014]</a></td><td>Labbé, Sébastien, and Christophe Reutenauer. A d-dimensional Extension of
Christoffel Words. <a class="reference external" href="http://arxiv.org/abs/1404.4021">arXiv:1404.4021</a> (April 15, 2014).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="bl2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released#id7">[BL2014]</a></td><td>V. Berthé, S. Labbé, Factor Complexity of S-adic sequences
generated by the Arnoux-Rauzy-Poincaré Algorithm. <a class="reference external" href="http://arxiv.org/abs/1404.4189">arXiv:1404.4189</a> (April, 2014).</td></tr>
</tbody>
</table>
</div>
</div></div>







<p class="date">
<a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/slabbe-0.1.spkg-released">by Sébastien Labbé at August 27, 2014 04:53 PM</a>
</p>
</div>
</div>




<div class="entrygroup" id="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/releasing-slabbe-my-own-sage-package" lang="en">
<h4><a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/releasing-slabbe-my-own-sage-package">Releasing slabbe, my own Sage package</a></h4>
<div class="entry">
<div class="content">
<div class="document">
<p>Since two years I wrote thousands of line of private code for my own research.
Each module having between 500 and 2000 lines of code. The code which is the
more clean corresponds to code written in conjunction with research articles.
People who know me know that I systematically put docstrings and doctests in my
code to facilitate reuse of the code by myself, but also in the idea of sharing
it and eventually making it public.</p>
<p>I did not made that code into Sage because it was not mature enough. Also, when
I tried to make a complete module go into Sage (see <a class="reference external" href="http://trac.sagemath.org/ticket/13069">#13069</a> and <a class="reference external" href="http://trac.sagemath.org/ticket/13346">#13346</a>),
then the monstrous never evolving <a class="reference external" href="http://trac.sagemath.org/ticket/12224">#12224</a> became a dependency of the first
and the second was unofficially reviewed asking me to split it into smaller
chunks to make the review process easier. I never did it because I spent
already too much time on it (making a module 100% doctested takes time). Also,
the module was corresponding to a published article and I wanted to leave it
just like that.</p>
<p><strong>Getting new modules into Sage is hard</strong></p>
<p>In general, the introduction of a complete new module into Sage is hard
especially for beginners. Here are two examples I feel responsible for:
<a class="reference external" href="http://trac.sagemath.org/ticket/10519">#10519</a> is 4 years old and counting, the author <a class="reference external" href="http://trac.sagemath.org/ticket/10519#comment:67">has a new work and
responsabilities</a>; in <a class="reference external" href="http://trac.sagemath.org/ticket/12996">#12996</a>, the author was decouraged by the amount of
work given by the reviewers. There is a lot of things a beginner has to
consider to obtain a positive review. And even for a more advanced developper,
other difficulties arise. Indeed, a module introduces a lot of new functions
and it may also introduce a lot of new bugs... and Sage developpers are
sometimes reluctant to give it a positive review. And if it finally gets a
positive review, it is not available easily to normal users of Sage until the
next release of Sage.</p>
<p><strong>Releasing my own Sage package</strong></p>
<p>Still I felt the need around me to make my code public. But how? There are
people (a few of course but I know there are) who are interested in reproducing
computations and images done in my articles. This is why I came to the idea of
releasing my own Sage package containing my public research code. This way both
developpers and colleagues that are user of Sage but not developpers will be
able to install and use my code. This will make people more aware if there is
something useful in a module for them. And if one day, somebody tells me: &quot;this
should be in Sage&quot;, then I will be able to say : &quot;I agree! Do you want to
review it?&quot;.</p>
<p><strong>Old style Sage package</strong> vs <strong>New sytle git Sage package</strong></p>
<p>Then I had to chose between the old and the new style for Sage packages. I did
not like the new style, because</p>
<blockquote>
<ul class="simple">
<li>I wanted the history of my package to be independant of the history of Sage,</li>
<li>I wanted it to be as easy to install as <tt class="docutils literal">sage <span class="pre">-i</span> slabbe</tt>,</li>
<li>I wanted it to work on any recent enough version of Sage,</li>
<li>I wanted to be able to release a new version, give it to a colleague who
could install it right away without changing its own Sage (i.e., updating
the checksums).</li>
</ul>
</blockquote>
<p>Therefore, I choose the old style. I based my work on other optional Sage
packages, namely the <a class="reference external" href="http://sagemanifolds.obspm.fr/">SageManifolds</a> spkg and the <a class="reference external" href="http://www.risc.jku.at/research/combinat/risc/software/ore_algebra/index.php">ore_algebra</a> spkg.</p>
<p><strong>Content of the initial version</strong></p>
<p>The initial version of the slabbe Sage package has modules concerning four
topics: <em>Digital geometry</em>, <em>Combinatorics on words</em>, <em>Combinatorics</em> and
<em>Python class inheritance</em>.</p>
<a class="reference external image-reference" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/slabbe_content.png"><img alt="/~labbe/Files/2014/slabbe_content.png" src="http://www.liafa.univ-paris-diderot.fr/~labbe/Files/2014/slabbe_content.png" /></a>
<p>For installation or for release notes of the initial version of the spkg,
consult the slabbe spkg section of the <a class="reference external" href="http://www.liafa.univ-paris-diderot.fr/~labbe/Sage">Sage</a> page of this website.</p>
</div></div>







<p class="date">
<a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/2014/08/releasing-slabbe-my-own-sage-package">by Sébastien Labbé at August 27, 2014 04:48 PM</a>
</p>
</div>
</div>



</div>
<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-5041553718036647954">
<h4><a href="http://sagemath.blogspot.com/2014/08/what-is-sagemathcloud-lets-clear-some.html">What is SageMathCloud: let's clear some things up</a></h4>
<div class="entry">
<div class="content">
<span>[PDF version of this blog post]</span><br /><blockquote><i>"You will have to close source and commercialize Sage. It's inevitable."</i> -- Michael Monagan, cofounder of Maple, told me this in 2006.</blockquote><a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud (SMC) </a>is a website that I first launched in April 2013, through which you can use Sage and all other open source math software online, edit Latex documents, IPython notebooks, Sage worksheets, track your todo items, and many other types of documents. You can write, compile, and run code in most programming languages, and use a color command line terminal. There is realtime collaboration on everything through shared projects, terminals, etc. Each project comes with a default quota of 5GB disk space and 8GB of RAM.<br /><br /><a href="https://cloud.sagemath.com/" target="_blank">SMC</a> is fun to use, pretty to look at, frequently backs up your work in many ways, is fault tolerant, encourages collaboration, and provides a web-based way to use standard command-line tools.<br /><br /><h3 id="the-relationship-with-the-sagemath-software">The Relationship with the <a href="http://sagemath.org/">SageMath Software</a></h3>The goal of the SageMath software project, which I founded in 2005, is to create a viable free open source alternative to Magma, Mathematica, Maple, and Matlab. <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> is <strong>not</strong> mathematics software -- instead, <a href="https://cloud.sagemath.com/" target="_blank">SMC </a>is best viewed by analogy as a browser-based version of a Linux desktop environment like KDE or Gnome. The vast majority of the code we write for <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> involves text editor issues (problems similar to those confronted by Emacs or Vim), personal information management, support for editing LaTeX documents, terminals, file management, etc. There is almost no mathematics involved at all.<br /><br />That said, the main software <em>I</em> use is Sage, so of course support for Sage is a primary focus. <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> is a software environment that is being optimized for its users, who are mostly college students and teachers who use Sage (or Python) in conjunction with their courses. A big motivation for the existence of <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> is to make Sage much more accessible, since growth of Sage has stagnated since 2011, with the number one show-stopper obstruction being the difficulty of students installing Sage.<br /><h4 id="sage-is-failing">Sage is Failing</h4>Measured by the mission statement, Sage has overall failed. The core goal is to provide similar functionality to Magma (and the other Ma's) across the board, and the Sage development model and community has failed to do this across the board, since after 9 years, based on our current progress, we will never get there. There are numerous core areas of research mathematics that I'm personally familiar with (in arithmetic geometry), where Sage has barely moved in years and Sage does only a few percent of what Magma does. Unless there is a viable plan for the areas to <strong>all</strong> be systematically addressed in a reasonable timeframe, not just with arithmetic geometry in Magma, but with everything in Mathematica, Maple., etc, we are definitely failing at the main goal I have for the Sage math software project.<br /><br />I have absolutely no doubt that money combined with good planning and management would make it possible to achieve our mission statement. I've seen this hundreds of times over at a small scale at Sage Days workshops during the last decade. And let's not forget that with very substantial funding, Linux now provides a viable free open source alternative to Microsoft Windows. Just providing Sage developers with travel expenses (and 0 salary) is enough to get a huge amount done, when possible. But all my attempts with foundations and other clients to get any <em>significant</em> funding, at even the level of 1% of the funding that Mathematica gets each year, has failed. For the life of the Sage project, we've never got more than maybe 0.1% of what Mathematica gets in revenue. It's just a fact that the mathematics community provides Mathematica $50+ million a year, enough to fund over 600 fulltime positions, and they won't provide enough to fund one single Sage developer fulltime.<br /><br />But the Sage mission statement remains, and even if everybody else in the world gives up on it, <strong>I HAVE NOT</strong>. <a href="https://cloud.sagemath.com/" target="_blank">SMC </a>is my last ditch strategy to provide resources and visibility so we can succeed at this goal and give the world a viable free open source alternative to the Ma's. I wish I were writing interesting mathematical software, but I'm not, because I'm sucking it up and playing the long game.<br /><br /><h3 id="the-users-of-smc">The Users of <a href="https://cloud.sagemath.com/" target="_blank">SMC</a></h3>During the last academic year (e.g., April 2014) there were about 20K "monthly active users" (as defined by Google Analytics), 6K weekly active users, and usually around 300 simultaneous connected users. The summer months have been slower, due to less teaching.<br /><br />Numerically most users are undergraduate students in courses, who are asked to use <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> in conjunction with a course. There's also quite a bit of usage of <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> by people doing research in mathematics, statistics, economics, etc. -- pretty much all computational sciences. Very roughly, people create Sage worksheets, IPython notebooks, and Latex documents in somewhat equal proportions.<br /><h3 id="what-smc-runs-on">What <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> runs on</h3>Technically, SMC is a multi-datacenter web application without specific dependencies on particular cloud provider functionality. In particular, we use the Cassandra database, and custom backend services written in Node.js (about 15,000 lines of backend code). We also use Amazon's Route 53 service for geographically aware DNS. There are two racks containing dedicated computers on opposites sides of campus at University of Washington with 19 total machines, each with about 1TB SSD, 4TB+ HDD, and 96GB RAM. We also have dozens of VM's running at 2 Google data centers to the east.<br /><br />A substantial fraction of the work in implementing <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> has been in designing and implementing (and reimplementing many times, in response to real usage) a robust replicated backend infrastructure for projects, with regular snapshots and automatic failover across data centers. As I write this, users have created 66677 projects; each project is a self-contained Linux account whose files are replicated across several data centers.<br /><h3 id="the-source-code-of-smc">The Source Code of <a href="https://cloud.sagemath.com/" target="_blank">SMC</a></h3>The underlying source of SMC, both the backend server and frontend client, is mostly written in CoffeeScript. The frontend (which is nearly 20,000 lines of code) is implemented using the "progressive refinement" approach to HTML5/CSS/Javascript web development. We do not use any Javascript single page app frameworks, though we make heavy use of Bootstrap3 and jQuery. All of the library dependencies of SMC, e.g., CodeMirror, Bootstrap, jQuery, etc. for SMC are licensed under very permissive BSD/MIT, etc. libraries. In particular, absolutely nothing in the Javascript software stack is GPL or AGPL licensed. The plan is that any SMC source code that will be open sourced will be released under the BSD license. Some of the SMC source code is not publicly available, and is owned by University of Washington. But other code, e.g., the realtime sync code, is already available.<br />Some of the functionality of SMC, for example Sage worksheets, communicate with a separate process via a TCP connection. That separate process is in some cases a GPL'd program such as Sage, R, or Octave, so the viral nature of the GPL does not apply to SMC. Also, of course the virtual machines are running the Linux operating system, which is mostly GPL licensed. (There is absolutely no AGPL-licensed code anywhere in the picture.)<br /><br />Note that since none of the SMC server and client code links (even at an interpreter level) with any GPL'd software, that code can be legally distributed under any license (e.g., from BSD to commercial).<br />Also we plan to create a fully open source version of the Sage worksheet server part of SMC for inclusion with Sage. This is not our top priority, since there are several absolutely critical tasks that still must be finished first on SMC, e.g., basic course management.<br /><h3 id="the-smc-business-model">The <a href="https://cloud.sagemath.com/" target="_blank">SMC</a> Business Model</h3>The University of Washington Center for Commercialization (C4C) has been very involved and supportive since the start of the projects. There are no financial investors or separate company; instead, funding comes from UW, some unspent grant funds that were about to expire, and a substantial Google "Academic Education Grant" ($60K). Our first customer is the "US Army Engineer Research and Development Center", which just started a support/license agreement to run their own SMC internally. We don't currently offer a SaaS product for sale yet -- the options for what can be sold by UW are constrained, since UW is a not-for-profit state university. Currently users receive enhancements to their projects (e.g., increased RAM or disk space) in exchange for explaining to me the interesting research or teaching they are doing with <a href="https://cloud.sagemath.com/">SMC.</a><br /><br />The longterm plan is to start a separate for-profit company if we build a sufficient customer base. If this company is successful, it would also support fulltime development of Sage (e.g., via teaching buyouts for faculty, support of students, etc.), similar to how Magma (and Mathematica, etc.) development is funded.<br /><br />In conclusion, in response to Michael Monagan, you are wrong. And you are right.</div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/08/what-is-sagemathcloud-lets-clear-some.html">by William Stein (noreply@blogger.com) at August 27, 2014 06:55 AM</a>
</p>
</div>
</div>




<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-2620037689426510230">
<h4><a href="http://sagemath.blogspot.com/2014/08/you-dont-really-think-that-sage-has.html">You don't really think that Sage has failed, do you?</a></h4>
<div class="entry">
<div class="content">
<div>I just received an email from a postdoc in Europe, and very longtime contributor to the<a href="http://sagemath.org/" target="_blank"> Sage project</a>. &nbsp;He's asking for a letter of recommendation, since he has to leave the world of mathematical software development (after a decade of training and experience), so that he can take a job at hedge fund. &nbsp;He ends his request with the question:</div><div><br /></div><div>&gt; P.S. You don't _really_ think that Sage has failed, do you?<br /><br />After almost exactly 10 years of working on the <a href="http://sagemath.org/" target="_blank">Sage project</a>, I absolutely do think it has failed to accomplish the stated goal of the mission statement: "<em>Create a viable free open source alternative to Magma, Maple, Mathematica and Matlab</em><span>."</span>. &nbsp; &nbsp; When it was only a few years into the project, it was really hard to evaluate progress against such a lofty mission statement. &nbsp;However, after 10 years, it's clear to me that not only have we not got there, we are not going to ever get there before I retire. &nbsp; And that's definitely a failure. &nbsp;&nbsp;</div><div><br /></div><div>Here's a very rough quote I overheard at lunch today at <a href="http://wiki.sagemath.org/days61" target="_blank">Sage Days 61</a>, from John Voight, who wrote much quaternion algebra code in <a href="http://magma.maths.usyd.edu.au/magma/" target="_blank">Magma</a>: "I'm making a list of what is missing from Sage that Magma has for working with quaternion algebras. &nbsp;However, it's so incredibly daunting, that I don't want to put in everything. &nbsp;I've been working on Magma's quaternion algebras for over 10 years, as have several other people. &nbsp;It's truly daunting how much functionality Magma has compared to Sage."</div><div><br /></div><div>The only possible way Sage will not fail at the stated mission is if I can get several million dollars a year in money to support developers to work fulltime on implementing interesting core mathematical algorithms. &nbsp;This is something that Magma has had for over 20 years, and that Maple, Matlab, and Mathematica also have. &nbsp; That I don't have such funding is probably why you are about to take a job at a hedge fund. &nbsp; &nbsp;If I had the money, I would <b><i>try</i></b> to hire a few of the absolute best people (rather than a bunch of amateurs), people like you, Robert Bradshaw, etc. -- we know who is good. (And clearly I mean serious salaries, not grad student wages!)</div><div><br /></div><div>So yes, I think the current approach to Sage has failed. &nbsp; &nbsp;I am going to try another approach, namely <a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a>. &nbsp;If it works, maybe the world will get a free open source alternative to Magma, Mathematica, etc. &nbsp;Otherwise, maybe the world never ever will. &nbsp; &nbsp; &nbsp;If you care like I do about having such a thing, and you're teaching course, or whatever, maybe try using <a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a>. &nbsp; If enough people use <a href="https://cloud.sagemath.com/" target="_blank">SageMathCloud</a> for college teaching, then maybe a business model will emerge, and Sage will get proper funding. &nbsp;&nbsp;</div></div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/08/you-dont-really-think-that-sage-has.html">by William Stein (noreply@blogger.com) at August 27, 2014 06:52 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>August 23, 2014</h2>

<div class="channelgroup">







<h3><a href="http://blog.hav3n.net/?tag=gsoc-2014" title="Nikhil's GSoC Blog » GSoC 2014">Nikhil Peter</a></h3>


<div class="entrygroup" id="http://blog.hav3n.net/?p=45" lang="en-US">
<h4><a href="http://blog.hav3n.net/?p=45">GSoC: An End, And A New Beginning</a></h4>
<div class="entry">
<div class="content">
Well, it&#8217;s officially done. As per my proposal, the project has been officially completed. It&#8217;s been a rollercoaster ride of new experiences, a ton of code(by my count its somewhere around 20k lines or so, but GitHub shows a much larger number) and some unforgettable memories. The app is nowhere near perfect, however, and I [&#8230;]</div>







<p class="date">
<a href="http://blog.hav3n.net/?p=45">by hav3n at August 23, 2014 09:15 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>August 22, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-1747499748510710173">
<h4><a href="http://mathandhats.blogspot.com/2014/08/gsoc-wrapping-up.html">GSoC: Wrapping Up</a></h4>
<div class="entry">
<div class="content">
Today marks the last day of my Google Summer of Code 2014 project. Evaluations are due midday Friday PDT, and code submissions for successfully passed projects start soon thereafter. The end result of my project can be found at Sage <a href="http://trac.sagemath.org/ticket/16773">Trac Ticket 16773</a>. In total it's just over 2000 lines of Python and Cython code, to be added to the next major Sage release (6.4) if/when it gets a final thumbs-up review.<br /><br />When I write just the number of lines of code it doesn't sound like very much at all - I'm sure there are GSoC projects this year that produced at least 10k lines of code! However, given that what I wrote is complex mathematical code that needed a) significant optimization, and b) to be be mathematically sound in the first place, I'd say that isn't too bad. Especially since the code does what the project description aimed for it to do: compute analytic ranks of rational elliptic curves very quickly with a very low rate of failure. Hopefully this functionality can and will be used to produce numerical data for number theory research in the years to come.<br /><br />The Google Summer of Code has been a thoroughly rewarding experience for me. It's a great way to sharpen one's coding skills and get paid in the process. I recommend it for any university student who's looking to go into any industry that requires programming skills; I'd apply to do it again next year if I wasn't planning to graduate then!</div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/08/gsoc-wrapping-up.html">by Simon Spicer (noreply@blogger.com) at August 22, 2014 09:04 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>August 18, 2014</h2>

<div class="channelgroup">







<h3><a href="http://blog.harald.schil.ly/search/label/sage" title="Harald Schilly">Harald Schilly</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-3473399517246044360.post-7007006977497989671">
<h4><a href="http://blog.harald.schil.ly/2014/08/new-combinatorial-designs-in-sage-by.html">New combinatorial designs in Sage - by Nathann Cohen</a></h4>
<div class="entry">
<div class="content">
<div dir="ltr"><div>This is a guest post by Nathann Cohen.&nbsp;</div><hr size="1" /><br /><h2>New combinatorial designs in Sage</h2><div>Below, these graphs are a decomposition of a $K_{13}$ (i.e. the complete graph on 13 points) into copies of $K_4$. Pick two vertices you like: they appear exactly once together in one of the $K_4$.</div><div><br /></div><div><br /></div><div class="separator"><a href="http://1.bp.blogspot.com/-1SBIfp8sEvk/U_IG5p8AdXI/AAAAAAAAcMc/nK8044Ld6aY/s1600/bidis.png"><img border="0" src="http://1.bp.blogspot.com/-1SBIfp8sEvk/U_IG5p8AdXI/AAAAAAAAcMc/nK8044Ld6aY/s1600/bidis.png" height="400" width="398" /></a></div><div>The second graph shows a decomposition of  a $K_{4,4,4}$ (i.e. the complete multipartite graph on $4\times 3$ points) into  copies of $K_3$. Pick two vertices you like from different groups: they  appear exactly once together in one of the $K_4$.</div><div><br /></div><br /><div class="separator"><a href="http://1.bp.blogspot.com/-2iuNNiHo9As/U_IG7AZEGrI/AAAAAAAAcMk/lfIOKmKHXDE/s1600/TDs.png"><img border="0" src="http://1.bp.blogspot.com/-2iuNNiHo9As/U_IG7AZEGrI/AAAAAAAAcMk/lfIOKmKHXDE/s1600/TDs.png" height="365" width="400" /></a></div><div><br /></div><div><div><br />Sage  has gotten quite good at building such decompositions (a specific kind  of combinatorial designs) when they exist. This post is about them.</div></div><div><br /></div>The first object belongs to a family called <b>Balanced Incomplete Block Designs (or $(n,k)$-BIBD)</b>, which are defined as "a collection $\mathcal S$ of sets, all of them with size $k$ (here $k=4$), such that any pair of points of a set $X$ with $|X|=n$ (here $n=13$) appears in exactly one set of $\mathcal S$".<br /><br />The second belongs to the family of <b>Transversal Designs (or $TD(k,n)$)</b> which have a similar definition: consider a set $X$ containing $k$ groups (here $k=3$) of $n$ vertices (here $n=4$). A collection $\mathcal S$ of sets, each of which contains one point from each group, is a $TD(k,n)$ if any two points from different groups appear together in exactly one set of $\mathcal S$.<br /><br /> The main problem with combinatorial designs is to know where they exist. And that is not obvious. Sage does what it can on about that:  <br /><ul><li> If you want it to build a $(14,4)$-BIBD, it will tell you that none exists. </li><li> If you want it to build a $(16,4)$-BIBD, it will tell you that one exists. </li><li> If you want it to build a $(51,6)$-BIBD, it will tell you that it just not know if there is one (and nobody knows better at the moment) </li></ul>Examples here:<br /><br /><span><span>sage: designs.balanced_incomplete_block_design(14,4,existence=True)</span></span><br /><span><span>False</span></span><br /><span><span>sage: designs.balanced_incomplete_block_design(16,4,existence=True)</span></span><br /><span><span>True</span></span><br /><span><span>sage: designs.balanced_incomplete_block_design(51,6,existence=True)</span></span><br /><span><span>Unknown</span></span><br /><br />For a developer (and design lover), the game consists in teaching Sage how to build all combinatorial designs that appear in some research paper. For BIBD as well as for Transversal Designs, on which a LOT of sweat was spent these last months.<br /><br />For Transversal designs the game is a bit different, as we know that a $TD(k-1,n)$ exists whenever a $TD(k,n)$ exists. Thus, the game consists in finding the largest integer $k_n$ such that a $TD(k_n,n)$ exists. This game is hardly new, and hardly straightforward: In the Handbook of Combinatorial Designs, one can find the table of such $k$ up to $n=10000$ (see <a href="http://books.google.fr/books?id=S9FA9rq1BgoC&dq=handbook%20combinatorial%20designs%20MOLS%2010000&pg=PA176">here</a>).<br /><br />The good thing about Sage is that it does not just claim that such a design exists: it also builds it, and there is no better existence proof than that (it is very very quick to check that a combinatorial design is valid).  The <i>other</i> good thing is that there is no common database for such data (the Handbook is not updated/printed every night), and that by teaching Sage all new designs found by researchers we build such a database. And it already contains designs that were not known when the Handbook was printed.<br /><br />Finally, the <i>other other</i> good thing about Sage is that it will soon be able to tell you where those designs  come from. Indeed, the most powerful results in the field of Transversal Designs are of the shape "If there exists a $TD(k_1,n_1)$, and a $TD(k_2,n_2)$, ..., and a $TD(k_c,n_c)$, then you can combine them all to obtain a $TD(k,n)$ with $k=k(k_1,...,k_c)$ and $n=n(n_1,...,n_c)$". And it is never very clear how to inverse these functions: if you want to build a $TD(k,n)$, which integers $k_1,...,k_c,n_1,...,n_c$ should you pick ?<br /><br /> Sage knows. It must know it, in order to build these designs anyway. And you can find that data inside. And soon, we will teach it to give you the bibliographical references of the papers in which you can find the right construction to produce the $TD(k,n)$ that you want. And we will provide the right parameters. And the world will be at peace.<br /><br /> A couple of things before we part: <br /><ul><li>Transversal Designs (TD), Orthogonal Arrays (OA), and Mutually Orthogonal Latin Squares (MOLS) are all equivalent objects. </li><li>We write a LOT of Transversal Designs code these days, so expect all this to improve very fast. </li><li>You can learn what Sage knows of combinatorial designs <a href="http://www.sagemath.org/doc/reference/combinat/designs.html">right here</a>. </li></ul>Finally, there are far too many combinatorial designs for one man to learn. If you love combinatorial designs, come join us: <a href="http://www.labri.fr/perso/vdelecro/">Vincent Delecroix</a>, you, <a href="http://www.steinertriples.fr/ncohen/">and I</a> have code to write together. And if you know a related mathematical results that Sage ignores, come tell us: we could not have gone so far without the mathematical knowledge of <a href="https://research.unsw.edu.au/people/dr-julian-abel">Julian Abel</a>. And Sage does not know everything yet.<br /><br />Have fuuuuuuuuuuuuuuuuuuun !<br /><br />Nathann </div></div>







<p class="date">
<a href="http://blog.harald.schil.ly/2014/08/new-combinatorial-designs-in-sage-by.html">by Harald Schilly (noreply@blogger.com) at August 18, 2014 08:32 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>August 15, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-6909482725868653356">
<h4><a href="http://mathandhats.blogspot.com/2014/08/how-big-should-delta-be.html">How big should Delta be?</a></h4>
<div class="entry">
<div class="content">
Let's take a look at the central formula in my GSoC rank estimation code. Let $E$ be a rational elliptic curve with analytic rank $r$. Then<br />$$ r &lt; \sum_{\gamma} \text{sinc}^2(\Delta\gamma) = &nbsp;\frac{1}{\pi\Delta} \left[ C_0 + \frac{1}{2\pi\Delta}\left(\frac{\pi^2}{6}-\text{Li}_2\left(e^{-2\pi\Delta}\right) \right) + \sum_{n=1}^{e^{2\pi\Delta}} c_n\left(1 - \frac{\log n}{2\pi\Delta}\right) \right] $$<br />where<br /><br /><ul><li>$\gamma$ ranges over the nontrivial zeros of the $L$-function attached to $E$</li><li>$\Delta$ is a positive parameter</li><li>$C_0 = -\eta + \log\left(\frac{\sqrt{N}}{2\pi}\right)$; $\eta$ is the Euler-Mascheroni constant $=0.5772\ldots$ and $N$ is the conductor of $E$</li><li>$\text{Li}_2(x)$ is the dilogarithm function, defined by $\text{Li}_2(x) = \sum_{k=1}^{\infty} \frac{x^k}{k^2}$</li><li>$c_n$ is the $n$th coefficient of the logarithmic derivative of the $L$-function of $E$.</li></ul><div>The thing I want to look at in this post is that parameter $\Delta$. The larger you make it, the closer the sum on the left hand side over the zeros is to the analytic rank, so when trying to determine the rank of $E$ we want to pick as large a $\Delta$ as we can. However, the bigger this parameter is the more terms we have to compute in the sum over the $c_n$ on the right hand side; moreover the number of terms - and thus the total computation time - scales exponentially with $\Delta$. This severely constrains how big we can make $\Delta$; generally a value of $\Delta=2$ may take a second or two for a single curve on SageMathCloud, while $\Delta=3$ may take upwards of an hour. For the <a href="http://mathandhats.blogspot.com/2014/07/the-average-rank-of-elliptic-curves.html">average rank project</a>&nbsp;I'm working on I ran the code on 12 million curves using $\Delta=1.3$; the total computation time was about 4 days on SMC.</div><div><br /></div><div>However, it should be clear that using too large a $\Delta$ is overkill: if you run the code on a curve with $\Delta=1$ and get a bound of zero out, you know that curve's rank exactly zero (since it's at most zero, and rank is a non-negative integer). Thus using larger $\Delta$ values on that curve will do nothing except provide you the same bound while taking much longer to do so.</div><div><br /></div><div>This begs the question: just how big of a $\Delta$ value is good enough? Can we, given some data defining an elliptic curve, decide a priori what size $\Delta$ to use so that a) the computation returns a bound that is likely to be the true of the curve, and b) it will do so in as little time as possible?</div><div><br /></div><div>The relevant invariant to look at here is conductor $N$ of the elliptic curve; go back to the formula above and you'll see that the zero sum includes a term which is $O\left(\frac{\log(N)}{2\pi\Delta}\right)$ (coming from the $\frac{1}{\pi \Delta} C_0$ term). This means that size of the returned estimate will scale with $\log(N)$: for a given $\Delta$, the bound returned on a curve with 10-digit conductor will be about double that which is returned for a 5-digit conductor curve, for example. However, we can compensate this by increasing $\Delta$ accordingly.</div><div><br /></div><div>To put it all more concretely we can pose the following questions:</div><div><ul><li>Given an elliptic curve $E$ with conductor $N$, how large does $\Delta$ need to be in terms of $N$ so that the returned bound is <i>guaranteed</i> to be the true analytic rank of the curve?</li><li>Given a conductor size $N$ and a proportionality constant $P \in [0,1]$, how big does $\Delta$ have to be in terms of $N$ and $P$ so that at least $P\cdot 100$ percent of all elliptic curves with conductor of size about $N$ will, when the rank estimation code is run on them with that $\Delta$ value, yield returned bounds that are equal to their true analytic rank?</li></ul><div>[Note: in both of the above questions we are making the implicit assumption that the returned rank bound is monotonically decreasing for increasing $\Delta$. This is not necessarily the case: the function $y = \text{sinc}^2(x)$ is <i>not</i> a decreasing function in $x$. However, in practice any upwards fluctuation we see in the zero sum is small enough to be eliminated when we take the floor function to get an integer rank bound.]</div></div><div><br /></div><h3>A $\Delta$ CHOICE GOOD ENOUGH FOR MOST CURVES</h3><div><br /></div><div>The first question is easier to phrase, but more difficult to answer, so we will defer it for now. To answer the second question, it is useful mention what we know about the distribution and density of nontrivial zeros of an elliptic curve $L$-function.</div><div><br /></div><div>Using some complex analysis we can show that, for the $L$-function of an elliptic curve with conductor $N$, the expected number of zeros in the critical strip with imaginary part at most $T$, is $O(T\log N+ T\log T)$. That is, expected zero density has two distinct components: a part that scales linearly with log of the conductor, and a part that doesn't scale with conductor (but does scale slightly faster than linearly with how far out you go).</div><div><br /></div><div>Consider the following: if we let&nbsp;</div><div>$$\Delta(N) = \frac{C_0}{\pi} = \frac{1}{\pi}\left(-\eta+\log\left(\frac{\sqrt{N}}{2\pi}\right)\right)$$</div><div>then the first term in the right hand side of the zero sum formula is precisely 1 - this is the term that comes from the $\log N$ part of the zero density. The next term - the one involving $\frac{\pi^2}{6}-\text{Li}_2\left(e^{-2\pi\Delta}\right)$ - is the term that comes from the part independent of $N$; because the right hand side is divided by $\Delta$ it therefore goes to zero as the curve's conductor increases. The third term contains the $c_n$ coefficients which (per Sato-Tate) will be positive half the time and negative half the time, so the entire sum could be positive or negative; we therefore expect its contribution to be small on average when we look at large number of elliptic curves.</div><div><br /></div><div>It thus stands to reason that for this value of Delta, and when the conductor $N$ is sufficiently large, the zero sum will be about 1, plus or minus a smallish amount coming from the $c_n$ sum. This argument is by no means rigorous, but we might therefore expect the zero sum to be within 2 of the actual analytic rank most of the time. Couple that with knowledge of the root number and you get a rank upper bound out which is equal to the actual analytic rank in all but a few pathological cases.</div><div><br /></div><div>Empirical evidence bears this out. I ran my rank estimation code with this choice of $\Delta$ scaling on the whole Cremona database, which contains all elliptic curves up to conductor 350000:</div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container"><tbody><tr><td><a href="http://3.bp.blogspot.com/-EDLl7VqZs_Q/U-ED2Og5lyI/AAAAAAAAAGE/lETBP5vrWGI/s1600/rkub_ne_rk.png"><img border="0" src="http://3.bp.blogspot.com/-EDLl7VqZs_Q/U-ED2Og5lyI/AAAAAAAAAGE/lETBP5vrWGI/s1600/rkub_ne_rk.png" height="191" width="400" /></a></td></tr><tr><td class="tr-caption">The proportion of curves up to conductor $N$ for which the computed rank bound is strictly greater than rank. The $x$-axis denotes conductor; the $y$-axis is the proportion of all curves up to that conductor for which&nbsp;the returned rank bound was <i>not</i> equal to the true rank (assuming BSD and GRH as always).</td></tr></tbody></table><div>As you can see, the percentage of curves for which the rank bound is strictly greater than rank holds fairly constant at about 0.25%. That's minuscule: what this is saying is that if you type in a random Weierstrass equation, there is only about a 1 in 1000 chance that the rank bounding code with $\Delta = \frac{C_0}{\pi}$ will return a value that isn't the actual analytic rank. Moreover, the code runs <i>considerably</i> faster than traditional analytic rank techniques, so if you wanted to, for example, <a href="http://mathandhats.blogspot.com/2014/07/the-average-rank-of-elliptic-curves.html">compute the ranks of a database of millions of elliptic curves,</a> this would be a good first port of call.</div><div><br /></div><div>Of course, this $\Delta$ scaling approach is by no means problem-free. Some more detailed analysis will show that that as stated above, the runtime of the code will actually be $O(N)$ (omitting log factors), i.e. asymptotic scaling is actually <i>worse</i> than traditional analytic rank methods, which rely on evaluating the $L$-function directly and thus are $O(\sqrt{N})$. It's just that with this code we have some very small constants sitting in front, so the crossover point is at large enough conductor values that neither method is feasible anyway.&nbsp;</div><div><br /></div><div>This choice of $\Delta$ scaling works for conductor ranges up to about $10^9$; that corresponds to $\Delta \approx 2.5$, which will give you a total runtime of about 10-20 seconds for a single curve on SMC. Increase the conductor by a factor of 10 and your runtime will also go up tenfold.</div><div><br /></div><div>For curves of larger conductor, instead of setting $\Delta = \frac{C_0}{\pi}$ we can choose to set $\Delta$ to be $\alpha\cdot \frac{C_0}{\pi}$ for any $\alpha \in [0,1]$; the resulting asymptotic runtime will then be $O(N^{\alpha})$, at the expense of having a reduced proportion of elliptic curves where rank bound is equal to true rank.</div><div><br /></div><h3>HOW LARGE DOES $\Delta$ HAVE TO BE TO GUARANTEE TRUE RANK?</h3><div><br /></div><div>When we use $\Delta = \frac{C_0}{\pi}$, the curves for which the returned rank estimate is strictly larger than the true rank are precisely those which have unusually low-lying zeros. For example, the rank 0 curve with Cremona label 256944c1, has a zero with imaginary part at 0.0256 (<a href="http://mathandhats.blogspot.com/2014/07/the-birch-and-swinnerton-dyer.html">see here for a plot</a>), compared to an expected value of 0.824. Using $\Delta = \frac{C_0}{\pi}$ on this curve means $\Delta \approx 1.214$; if we compute the corresponding zero sum with this value of $\Delta$ we get a value of 2.07803. The smallest value of $\Delta$ for which we get a zero sum value of less than 2 is empirically about 2.813; at this point taking the floor and invoking parity tells us that the curve's rank is zero.</div><div><br /></div><div>The above example demonstrates that if we want to guarantee that the returned rank bound is the true analytic rank, we are forced to increase the size of $\Delta$ to something larger than $\frac{C_0}{\pi}$. Do we need to increase $\Delta$ by a fixed value independent of $N$? Do we need to increase it by some constant factor? Or does it need to scale faster than $\log N$? These are hard questions to answer; it comes down to determining how close to the central point the lowest nontrivial zero can be as a function of the conductor $N$ (or some other invariants of $E$), which in turn is intimately related to estimating the size of the leading coefficient of the $L$-series of $E$ at the central point.&nbsp;<a href="http://mathandhats.blogspot.com/2014/07/the-birch-and-swinnerton-dyer.html">This is already the topic of a previous post</a>:&nbsp;it is a question that I hope to make progress in answering in my PhD dissertation.</div><div><br /></div></div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/08/how-big-should-delta-be.html">by Simon Spicer (noreply@blogger.com) at August 15, 2014 09:44 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>August 14, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-4086157401194135973">
<h4><a href="http://mathandhats.blogspot.com/2014/08/things-are-better-in-parallel.html">Things are Better in Parallel</a></h4>
<div class="entry">
<div class="content">
A recent improvement I've implemented in my GSoC code is to allow for parallelized computation. The world has rapidly moved to multi-core as a default, so it makes sense to write code that can exploit this. And it turns out that the zero sum rank estimation method that I've been working on can be parallelized in a very natural way.<br /><br /><h3>THE&nbsp;<span>@parallel</span> DECORATOR IN SAGE</h3><br />But first: how does one compute in parallel in Sage? Suppose I have written a function in a Sage environment (e.g. a SageMathCloud worksheet, .sage file, Sage console etc.) which takes in some input and returns some other input. The simple example <span>f</span> below takes in a number <span>n</span> and returns the square of that number.<br /><br /><div><div><span>sage:&nbsp;</span>def&nbsp;f(n):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;n*n</div><div><span>....:&nbsp;</span></div><div><span>sage:&nbsp;</span>f(2),f(3),f(5)</div><div>(4,&nbsp;9,&nbsp;25)</div></div><br />This is a fairly straightforward beast; put in a value, get a value out. But what if we have some computation that requires evaluating that function on a large number of inputs? For example, say we want to compute the sum of the first 10 million squares. If you only have one processor to tap, then you're limited to calling <span>f</span> over and over again in series:<br /><br /><div><div><div><div><span>sage:&nbsp;</span>def&nbsp;g(N):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;=&nbsp;0</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;n&nbsp;in&nbsp;range(N+1):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;+=&nbsp;f(n)</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;y</div><div><span>....:&nbsp;</span></div><div><span>sage:&nbsp;</span>%time&nbsp;g(10000000)</div><div>CPU&nbsp;times:&nbsp;user&nbsp;17.5&nbsp;s,&nbsp;sys:&nbsp;214&nbsp;ms,&nbsp;total:&nbsp;17.7&nbsp;s</div><div>Wall&nbsp;time:&nbsp;17.6&nbsp;s</div><div>333333383333335000000</div></div></div></div><br />In this example you could&nbsp;of course invoke the&nbsp;<a href="http://en.wikipedia.org/wiki/Square_pyramidal_number">formula for the sum of the first $n$ squares</a>&nbsp;and just write down the answer without having to add anything up, but in general you won't be so lucky. You can optimize the heck out of <span>f</span>, but in general when you're limited to a single processor you're confined to iterating over all the values you need to consider sequentially .<br /><br />However, if you have 2 processors available one could try write code that splits the work into two roughly equal parts that can run relatively independently. For example, for our function we could compute the sum of all the even squares up to a given bound in one process and the sum of all the odd squares in another, and then add the two results together to get the sum of all square up to our bound.<br /><br />Sage has a readily available mechanism to do exactly this: the <span>@parallel</span> decorator. To enable parallel computation in your function,&nbsp;put&nbsp;<span>@parallel</span> above your function definition (<a href="http://www.sagemath.org/doc/reference/parallel/sage/parallel/decorate.html">the decorator can take some parameters</a>; below&nbsp;<span>ncpus=2</span> tells it that we want to use 2 processors). Note that we also have to modify the function: now it no longer only takes the bound up to which we must add squares, but also a flag indicating whether we should consider even or odd squares.<br /><br /><div><div><div><span>sage:&nbsp;</span>@parallel(ncpus=2)</div><div><span>....:&nbsp;</span>def&nbsp;h(N,parity):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;=&nbsp;0</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;parity=="even":</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nums&nbsp;=&nbsp;range(0,N+1,2)</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;elif&nbsp;parity=="odd":</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nums&nbsp;=&nbsp;range(1,N+1,2)</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;n&nbsp;in&nbsp;nums:</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;+=&nbsp;f(n)</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;y</div></div></div><div><br /></div><div>Instead of calling <span>h</span> with its standard sequence of parameters, we can pass it a list of tuples, where each tuple is a valid sequence of inputs. Sage then sends each tuple of inputs off to an available processor and evaluates the function on them there. What's returned is a generator object that can iterate over all the outputs; we can always see the output directly by calling <span>list()</span> on this returned generator:</div><div><br /></div><div><div><div><div><span>sage:&nbsp;</span>for&nbsp;tup&nbsp;in&nbsp;list(h([(1000,"even"),(1000,"odd")])):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;print(tup)</div><div><span>....:&nbsp;</span></div><div>(((1000,&nbsp;'even'),&nbsp;{}),&nbsp;167167000)</div><div>(((1000,&nbsp;'odd'),&nbsp;{}),&nbsp;166666500)</div></div></div></div><div><br /></div><div>Note that the tuple of inputs is also returned. Because we're doing things in parallel, we need to know which output corresponds to which input, especially since processes may finish at different times and return order is not necessarily the same as the order of the input list.</div><div><br /></div><div>Finally, we can write a wrapper function which calls our parallelized function and combines the returned results:</div><div><br /></div><div><div><div><span>sage:&nbsp;</span>def&nbsp;i(N):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;=&nbsp;0</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;output&nbsp;in&nbsp;h([(N,"even"),(N,"odd")]):</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y&nbsp;+=&nbsp;output[1]</div><div><span>....:&nbsp;</span>&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;y</div><div><span>....:&nbsp;</span></div><div><span>sage:&nbsp;</span>%time&nbsp;i(10000000)</div><div>CPU&nbsp;times:&nbsp;user&nbsp;1.76&nbsp;ms,&nbsp;sys:&nbsp;33.2&nbsp;ms,&nbsp;total:&nbsp;35&nbsp;ms</div><div>Wall&nbsp;time:&nbsp;9.26&nbsp;s</div><div>333333383333335000000</div></div></div><div><span><br /></span></div><div><span>Note that </span><span>i(10000000)</span> produces the same output at <span>g(10000000)</span> but in about half the time, as the work is split between two processes instead of one. This is the basic gist of parallel computation: write code that can be partitioned into parts that can operate (relatively) independently; run those parts on different processors simultaneously; and then collect returned outputs and combine to produce desired result.<br /><br /><h3>PARALLELIZING THE ZERO SUM COMPUTATION</h3></div><div><br /></div><div>Let's take a look at the rank estimating zero formula again. Let $E$ be a rational elliptic curve with analytic rank $r$. Then<br /><br />\begin{align*}<br />r &lt; \sum_{\gamma} \text{sinc}^2(\Delta\gamma) &amp;= &nbsp;\frac{1}{\pi \Delta}\left(-\eta+\log\left(\frac{\sqrt{N}}{2\pi}\right)\right) \\<br />&amp;+ \frac{1}{2\pi^2\Delta^2}\left(\frac{\pi^2}{6}-\text{Li}_2\left(e^{-2\pi\Delta}\right) \right) \\<br />&amp;+ \frac{1}{\pi \Delta}\sum_{\substack{n = p^k \\ n &lt; e^{2\pi\Delta}}} c_n\left(1 - \frac{\log n}{2\pi\Delta}\right)<br />\end{align*}<br />where</div><ul><li>$\gamma$ ranges over the nontrivial zeros of the $L$-function attached to $E$</li><li>$\Delta$ is a positive parameter</li><li>$\eta$ is the Euler-Mascheroni constant $=0.5772\ldots$</li><li>$N$ is the conductor of $E$</li><li>$\text{Li}_2(x)$ is the dilogarithm function, defined by $\text{Li}_2(x) = \sum_{k=1}^{\infty} \frac{x^k}{k^2}$</li><li>$c_n$ is the $n$th coefficient of the logarithmic derivative of the $L$-function of $E$, which is zero when $n$ is not a perfect prime power.</li></ul><div>The right hand side of the sum, which is what we actually compute, can be broken up into three parts: the first term involving the curve's conductor $N$; the second term involving the dilogarithm function $Li_2(x)$; and the sum over prime powers. The first two parts are quick to compute: evaluating them can basically be done in constant time regardless of the magnitude of $N$ or $\Delta$.<br /><br />It is therefore not worth considering parallelizing these two components, since the prime power sum dominates computation time for all but the smallest $\Delta$ values. Instead, what I've done is rewritten the zero sum code so that the prime power sum can be evaluated using multiple cores.<br /><br />As mentioned in <a href="http://mathandhats.blogspot.com/2014/07/how-to-find-prime-numbers-efficiently.html">this post</a>, we can turn this sum into one indexed by the primes (and not the prime powers); this actually makes parallelization quite straightforward. Recall that all primes except $2$ are odd, and all primes except $2$ and $3$ are either $1$ or $5$ remainder $6$. One can scale this up: given a list of small primes $[p_1,p_2,\ldots,p_n]$, all other primes fall into one of a relatively small number of residue classes modulo $p_1 p_2\cdots p_n$. For example, all primes beyond $2$, $3$, $5$ and $7$ have one of the following 48 remainders when you divide them by $210 = 2\cdot 3\cdot 5 \cdot 7$:<br />\begin{align*}<br />&amp;1, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79,\\<br />&amp;83, 89, 97, 101, 103, 107, 109, 113, 121, 127, 131, 137, 139, 143, 149, \\<br />&amp;151, 157, 163, 167, 169, 173, 179, 181, 187, 191, 193, 197, 199, 209,<br />\end{align*}<br />and no other.<br /><br />If we had 48 processors available. the natural thing to do would be to get each of them to iterate over all integers in a particular residue class up to $e^{2\pi\Delta}$, evaluating the summand whenever that integer is prime, and returning the sum thereof. For example, if the bound was 1 million, then processor 1 would compute and return $\sum_{n \equiv 1 (\text{mod } 210)}^{1000000} c_n\left(1 - \frac{\log n}{2\pi\Delta}\right)$. Processor 2 would do the same with all integers that are $11$ modulo $210$, etcetera.<br /><br />In reality, we have to figure out a) how many processors are available, and b) partition the work relatively equally among those processors. Thankfully <span>sage.parallel.ncpus.ncpus()</span> succinctly addresses the former, and the latter is achieved by splitting the residue classes into $n$ chunks of approximately equal size (where $n$ is the number of available CPUs) and then getting a given processor to evaluate the sum over those residues in a single chunk.<br /><br />Here is the method I wrote that computes the $\text{sinc}^2$ zero sum with (the option of) multiple processors:<br /><br /><small></small> Note that I've defined a subfunction to compute the prime sum over a given subset of residue classes; this is the part that is parallelized. Obtaining the residue chunks and computing the actual summand at each prime are both farmed out to external methods.<br /><br />Let's see some timings. The machine I'm running Sage on has 12 available processors:<br /><br /><div><div><div><span></span><span>sage:&nbsp;</span>sage.parallel.ncpus.ncpus()<br />12<br /><span></span></div><div><span>sage:&nbsp;</span>E&nbsp;=&nbsp;EllipticCurve([12838,-51298])<br /><span>sage:&nbsp;</span>Z&nbsp;=&nbsp;LFunctionZeroSum(E)</div><div><span>sage:&nbsp;</span>%time&nbsp;Z._zerosum_sincsquared_fast(Delta=2.6)</div><div>CPU&nbsp;times:&nbsp;user&nbsp;36.7&nbsp;s,&nbsp;sys:&nbsp;62.9&nbsp;ms,&nbsp;total:&nbsp;36.8&nbsp;s</div><div>Wall&nbsp;time:&nbsp;36.8&nbsp;s</div><div>2.8283629046</div><div><span>sage:&nbsp;</span>%time&nbsp;Z._zerosum_sincsquared_parallel(Delta=2.6)</div><div>CPU&nbsp;times:&nbsp;user&nbsp;7.87&nbsp;ms,&nbsp;sys:&nbsp;133&nbsp;ms,&nbsp;total:&nbsp;141&nbsp;ms</div><div>Wall&nbsp;time:&nbsp;4.06&nbsp;s</div><div>2.8283629046</div></div></div><div><br /></div>Same answer in a ninth of the time! Note that the parallelized method has some extra overhead, so even with 12 processors we're unlikely to get a full factor of 12 speedup. Nevertheless, the speed boost will allow us to run the zero sum code with larger $\Delta$ values, allowing us to investigate elliptic curves with even larger conductors.</div></div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/08/things-are-better-in-parallel.html">by Simon Spicer (noreply@blogger.com) at August 14, 2014 12:26 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>July 31, 2014</h2>

<div class="channelgroup">







<h3><a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-6365588202025292315.post-8194907099094130533">
<h4><a href="http://sagemath.blogspot.com/2014/07/sagemathcloud-history-and-status.html">SageMathCloud -- history and status</a></h4>
<div class="entry">
<div class="content">
2005: I made first release the SageMath software project, with the goal to create a viable open source free alternative to Mathematica, Magma, Maple, Matlab.<br /><br />2006: First web-based notebook interface for using Sage, called "sagenb". It was a cutting edge "AJAX" application at the time, though aimed at a small number of users.<br /><br />2007-2009: Much work on sagenb. But it's still not scalable. Doesn't matter since we don't have that many users.<br /><br />2011-: Sage becomes "self sustaining" from my point of view -- I have more time to work on other things, since the community has really stepped up.<br /><br />2012: I'm inspired by the Simons Foundation's (and especially Jim Simon's) "cluelessness" about open source software to create a new online scalable web application to (1) make it easier for people to get access to Sage, especially on Windows, and (2) generate a more longterm sustainable revenue stream to support Sage development. (I was invited to a day-long meeting in NYC at Simon's headquarters.)<br /><br />2012-2013: Spent much of 2012 and early 2013 researching options, building prototypes, some time talking with Craig Citro and Robert Bradshaw (both at Google), and launched SageMathCloud in April 2013. SMC got some high-profile use, e.g., by UCLA's 400+ student calculus course.<br /><br />2014: Much development over the last 1.5 years. Usage has also grown. There is some growth information <a href="http://boxen.math.washington.edu/home/schilly/salvus/stats/stats.html">here</a>. I also have useful google analytics data from the whole time, which shows around 4000 unique users per week, with an average session duration of 97 minutes (see attached). Number of users has actually dropped off during the summer, since there is much less teaching going on.<br /><br />SMC itself is written mostly in CoffeeScript using Node.js on the backend. There's a small amount of Python as well.<br /><br />It's a highly distributed multi-data center application. The database is Cassandra. The backend server processes are mostly Node.js processes, and also nginx+haproxy+stunnel.<br /><br />A copy of user data is stored in every data center, and is snapshotted every few minutes, both via :<br /><ul><li>ZFS -- for rolling snapshots that vanish after a month -- and via</li><li>bup -- for snapshots that remain forever, and are consistent across data centers.</li></ul>These snapshots are critical for making it possible to trust collaborators on projects to not (accidentally) destroy your work. It is not possible for users to delete the bup snapshots, by design.<br />Here's what it does: realtime collaborative editing of Latex docs, IPython notebooks, Sage worksheets; use the command line terminal; have several people collaborate on a project (=a Linux account).<br />The main applications seem to be:<br /><ul><li>teaching courses with a programming or math software components -- where you want all your students to be able to use something, e.g., IPython, Julia, etc, and don't want to have to deal with trying to get them to install said software themselves. Also, you want to easily be able to share files with students, see their work in realtime, etc. It's a much, much easier for people to get going that with naked VM's they have to configure -- and also I provide cross-data center replication.</li><li>collaborative research mathematics -- all co-authors of a paper work together in an SMC project, both writing the paper there and doing computations.</li></ul>Active development work right now:<br /><ul><li>course management for homework (etc)</li><li>administration functionality (mainly motivated by self-hosting and better moderation)</li><li>easy history slider to see all pasts states of a document</li><li>switching from bootstrap2 to bootstrap3.</li></ul></div>







<p class="date">
<a href="http://sagemath.blogspot.com/2014/07/sagemathcloud-history-and-status.html">by William Stein (noreply@blogger.com) at July 31, 2014 10:17 PM</a>
</p>
</div>
</div>



</div>
<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-376025509331820632">
<h4><a href="http://mathandhats.blogspot.com/2014/07/the-average-rank-of-elliptic-curves.html">The average rank of elliptic curves</a></h4>
<div class="entry">
<div class="content">
It's about time I should demonstrate the utility of the code I've written - the aim of the game for my GSoC project, after all, is to provide a new suite of tools with which to conduct mathematical research.<br /><br />First some background. Given an elliptic curve $E$ specified by equation $y^2 = x^3&nbsp;+ Ax&nbsp;+ B$ for integers $A$ and $B$, one of the questions we can ask is: what is the average rank of $E$ as $A$ and $B$ are allowed to vary? Because there are an infinite number of choices of $A$ and $B$, we need to formulate this question a bit more carefully. To this end, let us define the <i>height</i>&nbsp;of $E$ to be<br />$$ h(E) = \max\{|A|^3,|B|^2\} $$<br />[Aside: The height essentially measures the size of the coefficients of $E$ and is thus a fairly decent measure of the arithmetic complexity of the curve. We need the 3rd and 2nd powers in order to make the height function scale appropriately with the curve's discriminant.]<br /><br />We can then ask: what is the limiting value of the average rank of all curves up to height $X$, as $X$ gets bigger and bigger? Is it infinity? Is it 0? Is it some non-trivial positive value? Does the limit even exist? It's possible that the average rank, as a function of $X$ could oscillate about and never stabilize.<br /><br />There are strong heuristic arguments suggesting that the answer should be exactly $\frac{1}{2}$. Specifically, as the height bound $X$ gets very large, half of all curves should have rank 0, half should have rank 1, and a negligible proportion should have rank 2 or greater.<br /><br />Even as recently as five years ago this there we knew nothing concrete unconditionally about average curve rank. There are some results by <a href="http://link.springer.com/article/10.1007%2FBF01232033#page-1">Brumer</a>,&nbsp;<a href="http://projecteuclid.org/download/pdf_1/euclid.dmj/1082665288">Heath-Brown</a>&nbsp;and <a href="http://www.ams.org/journals/jams/2006-19-01/S0894-0347-05-00503-5/">Young</a> providing successively better upper bounds on the average rank of curves ordered by height (2.3, 2 and $\frac{25}{14}$ respectively), but these results are contingent on the Riemann Hypothesis.<br /><br />However, starting in 2011 Manjul Bhargava, together with Christopher Skinner and Arul Shankar, published a series of landmark papers (see <a href="https://www.dpmms.cam.ac.uk/research/BSD2011/bsd2011-Bhargava.pdf">here</a>&nbsp;for a good expository slideshow, and&nbsp;<a href="http://arxiv.org/pdf/1407.1826v2.pdf">here</a> and <a href="http://arxiv.org/pdf/1312.7859v1.pdf">here</a>&nbsp;for two of the latest publications) proving <i>unconditionally</i> that average rank - that is, the limiting value of the average rank of all elliptic curves up to height $X$ - is bounded above by 0.885. A consequence of their work too is that <a href="http://mattbakerblog.wordpress.com/tag/ranks-of-elliptic-curves/">at least 66% of all elliptic curves satisfy the rank part of the Birch and Swinnerton-Dyer Conjecture</a>.<br /><br />To a computationally-minded number theorist, the obvious question to ask is: Does the data support these results? I am by no means the first person to ask this question. Extensive databases of elliptic curves under various orderings have already been compiled, most notably those by <a href="http://homepages.warwick.ac.uk/~masgaj/ftp/data/">Cremona</a> (ordered by conductor) and <a href="http://modular.math.washington.edu/papers/stein-watkins/">Stein-Watkins</a> (ordered essentially by discriminant). However, as yet no extensive tabulation of height-ordered elliptic curves has been carried out.<br /><br />Here is a summarized table of elliptic curves with height at most 10000 - a total of 8638 curves, and the ranks thereof (all computations done in Sage, of course):<br /><br /><div align="center"><table border="0" cellpadding="0" cellspacing="0"><colgroup><col width="35" /><col span="2" width="49" /></colgroup><tbody><tr class="xl65" height="17"><td class="xl66" height="17" width="35">Rank</td><td class="xl68" width="49"># Curves</td><td class="xl67" width="49">%</td></tr><tr height="17"><td class="xl69" height="17"><div>0</div></td><td align="right" class="xl70">2988</td><td align="right" class="xl71">34.59%</td></tr><tr height="16"><td class="xl75" height="16"><div>1</div></td><td align="right" class="xl76">4307</td><td align="right" class="xl77">49.86%</td></tr><tr height="16"><td class="xl75" height="16"><div>2</div></td><td align="right" class="xl76">1286</td><td align="right" class="xl77">14.89%</td></tr><tr height="16"><td class="xl75" height="16"><div>3</div></td><td align="right" class="xl76">57</td><td align="right" class="xl77">0.66%</td></tr><tr height="16"><td class="xl75" height="16"><div>$\ge$4</div></td><td align="right" class="xl76">0</td><td align="right" class="xl77">0.00%</td></tr><tr height="16"><td class="xl72" height="16">Total:</td><td align="right" class="xl73">8638</td><td class="xl74"></td></tr></tbody></table></div><br />Thus the average rank of elliptic curves is 0.816 when the height bound is 10000. This is worrisome: the average is significantly different from the value of 0.5 we're hoping to see.<br /><br />The situation gets even worse when we go up to height bound 100000:<br /><br /><div align="center"><table border="0" cellpadding="0" cellspacing="0"><colgroup><col width="35" /><col span="2" width="49" /></colgroup><tbody><tr class="xl65" height="17"><td class="xl66" height="17" width="35">Rank</td><td class="xl68" width="49"># Curves</td><td class="xl67" width="49">%</td></tr><tr height="17"><td class="xl69" height="17"><div>0</div></td><td align="right" class="xl70">19492</td><td align="right" class="xl71">33.11%</td></tr><tr height="16"><td class="xl75" height="16"><div>1</div></td><td align="right" class="xl76">28818</td><td align="right" class="xl77">48.96%</td></tr><tr height="16"><td class="xl75" height="16"><div>2</div></td><td align="right" class="xl76">9747</td><td align="right" class="xl77">16.56%</td></tr><tr height="16"><td class="xl75" height="16"><div>3</div></td><td align="right" class="xl76">801</td><td align="right" class="xl77">1.36%</td></tr><tr height="16"><td class="xl75" height="16"><div><span>$\ge$</span>4</div></td><td align="right" class="xl76">4</td><td align="right" class="xl77">0.01%</td></tr><tr height="16"><td class="xl72" height="16">Total:</td><td align="right" class="xl73">58862</td><td class="xl74"></td></tr></tbody></table></div><br />This yields an average rank of 0.862 for height bound 100000. Bizarrely, the average rank is getting bigger, not smaller!<br /><br />[Note: the fact that 0.862 is close to Bhargava's asymptotic bound of 0.885 is coincidental. Run the numbers for height 1 million, for example, and you get an average rank of 0.8854, which is bigger than the above asymptotic bound. Observationally, we see the average rank continue to increase as we push out to even larger height bounds beyond this.]<br /><br />So what's the issue here? It turns out that a lot of the asymptotic statements we can make about elliptic curves are precisely that: asymptotic, and we don't yet have a good understanding of the associated rates of convergence. Elliptic curves, ornery beasts that they are, can seem quite different from their limiting behaviour when one only considers curves with small coefficients. We expect (hope?) that the average to eventually turn around and start to decrease back down to 0.5, but the exact point at which that happens is as yet unknown.<br /><br />This is where I come in. One of the projects I've been working on (with Wei Ho, Jen Balakrishnan, Jamie Weigandt, Nathan Kaplan and William Stein) is to compute the average rank of elliptic curves for as large a height bound as possible, in the hope that we will get results a bit more reassuring than the above. The main steps of the project are thus:<br /><br /><ol><li>Generate an&nbsp;ordered-by-height&nbsp;database of all elliptic curves up to some very large &nbsp;height bound (currently 100&nbsp;million; about 18.5 million curves);</li><li>Use every trick in the book to compute the ranks of said elliptic curves;</li><li>Compute the average of said ranks.</li></ol><div>Steps 1 and 3 are easy. Step 2 is not. Determining the rank of an elliptic curve is a notoriously hard problem - no unconditional algorithm with known complexity currently exists - especially when you want to do it for millions of curves in a reasonable amount of time. Sage, for example, already has a <span>rank()</span> method attached to their <span>EllipticCurve</span> class; if you pass the right parameters to it, the method will utilize an array of approaches to get a value out that is (assuming standard conjectures) the curve's rank. However, its runtime for curves of height near 100 million&nbsp;is on the order of 20 seconds; set it loose on 18.5 million such curves and you're looking at a total computation time of about 10 CPU years.</div><div><br /></div><div>Enter GSoC project stage left. At the expense of assuming the Generalized Riemann Hypothesis and the Birch and Swinnerton-Dyer Conjecture, we can use the zero sum rank bounding code I've been working on to quickly compute concrete upper bounds on an elliptic curve's rank. This approach has a couple of major advantages to it:</div><div><ul><li>It's <i>fast</i>. In the time it's taken me to write this post, I've computed rank bounds on 2.5 million curves.</li><li>Runtime is essentially constant for any curve in the database; we don't have to worry about how the method scales with height or conductor. If we want to go up to larger height bounds at a later date, no problem.</li></ul><div>As always, some Terms and Conditions apply. The rank bounding code only gives you an upper bound on the rank: if, for example, you run the code on a curve and get the number 4 back, there's no way to determine with this method if the curve's rank is 4, or if it is really some non-negative integer less than 4.&nbsp;</div></div><div><br /></div><div>Note: there is an invariant attached to an elliptic curve called the <i>root number</i>&nbsp;which&nbsp;is efficiently computable, even for curves with large conductor (it took less than 20 minutes to compute the root number for all 18.5 million curves in our database). The root number is one of two values: -1 or +1; if it's -1 the curve has odd analytic rank, and if it's +1 the curve has even analytic rank. Assuming BSD we can therefore always easily tell if the curve's rank is even or odd. My GSoC rank estimation code takes the root number into account, so in the example above, a returned value of 4 tells us that the curve's true rank is one of three values: 0, 2 or 4.</div><div><br /></div><div>Even better, if the returned value is 0 or 1, we know this must be the actual algebraic rank of the curve: firstly, there's no ambiguity as to what the analytic rank is - it has to the returned 0 or 1; secondly, <a href="http://en.wikipedia.org/wiki/Birch_and_Swinnerton-Dyer_conjecture#Current_status">the BSD conjecture has been proven in the rank 0 &amp; 1 cases</a>. Thus even though we are a priori only computing analytic rank upper bounds, for some proportion of curves we've found the actual algebraic rank.<br /><br />[Note that the rank bounding code I've written is predicated on knowing that all nontrivial zeros of an elliptic curve $L$-function lie on the critical line, so we still have to assume the Generalized Riemann Hypothesis.]</div><div><br /></div><div>Thus running the rank bound code on the entire database of curves is a very sensible first step, and it's what I'm currently doing. It's computationally cheap to do - on <a href="https://cloud.sagemath.com/">SageMathCloud,</a>&nbsp;using a Delta value of 1.0, the runtime for a single curve is about 4 milliseconds. Moreover, for some non-negligible percentage of curves the bounds will be observably sharp - based on some trial runs I'm expecting about 20-30% of the computed bounds to be 0 or 1.</div><div><br /></div><div>That's about 4 million curves for which we won't have to resort to much more expensive rank finding methods. Huge savings!</div></div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/07/the-average-rank-of-elliptic-curves.html">by Simon Spicer (noreply@blogger.com) at July 31, 2014 07:37 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>July 21, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-422299277135084642">
<h4><a href="http://mathandhats.blogspot.com/2014/07/how-to-find-prime-numbers-efficiently.html">How to efficiently enumerate prime numbers</a></h4>
<div class="entry">
<div class="content">
There's a part in my code that requires me to evaluate a certain sum<br /><div>$$ \sum_{p\text{ prime }&lt; \,M} h_E(p) $$</div><div>where $h_E$ is a function related to specified elliptic curve that can be evaluated efficiently, and $M$ is a given bound that I know. That is, I need to evaluate the function h_E at all the prime numbers less than $t$, and then add all those values up.</div><div><br /></div><div>The question I hope to address in this post is: how can we do this efficiently as $M$ gets bigger and bigger? Specifically, what is the best way to compute a sum over all prime numbers up to a given bound when that bound can be very large?</div><div><br /></div><div><i>[For those who have read my previous posts (you can skip this paragraph if you haven't - it's not the main thrust of this post), what I want to compute is, for an elliptic curve $E/\mathbb{Q}$, the analytic rank bounding sum $ \sum_{\gamma} \text{sinc}^2(\Delta \gamma) $ over the zeros of $L_E(s)$ for positive parameter $\Delta$; this requires us to evaluate the sum $ \sum_{n &lt; \exp(2\pi\Delta)} c_n\cdot(2\pi\Delta-\log n)$. Here the $c_n$ &nbsp;are the logarithmic derivative coefficients of the completed $L$-function of $E$. Crucially $c_n = 0$ whenever $n$ isn't a prime power, and we can lump together all the terms coming from the same prime; we can therefore express the sum in the form you see in the first paragraph.]</i></div><div><i><br /></i></div><div>As with so many things in mathematical programming, there is a simple but inefficient way to do this, and then there are more complicated and ugly ways that will be much faster. And as has been the case with other aspects of my code, I've initially gone with the first option to make sure that my code is mathematically correct, and then gone back later and reworked the relevant methods in an attempt to speed things up.</div><div><br /></div><h3>METHOD 1: SUCCINCT BUT STUPID</h3><div><br />Here's a Python function that will evaluate the sum over primes. The function takes two inputs: a function $h_E$ and an integer $M$, and returns a value equal to the sum of $h_E(p)$&nbsp;for all primes less than $M$.&nbsp;We're assuming here that the primality testing function <span>is_prime()</span> is predefined.</div><div><br /></div> <br /><div>As you can see, we can achieve the desired outcome in a whopping six lines of code. Nothing mysterious going on here: we simply iterate over all integers less than our bound and test each one for primality; if that integer is prime, then we evaluate the function <span>h_E</span> at that integer and add the result to <span>y</span>. The variable&nbsp;<span>y</span> is then returned at the end.</div><div><br /></div><div>Why is this a bad way to evaluate the sum? Because there are far more composite integers than there are primes. According to the <a href="http://en.wikipedia.org/wiki/Prime_number_theorem">prime number theorem</a>, the proportion of integers up to $M$ that are prime is approximately $\frac{1}{\log M}$. For my code I want to compute with bounds in the order of $M = e^{8\pi} \sim 10^{11}$; the proportion of integers that are prime up to this bound value is correspondingly about $\frac{1}{8\pi} \sim 0.04$. That is, 96% of the integers we iterate over aren't prime, and we end up throwing that cycle away.<br /><br />Just how inefficient this method is of course depends on how quickly we can evaluate the primality testing function <span>is_prime()</span>. The best known&nbsp;<a href="http://en.wikipedia.org/wiki/AKS_primality_test#History_and_running_time">deterministic primality testing algorithm</a>&nbsp;has running time that scales with (at most) the 6th power of $\log n$, where $n$ is the number being tested. This places primality testing in a class of algorithms called&nbsp;<a href="http://en.wikipedia.org/wiki/Time_complexity#Polynomial_time">Polynomial Time Complexity Algorithms</a>, which means the runtime of the function scales relatively well with the size of the input. However, what kills us here is the sheer number of times we have to call <span>is_prime()</span> - on all integers up to our bound $M$ - so even if it ran in constant time the <span>prime_sum()</span> function's running time is going to scale with the magnitude of $M$.</div><div><br /><h3>METHOD 2: SKIP THOSE $n$ WE KNOW ARE COMPOSITE</h3></div><div><br /></div><div>We can speed things up considerably by noting that apart from 2, all prime numbers are odd. We are therefore wasting a huge amount of time running primality tests on integers that we know a priori are composite. Assuming <span>is_prime()</span> takes a similar time to execute than our coefficient function <span>h_E()</span>, we could therefore roughly <i>halve</i> the runtime of the prime sum function by skipping the even integers and just checking odd numbers for primality.</div><div><br /></div><div>We can go further. Apart from 2 and 3, all primes yield a remainder of 1 or 5 when you divide them by 6 (because all primes except for 2 are 1 (modulo 2) and all primes except for 3 are 1 or 2 (modulo 3)). We can therefore skip all integers that are 0, 2, 3 or 4 modulo 6; this means we only have to check for primality on only one third of all the integers less than $M$.</div><div><br /></div><div>Here's a second version of the <span>prime_sum()</span> function that does this:</div><div><br /></div> <br /><div>Of course we could go even further with the technique by looking at remainders modulo $p$ for more primes $p$ and combining the results: for example, all primes outside of 2, 3 and 5 can only have a remainder of 7, 11, 13, 17, 19, 23 or 29 modulo 30. However, the further you go the more special cases you need to consider, and the uglier your code becomes; as you can see, just looking at cases modulo 6 requires us to write a function about three times as long as previously. This method therefore will only be able to take us so far before the code we'd need to write would become too unwieldy for practicality.</div><div><br /><h3>METHOD 3: PRIME SIEVING...</h3><br />This second <span>prime_sum()</span> version is a rudimentary example of a technique called <a href="http://en.wikipedia.org/wiki/Generating_primes#Prime_sieves">prime sieving</a>. The idea is to use quick computations to eliminate a large percentage of integers from consideration in a way that doesn't involve direct primality testing, since this is computationally expensive. Sieving techniques are an entire field of research in their own right, so I thought I'd just give as example one of the most famous methods: the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Eratosthenes</a> (named after the ancient Greek mathematician who is thought to first come up with the idea). This takes as input a positive bound $M$ and returns a list of all prime numbers less than $M$. The method goes as follows:<br /><ol><li>Start with a list of boolean flags indexed by the numbers 2 through $M$, and set all of them to True.&nbsp;</li><li>Starting at the beginning of the list, let $i$ be the index of the first True entry. Set all entries at indices a multiples of $i$ to False.</li><li>Repeat step 2 until the first True entry is at index $&gt; \sqrt{M}$.</li><li>Return a list of all integers $i$ such that the entry at index $i$ is True.</li></ol><div>This is definitely a case where a (moving) picture is worth a thousand words:</div><div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container"><tbody><tr><td><a href="http://3.bp.blogspot.com/-whIjs4sS4x0/U81wanTNPgI/AAAAAAAAAF0/LTgtOYA_bfY/s1600/Sieve_of_Eratosthenes_animation.gif"><img border="0" src="http://3.bp.blogspot.com/-whIjs4sS4x0/U81wanTNPgI/AAAAAAAAAF0/LTgtOYA_bfY/s1600/Sieve_of_Eratosthenes_animation.gif" height="265" width="320" /></a></td></tr><tr><td class="tr-caption">A good graphic representation of the Sieve of Eratosthenes being used to generate all primes less than 121. Courtesy Wikipedia: "<a href="http://commons.wikimedia.org/wiki/File:Sieve_of_Eratosthenes_animation.gif#mediaviewer/File:Sieve_of_Eratosthenes_animation.gif">Sieve of Eratosthenes animation</a>". Licensed under <a href="http://creativecommons.org/licenses/by-sa/3.0/" title="Creative Commons Attribution-Share Alike 3.0">CC BY-SA 3.0</a> via <a href="https://commons.wikimedia.org/wiki/">Wikimedia Commons</a>.&nbsp;</td></tr></tbody></table>How and why does this work? By mathematical induction, at each iteration the index of the first True entry will always be prime. However any multiple thereof is by definition composite, so we can walk along the list and flag them as not prime. Wash, rinse, repeat. We can stop at $\sqrt{M}$, since all composite numbers at most $M$ in magnitude must have at least one prime factor at most $\sqrt{M}$ in size.<br /><br />Here is a third version of our <span>prime_sum()</span> function that utilizes the Sieve of Eratosthenes:<br /><br /> Let's see how the three versions stack up against each other time-wise in the Sage terminal. I've saved the three functions in a file called <span>prime_sum_functions.py</span>, which I then import up front (if you want to do the same yourself, you'll need to import or define appropriate&nbsp;<span>is_prime()</span> and <span>sqrt()</span> functions at the top of the file). I've also defined a sample toy function <span>h_E()</span>&nbsp;and bound <span>M</span>:<br /><br /><div><div><span>sage:&nbsp;</span>from&nbsp;prime_sum_functions&nbsp;import&nbsp;*</div><div><span>sage:&nbsp;</span>def&nbsp;h_E(n):&nbsp;return&nbsp;sin(float(n))/float(n)</div><div><span>sage:&nbsp;</span>M&nbsp;=&nbsp;10000</div><div><span>sage:&nbsp;</span>prime_sum_v1(h_E,M)</div><div>0.19365326958140347</div><div><span>sage:&nbsp;</span>prime_sum_v2(h_E,M)</div><div>0.19365326958140347</div><div><span>sage:&nbsp;</span>prime_sum_v3(h_E,M)</div><div>0.19365326958140347</div><div><span>sage:&nbsp;</span>%timeit&nbsp;prime_sum_v1(h_E,M)</div><div>1&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;363&nbsp;ms&nbsp;per&nbsp;loop</div><div><span>sage:&nbsp;</span>%timeit&nbsp;prime_sum_v2(h_E,M)</div><div>1&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;206&nbsp;ms&nbsp;per&nbsp;loop</div><div><span>sage:&nbsp;</span>%timeit&nbsp;prime_sum_v3(h_E,M)</div><div>10&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;86.8&nbsp;ms&nbsp;per&nbsp;loop</div></div><br />Good news! All three functions (thankfully) produce the same result. And we see version 2 is about 1.8 times faster than version 1, while version 3 is four times as fast. These ratios remained roughly the same when I timed the functions on larger bounds, which indicates that the three versions have the same or similar asymptotic scaling - this should be expected, since no matter what we do we will always have to check something at each integer up to the bound.<br /><br /><h3>METHOD 4: ...AND BEYOND</h3><br />It should be noted, however, that the Sieve of Eratosthenes as implemented above would be a <i>terrible</i> choice for my GSoC code. This is because in order to enumerate the primes up to $M$ we need to create a list in memory of size $M$. This isn't an issue when $M$ is small, but for my code I need $M \sim 10^{11}$; an array of booleans that size would take up about 12 gigabytes in memory, and any speedups we get from not having to check for primality would be completely obliterated by read/write slowdowns due to working with an array that size. In other words, while the Sieve of Eratosthenes has great time complexity, it has abysmal space complexity.<br /><br />Thankfully, more memory-efficient sieving methods exist that drastically cut down the space requirements. The best of these - for example, the <a href="http://en.wikipedia.org/wiki/Sieve_of_Atkin">Sieve of Atkin</a> - need about $\sqrt{M}$ space. For $M \sim 10^{11}$ this translates to only about 40 kilobytes; much more manageable.<br /><br />Of course, there's always a downside: bleeding edge prime enumeration methods are finicky and intricate, and there are a plethora of ways to get it wrong when implementing them. At some point squeezing an extra epsilon of speedup from your code is no longer worth it in terms of the time and effort it will take to get there. For now, I've implemented a more optimized version of the second <span>prime_sum()</span> function in my code (where we skip over all integers that are obviously not prime), since for now that is my happy middle ground. &nbsp;If I have time at the end of the project I will revisit the issue of efficient prime enumeration and try implement a more optimized sieving method, but that is a tomorrow problem.</div></div></div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/07/how-to-find-prime-numbers-efficiently.html">by Simon Spicer (noreply@blogger.com) at July 21, 2014 03:00 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>July 14, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-434017993815801689">
<h4><a href="http://mathandhats.blogspot.com/2014/07/cythonize.html">Cythonize!</a></h4>
<div class="entry">
<div class="content">
I'm at the stage where my code essentially works: it does everthing I initially set out to have it do, including computing the <a href="http://mathandhats.blogspot.com/2014/06/fun-with-elliptic-curve-l-function.html">aforementioned zero sums for elliptic curve $L$-functions</a>. However, the code is written in pure Python, and it is therefore not as fast as it could be.<br /><br />This is often not a problem; Python is designed to be easy to read and maintain, and I'm hoping that the Python code I wrote is both of those. If we were just planning to run it on elliptic curves with small coefficients - for example, the curve represented by the equation $y^2=x^3-16x+16$ - this wouldn't be an issue. Curves with small coefficients have small conductors and thus few low-lying zeros near the central point, which allows us to run the zero sum code on them with small Delta parameter values. A small Delta value means the computation will finish very quickly regardless of how efficiently it's implemented, so it probably wouldn't be worth my while trying to optimize the code in that case.<br /><br />To illustrate this point, here is the first most high-level, generic version of the method that computes the sum $\sum_{\gamma} \text{sinc}^2(\Delta \gamma)$ over the zeros of a given elliptic curve $L$-function (minus documentation):<br /><br /> [Of course, there's plenty going on in the background here. I have a separate method, <span>self.cn()</span> which computes the logarithmic derivative coefficients, and I call the SciPy function <span>spence()&nbsp;</span><span>to compute the part of the sum that comes from the Fourier transform of the digamma function $\frac{\Gamma^{\prime}}{\Gamma}$. Nevertheless, the code is simple and straightforward, and (hopefully) it's easy to follow the logic therein.]</span><br /><br />However, the whole point of my GSoC project is to produce code that can be used for mathematical research; ultimately we want to push computations as far as we can and run the code on elliptic curves with large conductor, since curves with small conductor are already well-understood. Ergo, it's time I thought about going back over what I've written and seeing how I can speed it up.<br /><br />There are two distinct ways to achieve speedups. The first is to rewrite the code more cleverly to eliminates unnecessary loops, coercions, function calls etc. Here is a second version I have written of the same function (still in Python):<br /><br /> The major change I've made between the two versions is improving how the sum involving the logarithmic derivative coefficients is computed - captured in the variable <span>y</span>. In the first version, I simply iterated over all integers $n$ up to the bound $t$, calling the method <span>self.cn()</span> each time. However, the logarithmic derivative coefficient $c_n$ is zero whenever $n$ is not a prime power, and knowing its value for $n=p$ a prime allows us to efficiently compute its value for $p^k$ any power of that prime. It therefore makes sense to do everything "in-house": eliminate the method call to <span>self.cn()</span>, iterate only over primes, and compute the logarithmic derivative coefficients for all powers of a given prime together.<br /><br />Let's see how the methods match up in terms of speed. Below we run the two versions of the zero sum method on the elliptic curve $E: y^2=x^3-16x+16$, which is a rank 1 curve of conductor 37:<br /><br /><div><div><span>sage:&nbsp;</span>import&nbsp;sage.lfunctions.zero_sums&nbsp;as&nbsp;zero_sums</div><div><span>sage:&nbsp;</span>ZS&nbsp;=&nbsp;zero_sums.LFunctionZeroSum(EllipticCurve([-16,16]))</div><div><div><span>sage:&nbsp;</span>ZS._zerosum_sincsquared(Delta=1)</div><div>1.01038406984</div><div><div><span>sage:&nbsp;</span>ZS._zerosum_sincsquared_fast(Delta=1)</div><div>1.01038406984</div></div></div><div><span>sage:&nbsp;</span>%timeit&nbsp;ZS._zerosum_sincsquared(Delta=1)</div><div>10&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;20.5&nbsp;ms&nbsp;per&nbsp;loop</div><div><span>sage:&nbsp;</span>%timeit&nbsp;ZS._zerosum_sincsquared_fast(Delta=1)</div><div>100&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;3.46&nbsp;ms&nbsp;per&nbsp;loop</div></div><br />That's about a sixfold speedup we've achieved, just by reworking the section of the code that computes the $c_n$ sum.<br /><br />The downside, of course, is that the code in method version 2 is more complicated - and thus less readable - than that in version 1. This is often the case in software development: you can write code that is elegant and easy to read but slow, or you can write code that is fast but horribly complicated and difficult to maintain. And when it comes to mathematical programming, unfortunately, sometimes the necessity for speed trumps readability.<br /><br />The second major way to achieve speedups is to abandon pure Python and switch to a more low-level language. I could theoretically take my code and rewrite it in C, for example; if done relatively intelligently I'm sure the resulting code would blow what I have here out the water in terms of speed. However, I have no experience writing C code, and even if I did getting the code to interface with the rest of the Sage codebase would be a major headache.<br /><br />Thankfully there is a happy middle ground: <a href="http://cython.org/">Cython</a>. Cython is a programming language - technically a superset of Python - that allows direct interfacing with C and C++ data types and structures. Code written in Cython can be as fast as C code and nearly as readable as pure Python. Crucially, because it's so similar to Python it doesn't require rewriting all my code from scratch. And <a href="http://www.sagemath.org/doc/developer/coding_in_cython.html">Sage already knows how to deal with Cython</a>, so there aren't any compatibility issues there.<br /><br />I am therefore in the process of doing exactly that: rewriting my code in Cython. Mostly this is just a cut-and-paste job and is pleasingly hassle-free; however, in order to achieve the desired speedups, the bottleneck methods - such as our $\text{sinc}^2$ zero sum method above - must be modified to make use of C data types.<br /><br />Here is the third, most recent version of the <span>_zerosum_sincsquared()</span> method for our zero sum class, this time written in Cython:<br /><br /> Definitely longer and uglier. I now must declare my (C) variables up front; previously Python just created them on the fly, which is nice but slower than allocating memory space for the variables a priori. I've eliminated the use of complex arithmetic, so that everything can be done using C integer and float types. I still iterate over all primes up to the bound $t$; however now I deal with those primes that divide the conductor of $E$ (for which the associated summand is calculated slightly differently) beforehand, so that in the main loop I don't have to check at each point if my prime $p$ divides the conductor or not [This last check is expensive: the conductor $N$ can be very large - too large to cast as a $C$ <span>long long</span> even - so we would have to use slower Python or Sage data types to represent it. Better to get rid of the check altogether].<br /><br />Let's see how this version holds up in a speed test. The Cython code has already been built into Sage and the class loaded into the global namespace, so I can just call it without having to attach or load any file:<br /><br /><div><div><span>sage:&nbsp;</span>ZS&nbsp;=&nbsp;LFunctionZeroSum(EllipticCurve([-16,16]))</div><div><span>sage:&nbsp;</span>ZS._zerosum_sincsquared_fast(Delta=1)</div><div>1.01038406984</div><div><span>sage:&nbsp;</span>%timeit&nbsp;ZS._zerosum_sincsquared_fast(Delta=1)</div><div>1000&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;1.72&nbsp;ms&nbsp;per&nbsp;loop</div></div><br />The good news: the Cythonized version of the method produces the same output as the Python versions, and it's definitely faster. The bad news: the speedup is only about a factor of 2, which isn't hugely impressive given how much uglier the code is.<br /><br />Why is this? Crucially, we still iterate over all integers up to the bound $t$, testing for primality at each step. This is very inefficient: most integers are <i>not</i> prime (in fact,<a href="http://en.wikipedia.org/wiki/Prime_number_theorem"> asymptotically 0 percent of all positive integers are prime</a>); we should be using sieving methods to eliminate primality testing at those integers which we know before checking are composite. For example, we should at the very least only ever iterate over the odd numbers beyond 3. That immediately halves the number of primality tests we have to do, and we should therefore get a comparable speedup if primality testing is what is dominating the runtime in this method.<br /><br />This is therefore what I hope to implement next: rework the zero sum code yet again to incorporate prime sieving. This has applicability beyond just the $\text{sinc}^2$ method: all explicit formula-type sums at some point invoke summing over primes or prime powers, so having access to code that can do this quickly would be a huge boon.<br /><br /></div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/07/cythonize.html">by Simon Spicer (noreply@blogger.com) at July 14, 2014 11:37 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>July 11, 2014</h2>

<div class="channelgroup">







<h3><a href="http://blog.hav3n.net/?tag=gsoc-2014" title="Nikhil's GSoC Blog » GSoC 2014">Nikhil Peter</a></h3>


<div class="entrygroup" id="http://blog.hav3n.net/?p=41" lang="en-US">
<h4><a href="http://blog.hav3n.net/?p=41">Sage Android – UI Update</a></h4>
<div class="entry">
<div class="content">
It&#8217;s been a busy week so far in the land of UI improvements. Disclaimer: I&#8217;m pretty bad at UI, so any and all suggestions are welcome. Firstly, last week&#8217;s problems have been resolved viz. Everything is saved nicely on orientation change, including the interacts, which required quite a bit of effort. In short, it involved [&#8230;]</div>







<p class="date">
<a href="http://blog.hav3n.net/?p=41">by hav3n at July 11, 2014 05:59 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>July 08, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-94589752012638265">
<h4><a href="http://mathandhats.blogspot.com/2014/07/the-birch-and-swinnerton-dyer.html">The Birch and Swinnerton-Dyer Conjecture and computing analytic rank</a></h4>
<div class="entry">
<div class="content">
<div>Let $E$ be an elliptic curve with $L$-function $L_E(s)$. Recall that Google Summer of Code project is to implement in Sage a method that allows us to compute $\sum_{\gamma} f(\Delta \gamma)$, where $\gamma$ ranges over the imaginary parts of the nontrivial zeros of $L_E$, $\Delta$ is a given positive parameter, and $f(x)$ is a specified symmetric continuous integrable function that is 1 at the origin. The value of this sum then bounds the analytic rank of $E$ - the number of zeros at the central point - from above, since we are summing $1$ with multipliticy $r_{an}$ in the sum, along with some other nonzero positive terms (that are hopefully small). See <a href="http://mathandhats.blogspot.com/2014/06/fun-with-elliptic-curve-l-function.html">this post</a> for more info on the method.</div><div><br /></div><div>One immediate glaring issue here is that zeros that are close to the critical point will contribute values that are close to 1 in the sum, so the curve will then appear to have larger analytic rank than it actually does. An obvious question, then, is to ask: how close can the noncentral zeros get to the central point? Is there some way to show that they cannot be too close? If so, then we could figure out just how large of a $\Delta$ we would need to use in order to get a rank bound that is actually tight.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container"><tbody><tr><td><a href="http://1.bp.blogspot.com/-3JIMGjpIGhA/U7xnevHtwyI/AAAAAAAAAFk/neB1jWIIuio/s1600/low-lying+zeros.png"><img border="0" src="http://1.bp.blogspot.com/-3JIMGjpIGhA/U7xnevHtwyI/AAAAAAAAAFk/neB1jWIIuio/s1600/low-lying+zeros.png" height="400" width="400" /></a></td></tr><tr><td class="tr-caption">The rank zero curve $y^2 = x^3 - &nbsp;x^3 - 7460362000712 x - 7842981500851012704$ has an extremely low-lying zero at $\gamma =&nbsp;0.0256$ (and thus another one at $-0.0256$; as a result the zero sum looks like it's converging towards a value of 2 instead of the actual analytic rank of zero. In order to actually get a sum value out that's less than one we would have to use a $\Delta$ value of about 20; this is far beyond what's feasible due to the exponential dependence of the zero sum method on $\Delta$.</td></tr></tbody></table><div><br /></div><div>The good news is that there is hope in this regard; the nature of low-lying zeros for elliptic curve $L$-functions is actually the topic of my PhD dissertation (which I'm still working on, so I can't provide a link thereto just yet!). In order to understand how close the lowest zero can get to the central point we will need to talk a bit about the BSD Conjecture.</div><br />The&nbsp;<a href="http://en.wikipedia.org/wiki/BSD_conjecture">Birch and Swinnerton-Dyer Conjecture</a>&nbsp;is one of the two <a href="http://www.claymath.org/millennium-problems">Clay Math Millenium Problems</a> related to $L$-functions. The conjecture is comprised of two parts; the first part I&nbsp;mentioned briefly in <a href="http://mathandhats.blogspot.com/2014/06/day-1-of-my-google-summer-of-code.html">this previous post</a>.&nbsp;However, we can use the second part to gain insight into how good our zero sum based estimate&nbsp;for analytic rank&nbsp;will be.<br /><br />Even though I've stated the first part of the BSD Conjecture before, for completeness I'll reproduce the full conjecture here. Let $E$ be an elliptic curve defined over the rational numbers, e.g. a curve represented by the equation $y^2 = x^3&nbsp;+ Ax&nbsp;+ B$ for some integers $A$ and $B$ such that $4A^3+27B^2 \ne 0$. Let $E(\mathbb{Q})$ be the group of rational points on the elliptic curve, and let $r_{al}$ be the <i>algebraic rank</i> of $E(\mathbb{Q})$. Let $L_E(s)$ be the $L$-function attached to $E$, and let $L_E(1+s) = s^{r_{an}}\left[a_0 + a_1 s&nbsp;+ \ldots\right]$ be the Taylor expansion of $L_E(s)$ about $s=1$ such that the leading coefficient $a_0$ is nonzero; $r_{an}$ is called the <i>analytic rank</i> of $E$ (see <a href="http://mathandhats.blogspot.com/2014/06/day-1-of-my-google-summer-of-code.html">here</a> for more details on all of the above objects). The first part of the BSD conjecture asserts that $r_{al}=r_{an}$; that is, the order of vanishing of the $L$-function about the central point is exactly equal to the number of free generators in the group of rational points on $E$.<br /><div><br /></div><div>The second part of the conjecture asserts that we actually know the exact value of that leading coefficient $a_0$ in terms of other invariants of $E$. Specifically:</div><div>$$ a_0 = \frac{\Omega_E\cdot\text{Reg}_E\cdot\prod_p c_p\cdot\#\text{Ш}(E/\mathbb{Q})}{(\#E_{\text{Tor}}(\mathbb{Q}))^2}. $$</div><div><br /></div><div><div>Fear not if you have no idea what any of these quantities are. They are all things that we know how to compute - or at least estimate in size. I provide below brief descriptions of each of these quantities; however, feel free to skip this part. It suffices to know that we have a formula for computing the exact value of that leading coefficient $a_0$.</div></div><div><div class="separator"></div><ol><li>$\#E_{\text{Tor}}(\mathbb{Q})$ is the number of rational torsion points on $E$. Remember that the solutions $(x,y)$ to the elliptic curve equation $y^2 = x^3&nbsp;+ Ax+B$, where $x$ and $y$ are both rational numbers, form a group. Recall also that that the group of rational points $E(\mathbb{Q})$ may be finite or infinite, depending on whether the group has algebraic rank zero, or greater than zero. However, it turns out that there are only ever finitely many <i>torsion</i> points - those which can be added to themselves some finite number of times to get the group identity element. These points of finite order&nbsp;form a subgroup, denoted $E_{\text{Tor}}(\mathbb{Q})$, and the quantity in question is just the size of this finite group (squared in the formula). In fact, it's <a href="http://en.wikipedia.org/wiki/Mazur's_torsion_theorem">been proven</a> that the size of&nbsp;$E_{\text{Tor}}(\mathbb{Q})$ is at most 16.</li><li>$\Omega_E$ is the real period of $E$. This is perhaps a bit more tricky to define, but it essentially is a number that measures the size of the set of real points of $E$. If you plot the graph of the equation representing $E: y^2 = x^3 + Ax&nbsp;+ B$ on the cartesian plane, you get something that looks like one of the following:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container"><tbody><tr><td><a href="http://4.bp.blogspot.com/-VmiruEPt2Yc/U7xiwh4bbJI/AAAAAAAAAFc/B1K7EfcqVwQ/s1600/real_periods.png"><img border="0" src="http://4.bp.blogspot.com/-VmiruEPt2Yc/U7xiwh4bbJI/AAAAAAAAAFc/B1K7EfcqVwQ/s1600/real_periods.png" height="300" width="400" /></a></td></tr><tr><td class="tr-caption">The plots of the real solutions to four elliptic curves, and their associated real periods.</td></tr></tbody></table><br />There is a way to assign an intrinsic "size" to these graphs, which we denote the <i>real period</i>&nbsp;$\Omega_E$. The technical definition is that&nbsp;$\Omega_E$ is equal to the integral of the absolute value of the differential $\omega = \frac{dx}{2y}$ along the part of the real graph of $E$ that is connected to infinity (that or twice that depending on whether the cubic equation $x^3&nbsp;+ Ax&nbsp;+ B$ has one or three real roots respectively).</li><li>$\text{Reg}_E$ is the <i>regulator</i> of $E$. This is a number that measures the "density" of rational points on $E$. Recall that $E(\mathbb{Q}) \approx T \times \mathbb{Z}^{r_{an}}$, i.e there free part of $E(\mathbb{Q})$ is isomorphic to $r_{an}$ copies of the integers. There is a canonical way to embed the free part of&nbsp;$E(\mathbb{Q})$ in $\mathbb{R}^{r_{an}}$ as a <a href="http://en.wikipedia.org/wiki/Lattice_(group)">lattice</a>; the regulator&nbsp;$\text{Reg}_E$ is the volume of the fundamental domain of this lattice. The thing to take away here is that elliptic curves with small regulators have lots of rational points whose coefficients have small numerators and denominators, while curves with large regulators have few such points.</li><li>$\prod_p c_p$ is the <i>Tamagawa product</i> for $E$. For each prime $p$, one can consider the points on $E$ over the <a href="http://en.wikipedia.org/wiki/P-adic_numbers">$p$-adic numbers</a>&nbsp;$\mathbb{Q}_p$. The <i>Tamagawa number</i>&nbsp;$c_p$ is the ratio of the size of the full group of $p$-adic points on $E$ to the subgroup of $p$-adic points that are connected to the identity. This is always a positive integer, and crucially, in all but a finite number of cases the ratio is 1. Thus we can consider the product of the $c_p$ as we range over all prime numbers, and this is precisely the definition of the Tamagawa product.</li><li>$\#\text{Ш}(E/\mathbb{Q})$ is the order of the <i>Tate-Shafarevich group</i> of $E$ over the rational numbers. The&nbsp;<a href="http://en.wikipedia.org/wiki/Tate%E2%80%93Shafarevich_group">Tate-Shafarevich</a> group of $E$ is probably the most mysterious part of the BSD formula; it is defined as the subgroup of the Weil–Châtelet group $H^1(G_{\mathbb{Q}},E)$ that becomes trivial when passing to any completion of $\mathbb{Q}$. If you're like me then this definition will be completely opaque; however, we can think of&nbsp;$\text{Ш}(E/\mathbb{Q})$ as measuring how much $E$ violates the <a href="http://en.wikipedia.org/wiki/Local-global_principle">local-global principle</a>: that one should be able to find rational solutions to an algebraic equation by finding solutions modulo a prime number $p$ for each $p$, and then piecing this information together with the Chinese Remainder Theorem to get a rational solution. Curves with nontrivial $\text{Ш}$ have homogeneous spaces that have solutions modulo $p$ for all $p$, but no rational points. The main thing here is that&nbsp;$\text{Ш}$ is conjectured to be finite, in which case&nbsp;$\#\text{Ш}(E/\mathbb{Q})$ is just a positive integer (in fact, it can be shown for elliptic curves that if&nbsp;$\text{Ш}$ is indeed finite, then its size is a perfect square).<br /><div></div></li></ol><div>Why is the BSD Conjecture relevant to rank estimation? Because it helps us overcome the crucial obstacle to computing analytic rank exactly: without extra knowledge, it's impossible to decide using numerical techniques whether the $n$th derivative of the $L$-function at the central point is exactly zero, or just so small that it looks like it is zero to the precision that we're using. If we can use the BSD formula to show a priori that $a_0$ must be at least $M_E$ in magnitude, where $M_E$ is some number that depends only on some easily computable data attached to the elliptic curve $E$, then all we need to do is evaluate successive derivatives of $L_E$ at the central point to enough precision to decide if that derivative is less than $M_E$ or not; this is readily doable on a finite precision machine. Keep going until we hit a derivative which is then definitely greater than $M_E$ in magnitude, at which we can halt and declare that the analytic rank is precisely the order of that derivative.</div><div><br /></div><div>In the context of the explicit formula-based zero sum rank estimation method implemented in our GSoC project, the size of the leading coefficient also controls how far close the lowest noncentral zero can be from the central point. Specifically, we have the folling result: Let $\gamma_0$ be the lowest-lying noncentral zero for $L_E$ (i.e. the zero closest to the central point that is not actually at the central point); let $\Lambda_E(s) = N^{s/2}(2\pi)^s\Gamma(s)L_E(s)$ is the completed $L$-function for $E$, and let $\Lambda_E(1+s) = s^{r_{an}}\left[b_0 + b_1 s&nbsp;+ b_2 s^2 \ldots\right]$ be the Taylor expansion of $\Lambda_E$ about the central point. Then:</div><div>$$ \gamma_0 &gt; \sqrt{\frac{b_0}{b_2}}. $$</div><div>Thankfully, $b_0$ is easily relatable back to the constant $a_0$, and we have known computable upper bounds on the magnitude of $b_2$, so knowing how small $a_0$ is tells us how close the lowest zero can be to the central point. Thus bounding $a_0$ from below in terms of some function of $E$ tells us how large of a $\Delta$ value we need to use in our zero sum, and thus how long the computation will take as a function of $E$.</div><div><br /></div><div>If this perhaps sounds a bit handwavy at this point it's because this is all still a work in progress, to be published as part of my dissertation. Nevertheless, the bottom line is that bounding the leading $L$-series coefficient from below gives us a way to directly analyze the computational complexity of analytic rank methods.&nbsp;</div><div><br /></div><div>I hope to go into more detail in a future post about what we can do to bound from below the leading coefficient of $L_E$ at the central point, and why this is a far from straightforward endeavour.</div></div></div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/07/the-birch-and-swinnerton-dyer.html">by Simon Spicer (noreply@blogger.com) at July 08, 2014 05:04 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>June 28, 2014</h2>

<div class="channelgroup">







<h3><a href="http://blog.hav3n.net/?tag=gsoc-2014" title="Nikhil's GSoC Blog » GSoC 2014">Nikhil Peter</a></h3>


<div class="entrygroup" id="http://blog.hav3n.net/?p=39" lang="en-US">
<h4><a href="http://blog.hav3n.net/?p=39">GSoC – Post Mid-Term Update</a></h4>
<div class="entry">
<div class="content">
Well, Mid-Terms have just finished(I passed!), and I&#8217;ve been neglecting this blog so here are some updates. The app is now in beta! More info can be found at the sage-devel post here Most of the work done is internal, but there are a few external fixes and enhancements as well. Agendas for the next [&#8230;]</div>







<p class="date">
<a href="http://blog.hav3n.net/?p=39">by hav3n at June 28, 2014 05:41 PM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>June 27, 2014</h2>

<div class="channelgroup">







<h3><a href="http://drvinceknight.blogspot.com/search/label/Sage" title="Un peu de math...">Vince Knight</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4212553888783541751.post-8371434845098368979">
<h4><a href="http://drvinceknight.blogspot.com/2014/06/pointing-at-blog-post-about-sage-and.html">Pointing at a blog post about Sage and a treasure hunt</a></h4>
<div class="entry">
<div class="content">
It looks like I might be moving... I've been playing with jekyll&nbsp;+ github and really love the workflow so it looks like I might be moving this blog over there.<br /><br />It's not official yet as I still need to think about a couple of things but in the meantime here's a post I just wrote over there about how the team I was in used Sage in a mathematical treasure hunt:&nbsp;<a class="ot-anchor aaTEdf" href="http://goo.gl/iLgGnL" rel="nofollow" target="_blank">http://goo.gl/iLgGnL</a></div>







<p class="date">
<a href="http://drvinceknight.blogspot.com/2014/06/pointing-at-blog-post-about-sage-and.html">by Vincent Knight (noreply@blogger.com) at June 27, 2014 11:10 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>June 26, 2014</h2>

<div class="channelgroup">







<h3><a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-4667528901979447244.post-3621459165867084973">
<h4><a href="http://mathandhats.blogspot.com/2014/06/fun-with-elliptic-curve-l-function.html">Fun with elliptic curve L-function explicit formulae</a></h4>
<div class="entry">
<div class="content">
Although I gave a brief exposition of the "baseline" explicit formula for the elliptic curve $L$-functions in a previous post, I wanted to spend some more time showing how one can use this formula to prove some useful statements about the elliptic curves and their $L$-functions. Some of these are already implemented in some way in the code I am building for my GSoC project, and I hope to include more as time goes on.<br /><br />First up, let's fix some notation. For the duration of this post we fix an elliptic curve $E$ over the rationals with conductor $N$. Let $L_E(s)$ be its associated $L$-function, and let $\Lambda_E(s)$ be the completed $L$-function thereof, i.e.<br />$\Lambda_E(s) = N^{s/2}(2\pi)^s\Gamma(s)L_E(s)$, where $\Gamma$ is the usual Gamma function on $\mathbb{C}$. If you want to know more about how $E$, $L_E$ and $\Lambda_E$ are defined and how we compute with them, some of my previous posts (<a href="http://mathandhats.blogspot.com/2014/06/day-1-of-my-google-summer-of-code.html">here</a> and <a href="http://mathandhats.blogspot.com/2014/06/how-to-compute-with-elliptic-curve-l.html">here</a>) go into their exposition in more detail.<br /><br />Let's recap briefly how we derived the baseline explicit formula for the $L$-function of $E$ (see <a href="http://mathandhats.blogspot.com/2014/06/the-explicit-formula-and-estimating-rank.html">this post</a>&nbsp;for more background thereon). Taking logarithmic derivatives of the above formula for $\Lambda_E(s)$ and shifting to the left by one gives us the following equality:<br />$$\frac{\Lambda_E^{\prime}}{\Lambda_E}(1+s) = \log\left(\frac{\sqrt{N}}{2\pi}\right) + \frac{\Gamma^{\prime}}{\Gamma}(1+s) + \frac{L_E^{\prime}}{L_E}(1+s).$$<br />Nothing magic here yet. However, $\frac{\Lambda_E^{\prime}}{\Lambda_E}$, $\frac{\Gamma^{\prime}}{\Gamma}$ and $\frac{L_E^{\prime}}{L_E}$ all have particularly nice series expansions about the central point. We have:<br /><br /><ul><li>$\frac{\Lambda_E^{\prime}}{\Lambda_E}(1+s) = \sum_{\gamma} \frac{s}{s^2+\gamma^2}$, where $\gamma$ ranges over the imaginary parts of the zeros of $L_E$ on the critical line; this converges for any $s$ not equal to a zero of $L_E$.</li><li>$\frac{\Gamma^{\prime}}{\Gamma}(1+s) = -\eta + \sum_{k=1}^{\infty} \frac{s}{k(k+s)}$, where $\eta$ is the Euler-Mascheroni constant $=0.5772156649\ldots$ (this constant is usually denoted by the symbol $\gamma$ - but we'll be using that symbol for something else soon enough!); this sum converges for all $s$ not equal to a negative integer.</li><li>$\frac{L_E^{\prime}}{L_E}(1+s) = \sum_{n=1}^{\infty} c_n n^{-s}$; this only converges absolutely in the right half plane $\Re(s)&gt;\frac{1}{2}$.</li></ul><br />Here<br />$$ c_n = \begin{cases}<br />\left[p^m+1-\#E(\mathbb{F}_{p^m})\right]\frac{\log p}{p^m}, &amp; n = p^m \mbox{ is a perfect prime power,} \\<br />0 &amp; \mbox{otherwise.}\end{cases} $$<br /><br />Assembling these equalities gives us the aforementioned explicit formula:<br />$$ \sum_{\gamma} \frac{s}{s^2+\gamma^2} = \left[-\eta+\log\left(\frac{\sqrt{N}}{2\pi}\right)\right] + \sum_{k=1}^{\infty} \frac{s}{k(k+s)} + \sum_n c_n n^{-s}$$<br />which holds for any $s$ where all three series converge. It is this formula which we will use repeatedly to plumb the nature of $E$.<br /><br />For ease of exposition we'll denote the term in the square brackets $C_0$. It pitches up a lot in the math below, and it's a pain to keep writing out!<br /><br />Some things to note:<br /><br /><ul><li>$C_0 = -\eta+\log\left(\frac{\sqrt{N}}{2\pi}\right)$ is easily computable (assuming you know $N$). Importantly, this constant depends only on the conductor of $E$; it contains no other arithmetic information about the curve, nor does it depend in any way on the complex input $s$.</li><li>The sum $\sum_{k=1}^{\infty} \frac{s}{k(k+s)}$ doesn't depend on the curve <i>at all</i>. As such, when it comes to computing values associated to this sum we can just hard-code the computation before we even get to working with the curve itself.</li><li>The coefficients $c_n$ can computed by counting the number of points on $E$ over finite fields up to some bound. This is quick to do for any particular prime power.</li></ul><br />Good news: the code I've written can compute all the above values quickly and efficiently:<br /><br /><div><div><span>sage:&nbsp;</span>E&nbsp;=&nbsp;EllipticCurve([-12,29])</div><div><span>sage:&nbsp;</span>Z&nbsp;=&nbsp;LFunctionZeroSum(E)</div><div><span>sage:&nbsp;</span>N = E.conductor()</div><div><span>sage:&nbsp;</span>print(Z.C0(),RDF(-euler_gamma+log(sqrt(N)/(2*pi))))</div><div>(2.0131665172,&nbsp;2.0131665172)</div><div><div><span>sage:&nbsp;</span>print(Z.digamma(3.5),RDF(psi(3.5)))</div><div>(1.10315664065,&nbsp;1.10315664065)</div><div><span>sage:&nbsp;</span>Z.digamma(3.5,include_constant_term=False)</div><div>1.68037230555</div><div><span>sage:&nbsp;</span>Z.cn(389)</div><div>-0.183966457901</div></div><div><div><span>sage:&nbsp;</span>Z.cn(next_prime(1e9))</div><div>0.000368045198812</div><div><span>sage:&nbsp;</span>timeit('Z.cn(next_prime(1e9))')</div><div>625&nbsp;loops,&nbsp;best&nbsp;of&nbsp;3:&nbsp;238&nbsp;µs&nbsp;per&nbsp;loop</div></div></div><br />So by computing values on the right we can compute the sum on the left - without having to know the exact locations of the zeros $\gamma$, which in general is hard to compute.<br /><br />Now that we have this formula in the bag, let's put it to work.<br /><br /><h3>NAÏVE RANK ESTIMATION</h3><br />If we multiply the sum over the zeros by $s$ and letting $\Delta = 1/s$, we get<br />$$\sum_{\gamma} \frac{\Delta^{-2}}{\Delta^{-2}+\gamma^2} = \sum_{\gamma} \frac{1}{1+(\Delta\gamma)^2},$$<br />Note that for large values of $\Delta$, $\frac{1}{1+(\Delta\gamma)^2}$ is small but strictly positive for all nonzero $\gamma$, and 1 for the central zeros, which have $\gamma=0$. Thus the value of the sum when $\Delta$ is large gives a close upper bound on the analytic rank $r$ of $E$. That is, we can bound the rank of $E$ from above by choosing a suitably large value of $\Delta$ and computing the quantity on the right in the inequality below:<br />$$r &lt; \sum_{\gamma} \frac{1}{1+(\Delta\gamma)^2} = \frac{1}{\Delta}\left[C_0 + \sum_{k=1}^{\infty} \frac{1}{k(1+\Delta k)} + \sum_n c_n n^{-1/\Delta}\right]. $$<br />Great! Right? Wrong. In practice this approach is not a very good one. The reason is the infinite sum over $n$ only converges absolutely for $\Delta&lt;2$, and for Delta values as small as this, the obtained bound won't be very good. A value of $\Delta=2$, for example, gives us the zero sum $\sum_{\gamma} \frac{1}{1+(2\gamma)^2}$. If a curve's $L$-function has a zero with imaginary part about 0.5, for example - as many $L$-functions do - then such a zero will contribute 0.5 to the sum. And because zeros come in symmetric pairs, the sum value will then be at least a whole unit larger than the actual analytic rank. In general, for $\Delta&lt;2$ the computed sum can be quite a bit bigger than the actual analytic rank of $E$.<br /><br />Moreover, even though the Generalized Riemann Hypothesis predicts that the sum $\sum_n c_n n^{-1/\Delta}$ does indeed converge for any positive value of $\Delta$, in practice the convergence is so slow that we end up needing to compute inordinate amounts of the $c_n$ in order to hope to get a good approximation of the sum. So no dice; this approach is just too inefficient to be practical.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container"><tbody><tr><td><a href="http://1.bp.blogspot.com/-Mz3qApXl4JY/U6yP78O1d2I/AAAAAAAAAEI/TGSY9_IAGUM/s1600/cn_cumsum.png"><img border="0" src="http://1.bp.blogspot.com/-Mz3qApXl4JY/U6yP78O1d2I/AAAAAAAAAEI/TGSY9_IAGUM/s1600/cn_cumsum.png" height="195" width="400" /></a></td></tr><tr><td class="tr-caption">A graphic depiction of the convergence problems we run into when trying to evaluate the sum over the $c_n$. For the elliptic curve $E: y^2 + y = x^3 - 79*x + 342$ the above plot shows the cumulative sum $\sum_{n&lt;T} c_n n^{-1/4}$ for $T$ up to 100000; this corresponds to $\Delta=4$. Note that even when we include this many terms in the sum, its value still varies considerably. It's unlikely the final computed value is correct to a single decimal digit yet.</td></tr></tbody></table><br /><h3>A BETTER APPROACH (THE ONE IMPLEMENTED IN MY CODE)</h3><br />We can get around this impasse by evaluating a modified sum over the zeros, one which requires us to only ever need to compute finitely many of the $c_n$. Here's how we do it. Start with the sum $\sum_{\gamma} \frac{s}{s^2+\gamma^2}$, and divide by $s^2$ to get $\frac{1}{s(s^2+\gamma^2)}$. Now hearken back to your college sophomore math classes and take the inverse Laplace transform of this sum. We get<br />$$ \mathcal{L}^{-1} \left[\sum_{\gamma} \frac{1}{s(s^2+\gamma^2)}\right](t) = \sum_{\gamma} \mathcal{L}^{-1} \left[\frac{1}{s(s^2+\gamma^2)}\right](t) = \frac{t^2}{2} \sum_{\gamma} \left(\frac{\sin(\frac{t}{2}\gamma)}{\frac{t}{2}\gamma}\right)^2 $$<br />Letting $\Delta = \frac{t}{2\pi}$ we get the sum<br />$$ \mathcal{L}^{-1} \left[\sum_{\gamma} \frac{s}{s^2+\gamma^2}\right](\Delta) = 2\pi^2\Delta^2 \sum_{\gamma} \text{sinc}^2(\Delta\gamma), $$<br />where $\text{sinc}(x) = \frac{\sin(\pi x)}{\pi x}$, and $\text{sinc}(0) = 1$.<br /><br />Note that as before, $\text{sinc}^2(\Delta\gamma)$ exaluates to 1 for the central zeros, and is small but positive for all nonzero $\gamma$ when $\Delta$ is large. So again, this sum will give an upper bound on the analytic rank of $E$, and that this bound converges to the true analytic rank as $\Delta \to \infty$.<br /><br />If we do the same - divide by $s^2$ and take inverse Laplace transforms - to the quantities on the right, we get the following:<br /><br /><ul><li>$\mathcal{L}^{-1} \left[\frac{C_0}{s^2} \right] = 2\pi\Delta C_0;$</li><li>$ \mathcal{L}^{-1} \left[\sum_{k=1}^{\infty} \frac{1}{sk(k+s)}\right] = \sum_{k=1}^{\infty} \frac{1}{k^2}\left(1-e^{-2\pi\Delta k}\right);$</li><li>$\mathcal{L}^{-1} \left[ \sum_{n=1}^{\infty} c_n \frac{n^{-s}}{s^2} \right] = \sum_{\log n&lt;2\pi\Delta} c_n\cdot(2\pi\Delta - \log n). $</li></ul>Note that the last sum is <i>finite</i>: for any given value of $\Delta$, we only need to compute the $c_n$ for $n$ up to $e^{2\pi\Delta}$. This is the great advantage here: we can compute the sum <i>exactly</i>&nbsp;without introducing any truncation error. The other two quantities are also readly computable to any precision.<br /><br />Combining the above values and dividing by $2\pi^2\Delta^2$, we arrive at the rank bounding formula which is implemented in my GSoC code, hideous as it is:<br />\begin{align*}<br />r &lt; \sum_{\gamma} \text{sinc}^2(\Delta\gamma) = &nbsp;\frac{1}{\pi\Delta} &amp;\left[ C_0 + \frac{1}{2\pi\Delta}\sum_{k=1}^{\infty} \frac{1}{k^2}\left(1-e^{-2\pi\Delta k}\right) \right. \\<br />&amp;\left. + \sum_{n&lt;e^{2\pi\Delta}} c_n\left(1 - \frac{\log n}{2\pi\Delta}\right) \right] \end{align*}<br />Of course, the number of terms needed on the right hand side is still exponential in $\Delta$, so this limits the tightness of the sum we can compute on the left hand side. In practice a personal computer can compute the sum with $\Delta=2$ in a few seconds, and a more powerful cluster can handle $\Delta=3$ in a similar time. Beyond Delta values of about 4, however, the number of $c_n$ is just too great to make the sum effectively computable.<br /><br /><h3>THE DENSITY OF ZEROS ON THE CRITICAL LINE</h3><br />Explicit formula-type sums can also be used to answer questions about the distribution of zeros of $L_E$ along the critical line. Let $T$ be a positive real number, and $M_E(T)$ be the counting function that gives the number of zeros in the critical strip with imaginary part at most $T$ in magnitude. By convention, when $T$ coincides with a zero of $L_E$, then we count that zero with weight. In other words, we can write<br />$$ M_E(T) = \sum_{|\gamma|&lt;T} 1 + \sum_{|\gamma|=T} 1/2.$$<br />There is a more mathematically elegant way to write this sum. Let $\theta(x)$ be the Heaviside function on $x$ given by<br />$$ \theta(x) = \begin{cases} 0, &amp; x&lt;0 \\<br />\frac{1}{2}, &amp; x=0 \\<br />1, &amp; x&gt;0. \end{cases}$$<br />Then we have that<br />$$M_E(T) = \sum_{\gamma} \theta(T^2-\gamma^2). $$<br />We have written $M_E(T)$ as a sum over the zeros of $L_E$, so we expect that it comprises the left-hand-side of some explicit formula-type sum. This is indeed this the case. Using Fourier transforms we can show that<br />$$M_E(T) = \frac{2}{\pi}\left[C_0 T + \sum_{k=1}^{\infty} \left(\frac{T}{k} - \arctan \frac{T}{k}\right) + \sum_{n=1}^{\infty} \frac{c_n}{\log n}\cdot \sin(T\log n) \right] $$<br /><br />With this formula in hand we can start asking questions on how the zeros of $L_E$ are distributed. For example, how does average zero density on the critical line scale as a function of $T$, the imaginary part of the area in the critical strip we're considering? How does zero density scale with the curve's conductor $N$?<br /><br />If one assumes the Generalized Riemann Hypothesis, we can show that $\sum_{n=1}^{\infty} \frac{c_n}{\log n}\cdot \sin(T\log n) = O(\log T)$. Moreover, this sum is in a sense equidistributed about zero, so we expect its contribution for a sufficiently large randomly chosen value of $T$ to be zero. The other two quantities are more straightforward. The $C_0 T$ term is clearly linear in $T$. Going back to the definition of $C_0$, we see that $C_0 T = \frac{1}{2}T\log N + $constant$\cdot T$. Finally, we can show that the sum over $k$ equals $T\log T + O(\log T)$. Combining this gives us the estimate<br />$$ M_E(T) = \frac{1}{\pi} T (\log N + 2\log T+a)&nbsp;+ O(\log T)&nbsp;$$<br />for some explicitly computable constant $a$ independent of $E$, $N$ or $T$ . That is, the number of zeros with imaginary part at most $T$ in magnitude is "very close" to $\frac{1}{\pi}T(\log N + 2\log T)$. Another way to put it is than the number of zeros in the interval $[T,T+1]$ is about $\frac{1}{2}\log N + \log T$.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container"><tbody><tr><td><a href="http://2.bp.blogspot.com/-Se_FhBWmhPU/U6yWCAPfKQI/AAAAAAAAAEY/wQqTw0cApWI/s1600/zero_counting_function.png"><img border="0" src="http://2.bp.blogspot.com/-Se_FhBWmhPU/U6yWCAPfKQI/AAAAAAAAAEY/wQqTw0cApWI/s1600/zero_counting_function.png" height="196" width="400" /></a></td></tr><tr><td class="tr-caption">The value of $M_E(T)$ for $T$ up to 30, for the elliptic curve $E:&nbsp;y^2 + y = x^3 - x$. The black line is just the 'smooth part' of $M_E(T)$, given by $\frac{2}{\pi}\left(C_0 T + \sum_{k=1}^{\infty} \left(\frac{T}{k} - \arctan \frac{T}{k}\right)\right)$. This gives us the 'expected number of zeros up to $T$', before we know any data about $E$ other than its conductor. The blue line is what we get when we add in $\sum_{n=1}^{\infty} \frac{c_n}{\log n}\cdot \sin(T\log n)$, which tells us the exact locations of the zeros: they will be found at the places where the blue curve jumps by 2.<br /><br />Note that the sum over $n$ converges *very* slowly. To produce the above plot, I included terms up to $n=1 000 000$, and there is still considerable rounding visible in the blue curve. If I could some how evaluate the $c_n$ sum in all its infinite glory, then resulting plot would be perfectly sharp, comprised of flat lines that jump vertically by 2 at the loci of the zeros.</td></tr></tbody></table><br /><br />These are two of the uses of explicit formula-type sums in the context of elliptic curve $L$-functions. If you want to read more about them, feel free to pick up my PhD thesis - when it eventually gets published!</div>







<p class="date">
<a href="http://mathandhats.blogspot.com/2014/06/fun-with-elliptic-curve-l-function.html">by Simon Spicer (noreply@blogger.com) at June 26, 2014 03:23 PM</a>
</p>
</div>
</div>


</div>

</div>

</div>
<div class="body-corner">
<div id="body-corner-bl"></div> 
<div id="body-corner-br"></div> 
</div>


<!-- Side bar for subscriptions -->

<div class="sidebar">
<!-- img src="images/cube5-thumb.png" width="136" height="136" alt="" -->

<h1> &nbsp; Planet Sage</h1>
<p>
Planet Sage is a central repository of news about Sage, its development
and use, brought to you by Sage developers and users. If you would like your
blog posts to be aggregated here, please email the
<a href="http://sagemath.org/contact.html">Planet Sage
maintainer</a>.
</p>

<h2>Subscribe</h2>
<p>
<a href="http://planet.sagemath.org/atom.xml">Atom Feed</a>, 
<a href="http://planet.sagemath.org/rss20.xml">RSS 2.0 Feed</a>
</p>

<h2>Subscriptions</h2>
<ul>
<li>
<a href="http://amca01.wordpress.com/category/sage/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">Alasdair McAndrew</a>
</li>
<li>
<a href="http://aghitza.org/tags/sage/index.rss" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="404: not found">Alex Ghitza</a>
</li>
<li>
<a href="http://knotsknotted.wordpress.com/category/gsoc/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://knotsknotted.wordpress.com/" class="message" title="internal server error">Amit Jamadagni</a>
</li>
<li>
<a href="http://benjamin-hackl.at/tag/gsoc15/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://benjamin-hackl.at/tag/gsoc15/" title="Benjamin Hackl » GSoC15">Benjamin Hackl</a>
</li>
<li>
<a href="http://carlo-hamalainen.net/blog/?feed=rss2&amp;cat=8" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="no activity in 356 days">Carlo Hamalainen</a>
</li>
<li>
<a href="https://sage2015gsocmatroid.wordpress.com/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="https://sage2015gsocmatroid.wordpress.com/" class="message" title="internal server error">Chao Xu</a>
</li>
<li>
<a href="http://christopherolah.wordpress.com/tag/sage/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">Christopher Olah</a>
</li>
<li>
<a href="http://quantumtetrahedron.wordpress.com/category/personal-research/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://quantumtetrahedron.wordpress.com/" class="message" title="internal server error">David Horgan (quantumtetrahedron)</a>
</li>
<li>
<a href="http://wdjoyner.wordpress.com/tag/sage/feed" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">David Joyner</a>
</li>
<li>
<a href="http://doxdrum.wordpress.com/tag/sage/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">Doxdrum</a>
</li>
<li>
<a href="http://www.phas.ubc.ca/~eviatarb/index.php?feed=type&amp;c=sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://www.phas.ubc.ca/~eviatarb/" class="message" title="no activity in 356 days">Eviatar Bach</a>
</li>
<li>
<a href="http://fredrik-j.blogspot.com/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://fredrik-j.blogspot.com/search/label/sage" class="message" title="no activity in 356 days">Fredrik Johansson</a>
</li>
<li>
<a href="http://blog.harald.schil.ly/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://blog.harald.schil.ly/search/label/sage" title="Harald Schilly">Harald Schilly</a>
</li>
<li>
<a href="http://gsoc-sage-lattices.blogspot.com/feeds/posts/default" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://gsoc-sage-lattices.blogspot.com/" class="message" title="no activity in 356 days">Jan Pöschko</a>
</li>
<li>
<a href="http://6dime.blogspot.com/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://6dime.blogspot.com/search/label/sage" class="message" title="no activity in 356 days">Jens Rasch</a>
</li>
<li>
<a href="http://jonathanleesage.blogspot.com/feeds/posts/default/-/gsoc" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://jonathanleesage.blogspot.com/" class="message" title="no activity in 356 days">Jonathan Lee</a>
</li>
<li>
<a href="http://leeworden.net/lw/taxonomy/term/25/feed" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://leeworden.net/lw/taxonomy/term/25" class="message" title="no activity in 356 days">Lee Worden</a>
</li>
<li>
<a href="http://sheaves.github.io/feed.xml" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://sheaves.github.io/" title="Sheaves">Liang Ze</a>
</li>
<li>
<a href="http://lina-kulakova.blogspot.com/feeds/posts/default" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://lina-kulakova.blogspot.com/" class="message" title="no activity in 356 days">Lina Kulakova</a>
</li>
<li>
<a href="http://neutraldrifts.blogspot.com/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://neutraldrifts.blogspot.com/search/label/sage" class="message" title="no activity in 356 days">Marshall Hampton</a>
</li>
<li>
<a href="http://martinralbrecht.wordpress.com/tag/sage/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">Martin Albrecht</a>
</li>
<li>
<a href="http://borassisagemath.blogspot.com/feeds/posts/default" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://borassisagemath.blogspot.com/" title="Performance Improvements for the Graph Module of Sagemath">Michele Borassi</a>
</li>
<li>
<a href="http://mvngu.wordpress.com/tag/sage/feed" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">Minh Van Nguyen</a>
</li>
<li>
<a href="http://ncalexan.wordpress.com/tag/sage/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="internal server error">Nick Alexander</a>
</li>
<li>
<a href="http://blog.hav3n.net/?feed=rss2&amp;tag=gsoc-2014" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://blog.hav3n.net/?tag=gsoc-2014" title="Nikhil's GSoC Blog » GSoC 2014">Nikhil Peter</a>
</li>
<li>
<a href="http://ondrejcertik.blogspot.com/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://ondrejcertik.blogspot.com/search/label/sage" class="message" title="no activity in 356 days">Ondrej Certik</a>
</li>
<li>
<a href="http://phisycsandgnulinux.site11.com/?tag=sage&amp;feed=rss2" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="no activity in 356 days">Oscar Lazo</a>
</li>
<li>
<a href="http://polybori.blogspot.com/feeds/posts/default/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://polybori.blogspot.com/" class="message" title="no activity in 356 days">PolyBoRi Blog</a>
</li>
<li>
<a href="http://rasmi.io/tag/sage/feed/" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://rasmi.io/" class="message" title="404: not found">Rasmi Elasmar</a>
</li>
<li>
<a href="http://blog.rlmiller.org/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a class="message" title="404: not found">Robert Miller</a>
</li>
<li>
<a href="http://sageworldmath.blogspot.com/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://sageworldmath.blogspot.com/search/label/sage" class="message" title="no activity in 356 days">Serge A. Salamanka</a>
</li>
<li>
<a href="http://mathandhats.blogspot.com/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://mathandhats.blogspot.com" title="Math and Hats">Simon Spicer</a>
</li>
<li>
<a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/categorie/sage/feed/atom/index.xml" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://www.liafa.univ-paris-diderot.fr/~labbe/blogue/" title="Sébastien Labbé">Sébastien Labbé</a>
</li>
<li>
<a href="http://matroidunion.org/?feed=rss2&amp;cat=7" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://matroidunion.org" class="message" title="no activity in 356 days">The Matroid Union</a>
</li>
<li>
<a href="http://titusnicolae.blogspot.com/feeds/posts/default" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://titusnicolae.blogspot.com/" class="message" title="no activity in 356 days">Titus Nicolae</a>
</li>
<li>
<a href="http://broniks.blogspot.mx/feeds/posts/default/-/sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://broniks.blogspot.com/search/label/sage" class="message" title="no activity in 356 days">Verónica Suaste Morales</a>
</li>
<li>
<a href="http://drvinceknight.blogspot.co.uk/feeds/posts/default/-/Sage" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://drvinceknight.blogspot.com/search/label/Sage" title="Un peu de math...">Vince Knight</a>
</li>
<li>
<a href="http://drvinceknight.github.io/unpeudemath/feed.xml" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://drvinceknight.github.io/unpeudemath/" title="Un peu de math">Vince Knight</a>
</li>
<li>
<a href="http://sagemath.blogspot.com/feeds/posts/default" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="http://sagemath.blogspot.com/" title="Sage: Open Source Mathematics Software">William Stein</a>
</li>
</ul>

<h2>Planetarium:</h2>
<ul>
<li><a href="http://www.planetapache.org/">Planet Apache</a></li>
<li><a href="http://planet.debian.net/">Planet Debian</a></li>
<li><a href="http://planet.freedesktop.org/">Planet freedesktop.org</a></li>
<li><a href="http://planet.gnome.org/">Planet GNOME</a></li>
<li><a href="http://planetkde.org/">Planet KDE</a></li>
<li><a href="http://planet.python.org/">Planet Python</a></li>
<li><a href="http://planet.ubuntulinux.org/">Planet Ubuntu</a></li>
<li><a href="http://www.planetplanet.org/">more...</a></li>
</ul>

<p>
<strong>Last updated:</strong><br>
June 09, 2015 11:30 AM<br>
<em>All times are UTC.</em><br>
<br>
Powered by:<br>
<a href="http://www.planetplanet.org/"><img src="images/planet.png" width="80" height="15" alt="Planet" border="0"></a>
</p>

</div>

</body>

</html>
